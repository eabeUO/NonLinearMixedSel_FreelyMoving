{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "touched-korea",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "import sys \n",
    "import yaml \n",
    "import glob\n",
    "import h5py \n",
    "import ray\n",
    "import logging \n",
    "import json\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "# import io_dict_to_hdf5 as ioh5\n",
    "import xarray as xr\n",
    "import scipy.linalg as linalg\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import shift as imshift\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model as lm \n",
    "from scipy.stats import binned_statistic\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import r2_score, mean_poisson_deviance\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torchvision import transforms\n",
    "import torchvision\n",
    "from scipy.ndimage import uniform_filter1d \n",
    "# from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sys.path.append(str(Path('.').absolute().parent))\n",
    "from utils import *\n",
    "import io_dict_to_hdf5 as ioh5\n",
    "from format_data import load_ephys_data_aligned\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "FigPath = check_path(Path('~/Research/SensoryMotorPred_Data').expanduser(),'Figures/Decoding')\n",
    "\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    logging_level=logging.ERROR,\n",
    ")\n",
    "print(f'Dashboard URL: http://{ray.get_dashboard_url()}')\n",
    "print('Dashboard URL: http://localhost:{}'.format(ray.get_dashboard_url().split(':')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-particle",
   "metadata": {},
   "source": [
    "Decode out spatial patches from neural activity. \n",
    "\n",
    "nonlinear combining of visual and movement gives more predictive power then linear combining. \n",
    "\n",
    "frames and movement at time t predict visual info at t+1 with linear comb and nonlinear comb. combining in nonlin way would work better. \n",
    "\n",
    "how to make linear or nonlinear combinations of inputs? input is pixel intensities, and movment params output pixel intesities at t+1. \n",
    "\n",
    "mult case: random projection at same dimentionality. Pixels * movement. \n",
    "\n",
    "h0 just visual predicts only visual. movement \"adds\" something here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-geneva",
   "metadata": {},
   "source": [
    "# Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test(file_dict, save_dir, model_dt=.1, frac=.1, train_size=.7, do_shuffle=False, do_norm=False, free_move=True, has_imu=True, has_mouse=False,):\n",
    "    ##### Load in preprocessed data #####\n",
    "    data = load_ephys_data_aligned(file_dict, save_dir, model_dt=model_dt, free_move=free_move, has_imu=has_imu, has_mouse=has_mouse,)\n",
    "    if free_move:\n",
    "        ##### Find 'good' timepoints when mouse is active #####\n",
    "        nan_idxs = []\n",
    "        for key in data.keys():\n",
    "            nan_idxs.append(np.where(np.isnan(data[key]))[0])\n",
    "        good_idxs = np.ones(len(data['model_active']),dtype=bool)\n",
    "        good_idxs[data['model_active']<.5] = False\n",
    "        good_idxs[np.unique(np.hstack(nan_idxs))] = False\n",
    "    else:\n",
    "        good_idxs = np.where((np.abs(data['model_th'])<10) & (np.abs(data['model_phi'])<10))[0]\n",
    "    \n",
    "    data['raw_nsp'] = data['model_nsp'].copy()\n",
    "    ##### return only active data #####\n",
    "    for key in data.keys():\n",
    "        if (key != 'model_nsp') & (key != 'model_active') & (key != 'unit_nums'):\n",
    "            data[key] = data[key][good_idxs] # interp_nans(data[key]).astype(float)\n",
    "        elif (key == 'model_nsp'):\n",
    "            data[key] = data[key][good_idxs]\n",
    "        elif (key == 'unit_nums'):\n",
    "            pass\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=train_size, random_state=42)\n",
    "    nT = data['model_nsp'].shape[0]\n",
    "    groups = np.hstack([i*np.ones(int((frac*i)*nT) - int((frac*(i-1))*nT)) for i in range(1,int(1/frac)+1)])\n",
    "\n",
    "    for train_idx, test_idx in gss.split(np.arange(len(data['model_nsp'])), groups=groups):\n",
    "        print(\"TRAIN:\", len(train_idx), \"TEST:\", len(test_idx))\n",
    "\n",
    "\n",
    "    data['model_dth'] = np.diff(data['model_th'],append=0)\n",
    "    data['model_dphi'] = np.diff(data['model_phi'],append=0)\n",
    "\n",
    "    data['model_vid_sm'] = (data['model_vid_sm'] - np.mean(data['model_vid_sm'],axis=0))/np.nanstd(data['model_vid_sm'],axis=0)\n",
    "    data['model_vid_sm'][np.isnan(data['model_vid_sm'])]=0\n",
    "    if do_norm:\n",
    "        data['model_th'] = (data['model_th'] - np.mean(data['model_th'],axis=0))/np.std(data['model_th'],axis=0) \n",
    "        data['model_phi'] = (data['model_phi'] - np.mean(data['model_phi'],axis=0))/np.std(data['model_phi'],axis=0) \n",
    "        if free_move:\n",
    "            data['model_roll'] = (data['model_roll'] - np.mean(data['model_roll'],axis=0))/np.std(data['model_roll'],axis=0) \n",
    "            data['model_pitch'] = (data['model_pitch'] - np.mean(data['model_pitch'],axis=0))/np.std(data['model_pitch'],axis=0) \n",
    "\n",
    "    ##### Split Data by train/test #####\n",
    "    data_train_test = {\n",
    "        'train_vid': data['model_vid_sm'][train_idx],\n",
    "        'test_vid': data['model_vid_sm'][test_idx],\n",
    "        'train_nsp': shuffle(data['model_nsp'][train_idx],random_state=42) if do_shuffle else data['model_nsp'][train_idx],\n",
    "        'test_nsp': shuffle(data['model_nsp'][test_idx],random_state=42) if do_shuffle else data['model_nsp'][test_idx],\n",
    "        'train_th': data['model_th'][train_idx],\n",
    "        'test_th': data['model_th'][test_idx],\n",
    "        'train_phi': data['model_phi'][train_idx],\n",
    "        'test_phi': data['model_phi'][test_idx],\n",
    "        'train_roll': data['model_roll'][train_idx] if free_move else [],\n",
    "        'test_roll': data['model_roll'][test_idx] if free_move else [],\n",
    "        'train_pitch': data['model_pitch'][train_idx] if free_move else [],\n",
    "        'test_pitch': data['model_pitch'][test_idx] if free_move else [],\n",
    "        'train_t': data['model_t'][train_idx],\n",
    "        'test_t': data['model_t'][test_idx],\n",
    "        'train_dth': data['model_dth'][train_idx],\n",
    "        'test_dth': data['model_dth'][test_idx],\n",
    "        'train_dphi': data['model_dphi'][train_idx],\n",
    "        'test_dphi': data['model_dphi'][test_idx],\n",
    "        'train_gz': data['model_gz'][train_idx] if free_move else [],\n",
    "        'test_gz': data['model_gz'][test_idx] if free_move else [],\n",
    "    }\n",
    "\n",
    "    d1 = data\n",
    "    d1.update(data_train_test)\n",
    "    return d1,train_idx,test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_move = True\n",
    "if free_move:\n",
    "    stim_type = 'fm1'\n",
    "else:\n",
    "    stim_type = 'hf1_wn' # 'fm1' # \n",
    "\n",
    "data_dir  = Path('~/Goeppert/freely_moving_ephys/ephys_recordings/070921/J553RT').expanduser() / stim_type\n",
    "save_dir  = check_path(Path('~/Research/SensoryMotorPred_Data/data/070921/J553RT/').expanduser(), stim_type)\n",
    "FigPath = check_path(FigPath, stim_type)\n",
    "save_dir,data_dir,FigPath\n",
    "# with open(save_dir / 'file_dict.json','r') as fp:\n",
    "#     file_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {'cell': 0,\n",
    " 'drop_slow_frames': True,\n",
    " 'ephys': list(data_dir.glob('*ephys_merge.json'))[0].as_posix(),\n",
    " 'ephys_bin': list(data_dir.glob('*Ephys.bin'))[0].as_posix(),\n",
    " 'eye': list(data_dir.glob('*REYE.nc'))[0].as_posix(),\n",
    " 'imu': list(data_dir.glob('*imu.nc'))[0].as_posix() if stim_type=='fm1' else None,\n",
    " 'mapping_json': '/home/seuss/Research/Github/FreelyMovingEphys/probes/channel_maps.json',\n",
    " 'mp4': True,\n",
    " 'name': '070921_J553RT_control_Rig2_'+stim_type,\n",
    " 'probe_name': 'DB_P128-6',\n",
    " 'save': data_dir.as_posix(),\n",
    " 'speed': None,\n",
    " 'stim_type': 'light',\n",
    " 'top': list(data_dir.glob('*TOP1.nc'))[0].as_posix() if stim_type=='fm1' else None,\n",
    " 'world': list(data_dir.glob('*world.nc'))[0].as_posix(),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = .05\n",
    "data,train_idx,test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=False, do_norm=False,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "locals().update(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-chest",
   "metadata": {},
   "source": [
    "# Testing Tuning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tuning curve for theta\n",
    "def tuning_curve(model_nsp, var, model_dt = .05, N_bins=10, Nstds=3):\n",
    "    var_range = np.linspace(np.nanmean(var)-Nstds*np.nanstd(var), np.nanmean(var)+Nstds*np.nanstd(var),N_bins)\n",
    "    tuning = np.zeros((model_nsp.shape[-1],len(var_range)-1))\n",
    "    tuning_std = np.zeros((model_nsp.shape[-1],len(var_range)-1))\n",
    "    for n in range(model_nsp.shape[-1]):\n",
    "        for j in range(len(var_range)-1):\n",
    "            usePts = (var>=var_range[j]) & (var<var_range[j+1])\n",
    "            tuning[n,j] = np.nanmean(model_nsp[usePts,n])/model_dt\n",
    "            tuning_std[n,j] = (np.nanstd(model_nsp[usePts,n])/model_dt)/ np.sqrt(np.count_nonzero(usePts))\n",
    "    return tuning, tuning_std, var_range[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning, tuning_std, var_range = tuning_curve(test_nsp, test_th, N_bins=10, model_dt=model_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 21\n",
    "fig, axs = plt.subplots(1,figsize=(7,5))\n",
    "axs.errorbar(var_range,tuning[n], yerr=tuning_std[n])\n",
    "axs.set_ylim(bottom=0)\n",
    "axs.set_xlabel('Eye Phi')\n",
    "axs.set_ylabel('Spikes/s')\n",
    "axs.set_title('Neuron: {}'.format(n))\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'ExampleTuningCurve.png',bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-example",
   "metadata": {},
   "source": [
    "# Decoding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def do_glm_fit_vis_skl(train_nsp, test_nsp, y_train, y_test, celln, model_type, lag_list, bin_length=40, model_dt=.1):\n",
    "    \n",
    "    ##### Format data #####\n",
    "    nt_glm_lag = len(lag_list)\n",
    "    \n",
    "    # Shift spikes by -lag for GLM fits\n",
    "    sps_train = train_nsp[:,celln] # np.roll(train_nsp[:,celln],-lag)\n",
    "    sps_test = test_nsp[:,celln] # np.roll(test_nsp[:,celln],-lag)\n",
    "\n",
    "\n",
    "    if model_type == 'elasticnetcv':\n",
    "        model = lm.ElasticNetCV(l1_ratio=[.05, .01, .5, .7]) # lm.RidgeCV(alphas=np.arange(100,10000,1000))) #  #MultiOutputRegressor(lm.Ridge(),n_jobs=-1)) \n",
    "        model.fit(sps_train,y_train)\n",
    "        sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "        sp_pred = model.predict(y_test)\n",
    "    elif model_type == 'ridgecv':\n",
    "        lambdas = 1024 * (2**np.arange(0,16))\n",
    "        model = lm.RidgeCV(alphas=lambdas)\n",
    "        model.fit(sps_train,y_train)\n",
    "        sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "        sp_pred = model.predict(y_test)\n",
    "    return cc_all, sta_all, sps_test, sp_pred, r2_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag=150 # in ms\n",
    "nt_glm_lag = 5\n",
    "# minlag = int(-lag//(1000*model_dt)); maxlag=int((lag//(1000*model_dt))+1)\n",
    "lag_list = np.array([-1,0,1,2,3]) #,np.arange(minlag,maxlag,np.floor((maxlag-minlag)/nt_glm_lag).astype(int))\n",
    "nt_glm_lag = len(lag_list)\n",
    "print(lag_list,1000*lag_list*model_dt)\n",
    "do_shuffle=False\n",
    "model_type = 'ridgecv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "winds_train = sliding_window_view(train_vid,(windn,windn),axis=(1,2))[:,::skipn,::skipn]\n",
    "winds_train = winds_train.reshape(winds_train.shape[0],-1,winds_train.shape[-2],winds_train.shape[-1])\n",
    "winds_test = sliding_window_view(test_vid,(windn,windn),axis=(1,2))[:,::skipn,::skipn]\n",
    "winds_test = winds_test.reshape(winds_test.shape[0],-1,winds_test.shape[-2],winds_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "# model = lm.RidgeCV(alphas=lambdas)\n",
    "model = lm.MultiTaskElasticNetCV(l1_ratio=[.05, .01, .5, .7]) # lm.RidgeCV(alphas=np.arange(100,10000,1000))) #  #MultiOutputRegressor(lm.Ridge(),n_jobs=-1)) \n",
    "model.fit(train_nsp,winds_train[:,0].reshape(winds_train.shape[0],-1))\n",
    "# sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "sp_pred = model.predict(test_nsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_glm_lag = 1\n",
    "nks = np.shape(train_vid)[1:]; nk = nks[0]*nks[1]*nt_glm_lag\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "model = lm.RidgeCV(alphas=lambdas,verbose=True, n_jobs=-1)\n",
    "# model = lm.MultiTaskElasticNetCV(cv=2,l1_ratio=[.01,.05,.5],verbose=True,selection='random',n_jobs=-1) # lm.RidgeCV(alphas=np.arange(100,10000,1000))) #  #MultiOutputRegressor(lm.Ridge(),n_jobs=-1)) \n",
    "model.fit(train_nsp,train_vid.reshape(train_vid.shape[0],-1))\n",
    "# sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "sp_pred = model.predict(test_nsp)\n",
    "pred_train = model.predict(train_nsp).reshape(-1,nks[0],nks[1])\n",
    "pred_test = sp_pred.reshape(sp_pred.shape[0],nks[0],nks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 2\n",
    "pred_test_norm = normimgs(pred_test)\n",
    "pred_test_up = np.zeros((pred_test.shape[0],sf*pred_test.shape[1],sf*pred_test.shape[2]))\n",
    "test_vid_norm = normimgs(test_vid)\n",
    "test_vid_up = np.zeros((test_vid.shape[0],sf*test_vid.shape[1],sf*test_vid.shape[2]))\n",
    "pred_train_norm = normimgs(pred_train)\n",
    "pred_train_up = np.zeros((pred_train.shape[0],sf*pred_train.shape[1],sf*pred_train.shape[2]))\n",
    "train_vid_norm = normimgs(train_vid)\n",
    "train_vid_up = np.zeros((train_vid.shape[0],sf*train_vid.shape[1],sf*train_vid.shape[2]))\n",
    "for n in range(pred_test.shape[0]):\n",
    "    pred_test_up[n] = cv2.resize(pred_test_norm[n],(sf*pred_test.shape[2],sf*pred_test.shape[1]))\n",
    "    test_vid_up[n] = cv2.resize(test_vid_norm[n],(sf*test_vid.shape[2],sf*test_vid.shape[1]))\n",
    "    pred_train_up[n] = cv2.resize(pred_train_norm[n],(sf*pred_train.shape[2],sf*pred_train.shape[1]))\n",
    "    train_vid_up[n] = cv2.resize(train_vid_norm[n],(sf*train_vid.shape[2],sf*train_vid.shape[1]))\n",
    "\n",
    "cond = 'test'\n",
    "if cond == 'train':\n",
    "    tot_samps = np.stack((pred_train_up, train_vid_up))\n",
    "else:\n",
    "    tot_samps = np.stack((pred_test_up, test_vid_up))\n",
    "tot_samps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1040 #2000\n",
    "dt = 10\n",
    "fig, ax = plt.subplots(1,10,figsize=(30,3))\n",
    "\n",
    "for n,t in enumerate(np.arange(t,t+dt)):\n",
    "    ax[n].imshow(pred_test_up[t,:,:], cmap='gray')\n",
    "    ax[n].axis('off')\n",
    "plt.suptitle('Decoding Frames')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'Decoding_Frame.png',facecolor='white', transparent=True)\n",
    "\n",
    "fig2, ax2 = plt.subplots(1,10,figsize=(30,3))\n",
    "for n,t in enumerate(np.arange(t,t+dt)):\n",
    "    ax2[n].imshow(test_vid_up[t,:,:], cmap='gray')\n",
    "    ax2[n].axis('off')\n",
    "plt.suptitle('Actual Frames')\n",
    "plt.tight_layout()\n",
    "# fig2.savefig(FigPath/'Decoding_Actual_Frame.png',facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 200 #2000\n",
    "dt = 200\n",
    "im_grid = torchvision.utils.make_grid(torch.from_numpy(pred_test[t:t+dt,np.newaxis,:,:]),nrow=10,normalize=False)[0]\n",
    "im_grid2 = torchvision.utils.make_grid(torch.from_numpy(test_vid[t:t+dt,np.newaxis,:,:]),nrow=10,normalize=False)[0]\n",
    "fig, axs = plt.subplots(1,2,figsize=(20,20))\n",
    "axs[0].imshow(im_grid, cmap='gray')#.permute(1,2,0))\n",
    "axs[0].set_title('Decoding Prediction')\n",
    "axs[1].imshow(im_grid2, cmap='gray')#.permute(1,2,0))\n",
    "axs[1].set_title('Actual Frame')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'DecodedMontage_{}.png'.format(model_type),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coeff = model.coef_.T.reshape(train_nsp.shape[-1],train_vid.shape[1],train_vid.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model_coeff[51],cmap='RdBu')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_grid = torchvision.utils.make_grid(torch.from_numpy(model_coeff[:,np.newaxis]),nrow=10,normalize=True)[0]\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,10))\n",
    "axs.imshow(im_grid, cmap='gray')#.permute(1,2,0))\n",
    "axs.set_title('Decoding Coeff')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'DecodingWeights_{}.png'.format(model_type),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "nks = np.shape(train_vid)[1:]; nk = nks[0]*nks[1]*nt_glm_lag\n",
    "vid_pred = sp_pred.reshape(sp_pred.shape[0],nks[0],nks[1])\n",
    "t=20\n",
    "plt.imshow(vid_pred[t])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "for do_shuffle in [False]:\n",
    "    # Load Data\n",
    "    data,train_idx,test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=do_shuffle, do_norm=True,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "    locals().update(data)\n",
    "    windn = 5\n",
    "    skipn = 3\n",
    "    ##### Start GLM Parallel Processing #####\n",
    "    start = time.time()\n",
    "    nks = np.shape(train_vid)[1:]; nk = nks[0]*nks[1]*nt_glm_lag\n",
    "    # Reshape data (video) into (T*n)xN array\n",
    "    winds_train = sliding_window_view(train_vid,(windn,windn),axis=(1,2))[:,::skipn,::skipn]\n",
    "    winds_train = winds_train.reshape(winds_train.shape[0],-1,winds_train.shape[-2],winds_train.shape[-1])\n",
    "    winds_test = sliding_window_view(test_vid,(windn,windn),axis=(1,2))[:,::skipn,::skipn]\n",
    "    winds_test = winds_test.reshape(winds_test.shape[0],-1,winds_test.shape[-2],winds_test.shape[-1])\n",
    "#     y_train = train_vid.reshape(train_vid.shape[0],-1)\n",
    "#     y_test = test_vid.reshape(test_vid.shape[0],-1) \n",
    "    \n",
    "    # Put data into shared memory for parallization \n",
    "    train_nsp_r = ray.put(train_nsp)\n",
    "    test_nsp_r = ray.put(test_nsp)\n",
    "    train_data_r = ray.put(x_train)\n",
    "    test_data_r = ray.put(x_test)\n",
    "    result_ids = []\n",
    "    # Loop over parameters appending process ids\n",
    "    for celln in range(train_nsp.shape[1]):\n",
    "        result_ids.append(do_glm_fit_vis_skl.remote(train_nsp_r, test_nsp_r, train_data_r, test_data_r, celln, model_type, lag_list, model_dt=model_dt))\n",
    "\n",
    "    print('N_proc:', len(result_ids))\n",
    "    results_p = ray.get(result_ids)\n",
    "    print('GLM Add: ', time.time()-start)\n",
    "\n",
    "    ##### Gather Data and Find Max CC Model #####\n",
    "    mcc = np.stack([results_p[i][0] for i in range(len(results_p))])\n",
    "    msta = np.stack([results_p[i][1] for i in range(len(results_p))])\n",
    "    msp = np.stack([results_p[i][2] for i in range(len(results_p))])\n",
    "    mpred = np.stack([results_p[i][3] for i in range(len(results_p))])\n",
    "    mr2 = np.stack([results_p[i][4] for i in range(len(results_p))])\n",
    "\n",
    "#     nt_glm_lag = len(lag_list)\n",
    "#     GLM_Data = {'mcc': mcc,\n",
    "#                 'msta': msta,\n",
    "#                 'msp': msp,\n",
    "#                 'mpred': mpred,\n",
    "#                 'mr2':mr2,}\n",
    "#     if do_shuffle:\n",
    "#         ioh5.save(save_dir/'GLM_{}_Data_VisOnly_notsmooth_dt{:03d}_T{:02d}_shuffled.h5'.format(model_type,int(model_dt*1000), nt_glm_lag), GLM_Data)\n",
    "#     else:\n",
    "#         ioh5.save(save_dir/'GLM_{}_Data_VisOnly_notsmooth_dt{:03d}_T{:02d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag), GLM_Data)\n",
    "        \n",
    "#     del train_nsp_r, test_nsp_r, train_data_r, test_data_r, result_ids, results_p, mcc, msta, msp, mpred, mr2,\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(5000).reshape(50,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "windn = 5\n",
    "skipn = 3\n",
    "winds = sliding_window_view(train_vid,(windn,windn),axis=(1,2))[:,::skipn,::skipn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "winds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-calvin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "crude-forty",
   "metadata": {},
   "source": [
    "# Predciting Future input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize movement combinations\n",
    "titles = np.array(['Theta','Phi','Roll','Pitch']) # 'dg_p','dg_n' 'roll','pitch'\n",
    "titles_all = []\n",
    "for n in range(1,len(titles)+1):\n",
    "    perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "    for ind in range(perms.shape[0]):\n",
    "        titles_all.append('_'.join([t for t in titles[perms[ind]]]))\n",
    "\n",
    "train_dgaze_p = train_dth + np.diff(train_gz,append=0)\n",
    "train_dgaze_n = train_dth - np.diff(train_gz,append=0)\n",
    "test_dgaze_p = test_dth + np.diff(test_gz,append=0)\n",
    "test_dgaze_n = test_dth - np.diff(test_gz,append=0)\n",
    "move_train = np.hstack((train_th[:,np.newaxis],train_phi[:,np.newaxis],train_roll[:,np.newaxis],train_pitch[:,np.newaxis]))#, train_dth[:,np.newaxis],train_dphi[:,np.newaxis]))\n",
    "move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_roll[:,np.newaxis],test_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "# move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))# test_dth[:,np.newaxis],test_dphi[:,np.newaxis]))\n",
    "model_move = np.hstack((model_th[:,np.newaxis],model_phi[:,np.newaxis],model_roll[:,np.newaxis],model_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "model_move = model_move - np.mean(model_move,axis=0)\n",
    "move_test = move_test - np.mean(move_test,axis=0)\n",
    "move_train = move_train - np.mean(move_train,axis=0)\n",
    "\n",
    "\n",
    "lag_list = [5]\n",
    "Tvid = train_vid.shape[0]\n",
    "rolled_vid = np.hstack([np.roll(model_vid_sm, nframes, axis=0) for nframes in lag_list]) # nt_glm_lag\n",
    "x_train = train_vid.reshape(len(train_idx),-1)\n",
    "x_test = test_vid.reshape(len(test_idx),-1)\n",
    "\n",
    "y_train = rolled_vid[train_idx].reshape(len(train_idx),-1)\n",
    "y_test = rolled_vid[test_idx].reshape(len(test_idx),-1)\n",
    "\n",
    "npx = train_vid.shape[1]*train_vid.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "model = lm.RidgeCV(alphas=lambdas)\n",
    "model.fit(x_train,y_train)\n",
    "# sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "vid_pred = model.predict(x_test)\n",
    "cc = np.corrcoef(y_test,vid_pred)[0,1]\n",
    "r2 = model.score(vid_pred,y_test)\n",
    "\n",
    "\n",
    "n=4;ind=0\n",
    "# for n in range(1,len(titles)+1):\n",
    "perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "#     for ind in range(perms.shape[0]):\n",
    "x_train = np.concatenate((x_train,move_train[:,perms[ind]]),axis=1)\n",
    "x_test = np.concatenate((x_test,move_test[:,perms[ind]]),axis=1)\n",
    "\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "model = lm.RidgeCV(alphas=lambdas)\n",
    "model.fit(x_train,y_train)\n",
    "# sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "vid_predm = model.predict(x_test)\n",
    "ccm = np.corrcoef(y_test,vid_predm)[0,1]\n",
    "r2m = r2_score(vid_predm[:,:npx], y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_[:,npx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.coef_[:,-4].reshape(20,30))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.coef_[500,:npx].reshape(20,30))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_predm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(x_test[:100,100] ,label='x_test')\n",
    "ax.plot(y_test[:100,100] ,label='y_test')\n",
    "ax.plot(vid_pred[:100,100] ,label='vid_pred')\n",
    "ax.plot(vid_predm[:100,100] ,label='vid_predm')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 100\n",
    "fig,axs = plt.subplots(1,3,figsize=(30,10))\n",
    "ax = axs[0]\n",
    "ax.imshow(y_test[t].reshape(20,30))\n",
    "ax = axs[1]\n",
    "ax.imshow(y_test[t-1].reshape(20,30))\n",
    "ax = axs[2]\n",
    "ax.imshow(vid_pred[t-5].reshape(20,30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-comparative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-metadata",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-beast",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-responsibility",
   "metadata": {},
   "source": [
    "## Regression on Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_shuffle = False\n",
    "data = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=do_shuffle, do_norm=True, free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "locals().update(data)\n",
    "Y_train = np.hstack((train_th[:,np.newaxis],train_phi[:,np.newaxis],train_roll[:,np.newaxis],train_pitch[:,np.newaxis]))#, train_dth[:,np.newaxis],train_dphi[:,np.newaxis]))\n",
    "Y_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_roll[:,np.newaxis],test_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'ridgecv'\n",
    "if model_type == 'elasticnetcv':\n",
    "    model = make_pipeline(StandardScaler(), lm.ElasticNetCV()) # lm.RidgeCV(alphas=np.arange(100,10000,1000))) #  #MultiOutputRegressor(lm.Ridge(),n_jobs=-1)) \n",
    "elif model_type == 'ridgecv':\n",
    "    model = make_pipeline(StandardScaler(), lm.RidgeCV())\n",
    "\n",
    "model.fit(train_nsp, Y_train)\n",
    "pred_train = model.predict(train_nsp)\n",
    "pred_test = model.predict(test_nsp)\n",
    "train_score = model.score(train_nsp,Y_train)\n",
    "test_score = model.score(test_nsp, Y_test)\n",
    "print('Train Score:', train_score, 'Test Score:', test_score)\n",
    "# print(model['model_type'].coef_[22])\n",
    "cc = np.corrcoef(pred_test,Y_test)\n",
    "print('cc={:.02f}'.format(cc[0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Flip test and train #####\n",
    "# model2 = make_pipeline(StandardScaler(), lm.RidgeCV())\n",
    "# model2.fit(test_nsp, Y_test)\n",
    "# pred_train = model2.predict(test_nsp)\n",
    "# pred_test = model2.predict(train_nsp)\n",
    "# train_score = model2.score(test_nsp,Y_test)\n",
    "# test_score = model2.score(train_nsp, Y_train)\n",
    "# print('Train Score:', train_score, 'Test Score:', test_score)\n",
    "# print(model2['ridgecv'].coef_[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[model_type].alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeln = 3\n",
    "plt.plot(Y_test[:100,modeln])\n",
    "\n",
    "plt.plot(pred_test[:100,modeln])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "dt = 10000\n",
    "plt.plot(np.arange(t,t+dt),Y_train[t:t+dt])\n",
    "plt.plot(np.arange(t,t+dt), pred_train[t:t+dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 100\n",
    "dt = 100\n",
    "fig, axs = plt.subplots(1,figsize=(7,5))\n",
    "cc = np.corrcoef(Y_test,pred_test)[0,1]\n",
    "axs.plot(np.arange(t,t+dt)*model_dt,Y_test[t:t+dt], 'k', label='Ground Truth')\n",
    "axs.plot(np.arange(t,t+dt)*model_dt,pred_test[t:t+dt], 'r', label='Prediction')\n",
    "axs.set_title('CorrCoeff: {:.02f}'.format(cc))\n",
    "axs.set_xlabel('Time (s)')\n",
    "# axs.set_ylabel('Eye Phi Angle')\n",
    "axs.legend()\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'LinearRegressionExample_phi.png',bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(Y_train,pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(Y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test,pred_test, alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(model['elasticnetcv'].coef_)\n",
    "plt.plot(model['ridgecv'].coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-girlfriend",
   "metadata": {},
   "source": [
    "# Autocorrelation of the th, vid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter1d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(test_th, test_nsp[:,22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcorr_data = plt.xcorr(test_th, test_nsp[:,22], maxlags=100)\n",
    "lags, xscore = xcorr_data[0], xcorr_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags[np.argmax(xscore)], xscore[np.argmax(xscore)],lags[np.argmin(xscore)], xscore[np.argmin(xscore)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.acorr(train_th, maxlags=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-broadcasting",
   "metadata": {},
   "source": [
    "## Regression on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vid, test_vid, train_nsp, test_nsp, train_th, test_th, train_phi, test_phi, train_roll, test_roll, train_pitch, test_pitch, train_t, test_t, train_dth, test_dth, train_dphi, test_dphi = \\\n",
    "train_test_split(model_vid_sm, model_nsp, model_th, model_phi, model_roll, model_pitch, model_t, model_dth, model_dphi, train_size=.6, shuffle=False, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-pilot",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_vid.reshape(train_vid.shape[0],-1)#[:,10:11] # np.stack((train_roll, train_pitch),axis=1) # \n",
    "Y_test = test_vid.reshape(test_vid.shape[0],-1)#[:,10:11] # np.stack((test_roll, test_pitch),axis=1) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def multi_regression(train_nsp,Y_train,test_nsp,Y_test,idx,model_type):\n",
    "    if model_type == 'elasticnetcv':\n",
    "        model = lm.ElasticNetCV() # lm.RidgeCV(alphas=np.arange(100,10000,1000))) #  #MultiOutputRegressor(lm.Ridge(),n_jobs=-1)) \n",
    "    elif model_type == 'ridgecv':\n",
    "        model = lm.RidgeCV(alphas=np.arange(100,10000,1000))\n",
    "        \n",
    "    # MultiTaskElasticNetCV(n_jobs=-1)) # RidgeCV()# MultiTaskLassoCV(n_jobs=-1) # RidgeCV() # LinearRegression(n_jobs=-1) #\n",
    "    # register_ray()\n",
    "    # with joblib.parallel_backend('ray'):\n",
    "    model.fit(train_nsp, Y_train[:,idx])\n",
    "    pred_train = model.predict(train_nsp)\n",
    "    pred_test = model.predict(test_nsp)\n",
    "    model_coeff = model.coef_\n",
    "#     print('Train Score:', model.score(train_nsp,Y_train), 'Test Score:', model.score(test_nsp, Y_test))\n",
    "    train_score = np.corrcoef(pred_train,Y_train[:,idx])[0,1]\n",
    "    test_score = np.corrcoef(pred_test, Y_test[:,idx])[0,1]\n",
    "    alphas = model.alpha_\n",
    "    return pred_train, pred_test, train_score, test_score, model_coeff, alphas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'ridgecv'\n",
    "\n",
    "start = time.time()\n",
    "train_nsp_r = ray.put(train_nsp)\n",
    "Y_train_r = ray.put(Y_train)\n",
    "test_nsp_r = ray.put(test_nsp)\n",
    "Y_test_r = ray.put(Y_test)\n",
    "result_ids = []\n",
    "[result_ids.append(multi_regression.remote(train_nsp_r,Y_train_r,test_nsp_r,Y_test_r,idx,model_type)) for idx in range(0, train_vid.shape[-1]*train_vid.shape[-2])]\n",
    "results_p = ray.get(result_ids)\n",
    "print('MultiReg Time: ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = np.stack([results_p[i][0] for i in range(len(results_p))])\n",
    "pred_test = np.stack([results_p[i][1] for i in range(len(results_p))])\n",
    "train_scores = np.array([results_p[i][2] for i in range(len(results_p))])\n",
    "test_scores = np.array([results_p[i][3] for i in range(len(results_p))])\n",
    "model_coeff = np.array([results_p[i][4] for i in range(len(results_p))])\n",
    "alphas = np.array([results_p[i][5] for i in range(len(results_p))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pred_train.T.reshape(pred_train.shape[-1],train_vid.shape[1],train_vid.shape[2])\n",
    "pred_test = pred_test.T.reshape(pred_test.shape[-1],test_vid.shape[1],test_vid.shape[2])\n",
    "model_coeff = model_coeff.T.reshape(train_nsp.shape[-1],train_vid.shape[1],train_vid.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet_data = {\n",
    "#                 'train_scores': train_scores,\n",
    "#                 'test_scores': test_scores,\n",
    "#                 'pred_train': pred_train,\n",
    "#                 'pred_test': pred_test, }\n",
    "# ioh5.save(save_dir/'ElasticNet_data.h5',ElasticNet_data)\n",
    "\n",
    "# Ridge_data = ioh5.load(save_dir/'RidgeData.h5')\n",
    "# locals().update(ElasticNet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# t = 200\n",
    "# dt = 500\n",
    "# comb = np.concatenate((pred_train[t:t+dt,np.newaxis,:,:], train_vid[t:t+dt,np.newaxis,:,:]),axis=1)\n",
    "\n",
    "# fig = px.imshow(comb, animation_frame=0, facet_col=1, binary_string=False)\n",
    "# fig.update_layout(width=1000,\n",
    "#                   height=500,\n",
    "#                  )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-basis",
   "metadata": {},
   "source": [
    "Need to look at decoding weights and see if they resempble receptive fields?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-lucas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "suspended-scout",
   "metadata": {},
   "source": [
    "## Plotting Decoded Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torchvision\n",
    "from scipy.ndimage import uniform_filter1d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "FigPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1130 #2000\n",
    "dt = 10\n",
    "fig, ax = plt.subplots(1,10,figsize=(30,3))\n",
    "\n",
    "for n,t in enumerate(np.arange(t,t+dt)):\n",
    "    ax[n].imshow(pred_test_up[t,:,:], cmap='gray')\n",
    "    ax[n].axis('off')\n",
    "plt.suptitle('Decoding Frames')\n",
    "plt.tight_layout()\n",
    "fig.savefig(FigPath/'Decoding_Frame.png',facecolor='white', transparent=True)\n",
    "\n",
    "fig2, ax2 = plt.subplots(1,10,figsize=(30,3))\n",
    "for n,t in enumerate(np.arange(t,t+dt)):\n",
    "    ax2[n].imshow(test_vid_up[t,:,:], cmap='gray')\n",
    "    ax2[n].axis('off')\n",
    "plt.suptitle('Actual Frames')\n",
    "plt.tight_layout()\n",
    "fig2.savefig(FigPath/'Decoding_Actual_Frame.png',facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1040 #2000\n",
    "dt = 100\n",
    "im_grid = torchvision.utils.make_grid(torch.from_numpy(pred_test[t:t+dt,np.newaxis,:,:]),nrow=10,normalize=False)[0]\n",
    "im_grid2 = torchvision.utils.make_grid(torch.from_numpy(test_vid[t:t+dt,np.newaxis,:,:]),nrow=10,normalize=False)[0]\n",
    "fig, axs = plt.subplots(2,1,figsize=(20,10))\n",
    "axs[0].imshow(im_grid, cmap='gray')#.permute(1,2,0))\n",
    "axs[0].set_title('Decoding Prediction')\n",
    "axs[1].imshow(im_grid2, cmap='gray')#.permute(1,2,0))\n",
    "axs[1].set_title('Actual Frame')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'DecodedMontage_{}.png'.format(model_type),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_grid = torchvision.utils.make_grid(torch.from_numpy(model_coeff[:,np.newaxis]),nrow=10,normalize=False)[0]\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,10))\n",
    "axs.imshow(im_grid, cmap='gray')#.permute(1,2,0))\n",
    "axs.set_title('Decoding Coeff')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'DecodingWeights_{}.png'.format(model_type),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 2\n",
    "pred_test_norm = normimgs(pred_test)\n",
    "pred_test_up = np.zeros((pred_test.shape[0],sf*pred_test.shape[1],sf*pred_test.shape[2]))\n",
    "test_vid_norm = normimgs(test_vid)\n",
    "test_vid_up = np.zeros((test_vid.shape[0],sf*test_vid.shape[1],sf*test_vid.shape[2]))\n",
    "pred_train_norm = normimgs(pred_train)\n",
    "pred_train_up = np.zeros((pred_train.shape[0],sf*pred_train.shape[1],sf*pred_train.shape[2]))\n",
    "train_vid_norm = normimgs(train_vid)\n",
    "train_vid_up = np.zeros((train_vid.shape[0],sf*train_vid.shape[1],sf*train_vid.shape[2]))\n",
    "for n in range(pred_test.shape[0]):\n",
    "    pred_test_up[n] = cv2.resize(pred_test_norm[n],(sf*pred_test.shape[2],sf*pred_test.shape[1]))\n",
    "    test_vid_up[n] = cv2.resize(test_vid_norm[n],(sf*test_vid.shape[2],sf*test_vid.shape[1]))\n",
    "    pred_train_up[n] = cv2.resize(pred_train_norm[n],(sf*pred_train.shape[2],sf*pred_train.shape[1]))\n",
    "    train_vid_up[n] = cv2.resize(train_vid_norm[n],(sf*train_vid.shape[2],sf*train_vid.shape[1]))\n",
    "\n",
    "cond = 'test'\n",
    "if cond == 'train':\n",
    "    tot_samps = np.stack((pred_train_up, train_vid_up))\n",
    "else:\n",
    "    tot_samps = np.stack((pred_test_up, test_vid_up))\n",
    "tot_samps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example Frames Video\n",
    "# t = 0\n",
    "# dt = pred_test.shape[0]\n",
    "# # comb = np.concatenate((normimgs(pred_test),normimgs(test_vid)),axis=2)\n",
    "# comb = np.concatenate((pred_test_up,test_vid_up),axis=2).astype(np.uint8)\n",
    "# # comb = (comb - np.min(comb,axis=(-1,-2))[:,np.newaxis,np.newaxis])/(np.max(comb,axis=(-1,-2))-np.min(comb,axis=(-1,-2)))[:,np.newaxis,np.newaxis]\n",
    "# # comb = (comb*255).astype(np.uint8)\n",
    "\n",
    "# FPS = 10\n",
    "# out = cv2.VideoWriter(os.path.join(FigPath,'Frames_ExVid.avi'), cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), FPS, (comb.shape[-1], comb.shape[-2]),0)\n",
    "            \n",
    "# for fm in tqdm(range(comb.shape[0])):\n",
    "#     out.write(comb[fm])\n",
    "# out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### Grab data of longest continuous sequence ######\n",
    "# def func1(a,b):\n",
    "#     # \"Enclose\" mask with sentients to catch shifts later on\n",
    "#     mask = np.r_[False,a,False]\n",
    "\n",
    "#     # Get the shifting indices\n",
    "#     idx = np.flatnonzero(mask[1:] != mask[:-1])\n",
    "\n",
    "#     s0,s1 = idx[::2], idx[1::2]\n",
    "#     idx_b = np.r_[0,(s1-s0).cumsum()]\n",
    "#     out = []\n",
    "#     for (i,j,k,l) in zip(s0,s1-1,idx_b[:-1],idx_b[1:]):\n",
    "#         out.append(((i, j), b[k:l]))\n",
    "#     return out\n",
    "\n",
    "# train_idxs,test_idxs = train_test_split(good_idxs,train_size=.6,random_state=0)\n",
    "\n",
    "# out = func1(test_idxs,np.arange(test_idxs.shape[0]))\n",
    "\n",
    "# max_seqn = 0\n",
    "# for n in range(len(out)):\n",
    "#     if len(out[n][1]) > max_seqn:\n",
    "#         max_seq = np.arange(out[n][0][0],out[n][0][1])\n",
    "#         max_seqn = len(out[n][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = 3\n",
    "tot_samps2 = uniform_filter1d(tot_samps,win_size,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 500\n",
    "dt = 100\n",
    "plt.plot(tot_samps2[0,t:t+dt,5,10])\n",
    "plt.plot(tot_samps[1,t:t+dt,5,10])\n",
    "plt.plot(tot_samps2[1,t:t+dt,5,10])\n",
    "plt.legend(['Pred','Actual','Actual_smoothed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation, PillowWriter, FFMpegWriter\n",
    "from matplotlib import colors\n",
    "def init():\n",
    "    for n in range(2):\n",
    "        axs[n].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def update(t):\n",
    "    for n in range(2):\n",
    "        ims[n].set_data(tot_samps2[n,t])\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-growth",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = 0# max_seq[0]\n",
    "lat_dims = 2\n",
    "x,y = [],[]\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,4))   #8,16,figsize=(50,30)  \n",
    "axs = axs.flatten()\n",
    "ims = []\n",
    "titles = ['Pred','Actual']\n",
    "for n in range(2):\n",
    "    ims.append(axs[n].imshow(tot_samps2[n,t],cmap='gray',norm=colors.Normalize()))\n",
    "    axs[n].axis('off')\n",
    "    axs[n].set_title('{}'.format(titles[n]))\n",
    "plt.tight_layout()\n",
    "# fig.savefig(os.path.join(FigurePath,'testimg.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-conservation",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# writervideo = PillowWriter(fps=60)  \n",
    "ani = FuncAnimation(fig, update, tqdm(range(tot_samps2.shape[1])), init_func=init)  #range(tot_samps.shape[1])\n",
    "plt.show()\n",
    "vpath = check_path(FigPath,'version_{:d}'.format(0))\n",
    "vname =  'DecodedVideo_{}_upsampled{:d}_smoothed{:d}_{}.mp4'.format(model_type,sf, win_size,cond)\n",
    "writervideo = FFMpegWriter(fps=10) \n",
    "ani.save(os.path.join(vpath,vname), writer=writervideo)\n",
    "print('DONE!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = train_scores.reshape((train_vid.shape[-2],train_vid.shape[-1]))\n",
    "test_scores = test_scores.reshape((test_vid.shape[-2],test_vid.shape[-1]))\n",
    "fig, axs = plt.subplots(2,1,figsize=(10,10))\n",
    "im1 = axs[0].imshow(train_scores, vmin=0, vmax=.55)\n",
    "axs[0].set_title('Train Correlation Map')\n",
    "add_colorbar(im1)\n",
    "im2 = axs[1].imshow(test_scores, vmin=0, vmax=.55)\n",
    "axs[1].set_title('Test Correlation Map')\n",
    "add_colorbar(im2)\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'DecodingScores_{}.png'.format(model_type),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1040\n",
    "dt = 20\n",
    "comb = np.concatenate((np.concatenate((pred_test[t:t+dt,:,:], test_vid[t:t+dt,:,:]),axis=1)),axis=1)\n",
    "fig, ax = plt.subplots(1,figsize=(25,20))\n",
    "ax.imshow(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-commerce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "judicial-arizona",
   "metadata": {},
   "source": [
    "Decoding wieghts of visual vs, decoding weights of movement and dot product overlap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-finnish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "entitled-vector",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_roll = train_roll/np.max(train_roll)\n",
    "# train_roll -=train_roll[0]\n",
    "# train_pitch = train_pitch/np.max(train_pitch)\n",
    "# train_pitch -=train_pitch[0]\n",
    "# test_roll = test_roll/np.max(test_roll)\n",
    "# test_roll -=test_roll[0]\n",
    "# test_pitch = test_pitch/np.max(test_pitch)\n",
    "# test_pitch -=test_pitch[0]\n",
    "\n",
    "# Y_train = torch.from_numpy(np.stack((train_roll, train_pitch),axis=1)).float()\n",
    "# Y_test  = torch.from_numpy(np.stack((test_roll, test_pitch),axis=1)).float()\n",
    "\n",
    "Y_train = torch.from_numpy(train_roll[:,np.newaxis]).float() #train_vid.reshape(train_vid.shape[0],-1)).float()#[:,10:11] # np.stack((train_roll, train_pitch),axis=1) # \n",
    "Y_test = torch.from_numpy(test_roll[:,np.newaxis]).float() #test_vid.reshape(test_vid.shape[0],-1)).float()#[:,10:11] # np.stack((test_roll, test_pitch),axis=1) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodingDataset(Dataset):\n",
    "    def __init__(self, data, output, N_fm, transform=None):\n",
    "        \n",
    "        self.data = data\n",
    "        self.output = output\n",
    "        self.transform = transform\n",
    "        self.N_fm = N_fm\n",
    "\n",
    "    def __len__(self):\n",
    "        return(self.data.shape[0])\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if idx < self.N_fm:\n",
    "            idx = self.N_fm\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        sample = torch.from_numpy(self.data[idx-self.N_fm:idx]).float()\n",
    "        gt = torch.from_numpy(self.output[idx-self.N_fm:idx,:]).float()\n",
    "        return sample.view(-1), gt.view(-1)\n",
    "    \n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "    \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_fm=1\n",
    "batch_size = 1024\n",
    "in_neurons = train_nsp.shape[1]*N_fm\n",
    "out_neurons = 2048\n",
    "out_dims = Y_train.shape[-1]*N_fm\n",
    "NEpochs = 500\n",
    "# train_dataset = DecodingDataset(train_nsp, np.stack((train_roll, train_pitch),axis=1), N_fm=N_fm)\n",
    "# test_dataset = DecodingDataset(test_nsp, np.stack((test_roll, test_pitch),axis=1), N_fm=N_fm)\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_nsp).float(),Y_train)\n",
    "test_dataset  = TensorDataset(torch.from_numpy(test_nsp).float(),Y_test)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(in_neurons,out_neurons),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(out_neurons,out_neurons),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(out_neurons,out_dims)).to(device)\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=.0001)\n",
    "criteria = nn.MSELoss()\n",
    "early_stopping = EarlyStopping(path=save_dir/'checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_loss = []\n",
    "test_tot_loss = []\n",
    "for epoch in tqdm(range(NEpochs)):\n",
    "    epoch_loss = []\n",
    "    for batch, y in train_dataloader:\n",
    "        pred = model(batch.to(device))\n",
    "        loss = criteria(pred.to(device),y.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    tot_loss.append(np.mean(epoch_loss))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_epoch_loss = []\n",
    "        for batch, y in test_dataloader:\n",
    "            pred = model(batch.to(device))\n",
    "            loss = criteria(pred.to(device),y.to(device))\n",
    "            test_epoch_loss.append(loss.item())\n",
    "        test_tot_loss.append(np.mean(test_epoch_loss))\n",
    "    early_stopping(np.mean(test_epoch_loss), model)\n",
    "    if early_stopping.early_stop == True:\n",
    "        print('Stopped Early!')\n",
    "        break\n",
    "    print('Epoch:', epoch, 'Epoch_Loss_Avg: ', np.mean(epoch_loss), 'Test_Epoch_Loss_Avg: ', np.mean(test_epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = np.arange(0,1000)\n",
    "fig, ax = plt.subplots(2,1,figsize=(20,10))\n",
    "ax[0].plot(Y_train[wind,0],'b-', label='roll')\n",
    "ax[0].plot(pred[wind,0].cpu().detach(),'r-', label='pred_roll')\n",
    "ax[1].plot(Y_train[wind,1],'b-', label='pitch')\n",
    "ax[1].plot(pred[wind,1].cpu().detach(),'r-', label='pred_pitch')\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predt = []\n",
    "    for batch, y in test_dataloader:\n",
    "        pred = model(batch.to(device))\n",
    "        predt.append(pred.cpu().numpy())\n",
    "    predt = np.concatenate(predt,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = np.arange(0,1000)\n",
    "fig, ax = plt.subplots(2,1,figsize=(20,10))\n",
    "ax[0].plot(Y_test[wind,0],'b-', label='roll')\n",
    "ax[0].plot(predt[wind,0],'r-', label='pred_roll')\n",
    "ax[1].plot(Y_test[wind,1],'b-', label='pitch')\n",
    "ax[1].plot(predt[wind,1],'r-', label='pred_pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-adobe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
