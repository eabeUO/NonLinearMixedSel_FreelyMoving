{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "widespread-cleaners",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aggregate-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "import sys \n",
    "import yaml \n",
    "import glob\n",
    "import h5py \n",
    "import ray\n",
    "import logging \n",
    "import json\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import xarray as xr\n",
    "import scipy.linalg as linalg\n",
    "import scipy.sparse as sparse\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize_scalar,minimize\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import shift as imshift\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model as lm \n",
    "from scipy.stats import binned_statistic\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import r2_score, mean_poisson_deviance\n",
    "from pyglmnet import GLMCV, GLM\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sys.path.append('/home/seuss/Research/MyRepos/NonLinearMixedSel_FreelyMoving/')\n",
    "sys.path.append(str(Path('.').absolute()))\n",
    "from utils import *\n",
    "import io_dict_to_hdf5 as ioh5\n",
    "from format_data import *\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    logging_level=logging.ERROR,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beneficial-sleeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_dir: /home/seuss/Research/SensoryMotorPred_Data/data/070921/J553RT/fm1\n",
      "data_dir: /home/seuss/Goeppert/freely_moving_ephys/ephys_recordings/070921/J553RT/fm1\n",
      "FigPath: /home/seuss/Research/SensoryMotorPred_Data/Figures/Encoding/070921/J553RT/fm1\n"
     ]
    }
   ],
   "source": [
    "free_move = True\n",
    "if free_move:\n",
    "    stim_type = 'fm1'\n",
    "else:\n",
    "    stim_type = 'hf1_wn' # 'fm1' # \n",
    "# 012821/EE8P6LT\n",
    "# 128: 070921/J553RT\n",
    "date_ani = '070921/J553RT' #'062921/G6HCK1ALTRN'\n",
    "data_dir  = Path('~/Goeppert/freely_moving_ephys/ephys_recordings/').expanduser() / date_ani / stim_type\n",
    "save_dir  = check_path(Path('~/Research/SensoryMotorPred_Data/data/').expanduser() / date_ani, stim_type)\n",
    "FigPath = check_path(Path('~/Research/SensoryMotorPred_Data').expanduser(),'Figures/Encoding')\n",
    "FigPath = check_path(FigPath/date_ani, stim_type)\n",
    "FigPath_SFN = check_path(FigPath,'SFN')\n",
    "\n",
    "print('save_dir:',save_dir)\n",
    "print('data_dir:',data_dir)\n",
    "print('FigPath:', FigPath)\n",
    "# with open(save_dir / 'file_dict.json','r') as fp:\n",
    "#     file_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "executed-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {'cell': 0,\n",
    "            'drop_slow_frames': True,\n",
    "            'ephys': list(data_dir.glob('*ephys_merge.json'))[0].as_posix(),\n",
    "            'ephys_bin': list(data_dir.glob('*Ephys.bin'))[0].as_posix(),\n",
    "            'eye': list(data_dir.glob('*REYE.nc'))[0].as_posix(),\n",
    "            'imu': list(data_dir.glob('*imu.nc'))[0].as_posix() if stim_type=='fm1' else None,\n",
    "            'mapping_json': '/home/seuss/Research/Github/FreelyMovingEphys/probes/channel_maps.json',\n",
    "            'mp4': True,\n",
    "            'name': '01221_EE8P6LT_control_Rig2_'+stim_type, #070921_J553RT\n",
    "            'probe_name': 'DB_P128-6',\n",
    "            'save': data_dir.as_posix(),\n",
    "            'speed': list(data_dir.glob('*speed.nc'))[0].as_posix() if stim_type=='hf1_wn' else None,\n",
    "            'stim_type': 'light',\n",
    "            'top': list(data_dir.glob('*TOP1.nc'))[0].as_posix() if stim_type=='fm1' else None,\n",
    "            'world': list(data_dir.glob('*world.nc'))[0].as_posix(),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interstate-shelf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Loading Aligned Data\n",
      "TRAIN: 15628 TEST: 6698\n",
      "[-2 -1  0  1  2] [-100.  -50.    0.   50.  100.]\n"
     ]
    }
   ],
   "source": [
    "model_dt = .05\n",
    "do_shuffle=False\n",
    "do_norm = False\n",
    "data,train_idx,test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=do_shuffle, do_norm=do_norm,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "locals().update(data)\n",
    "\n",
    "lag_list = np.array([-2,-1,0,1,2]) #np.array([-1,0,1,2,3]) #,np.arange(minlag,maxlag,np.floor((maxlag-minlag)/nt_glm_lag).astype(int))\n",
    "nt_glm_lag = len(lag_list)\n",
    "print(lag_list,1000*lag_list*model_dt)\n",
    "do_shuffle=False\n",
    "model_type = 'Pytorch'\n",
    "ncells=model_nsp.shape[-1]\n",
    "bin_length=40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "breathing-interview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [0.]\n",
      "Done Loading Aligned Data\n",
      "TRAIN: 15628 TEST: 6698\n"
     ]
    }
   ],
   "source": [
    "lag_list = np.array([0]) #-2,-1,0,1,2]) \n",
    "nt_glm_lag = len(lag_list)\n",
    "print(lag_list,1000*lag_list*model_dt)\n",
    "do_shuffle = False\n",
    "model_type = 'Pytorch'\n",
    "\n",
    "# for do_shuffle in [False,True]:\n",
    "# Load Data\n",
    "data, train_idx, test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=do_shuffle, do_norm=True,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "locals().update(data)\n",
    "\n",
    "# Initialize movement combinations\n",
    "titles = np.array(['Theta','Phi','Roll','Pitch']) # 'dg_p','dg_n' 'roll','pitch'\n",
    "titles_all = []\n",
    "for n in range(1,len(titles)+1):\n",
    "    perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "    for ind in range(perms.shape[0]):\n",
    "        titles_all.append('_'.join([t for t in titles[perms[ind]]]))\n",
    "if free_move:\n",
    "    move_train = np.hstack((train_th[:,np.newaxis],train_phi[:,np.newaxis],train_roll[:,np.newaxis],train_pitch[:,np.newaxis]))\n",
    "    move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_roll[:,np.newaxis],test_pitch[:,np.newaxis])) \n",
    "    model_move = np.hstack((model_th[:,np.newaxis],model_phi[:,np.newaxis],model_roll[:,np.newaxis],model_pitch[:,np.newaxis]))\n",
    "    model_move = model_move - np.mean(model_move,axis=0)\n",
    "    move_test = move_test - np.mean(move_test,axis=0)\n",
    "    move_train = move_train - np.mean(move_train,axis=0)\n",
    "\n",
    "##### Start GLM Parallel Processing #####\n",
    "nks = np.shape(train_vid)[1:]; nk = nks[0]*nks[1]*nt_glm_lag\n",
    "n=4; ind=0\n",
    "perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "\n",
    "##### Start GLM Parallel Processing #####\n",
    "# Reshape data (video) into (T*n)xN array\n",
    "rolled_vid = np.hstack([np.roll(model_vid_sm, nframes, axis=0) for nframes in lag_list]) # nt_glm_lag\n",
    "rolled_vid_flat = rolled_vid.reshape(rolled_vid.shape[0],-1)\n",
    "x_train = rolled_vid[train_idx].reshape(len(train_idx),-1)\n",
    "x_test = rolled_vid[test_idx].reshape(len(test_idx),-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in Nepochs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15628, 600]), (15628, 128))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoding_Network(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, hidden_layers=2, device='cuda'):\n",
    "        super(Decoding_Network, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "        self.relu = nn.ReLU()\n",
    "        self.input_layer = nn.Linear(self.in_features,self.out_features)\n",
    "        self.layers = []\n",
    "        for n in range(hidden_layers):\n",
    "            self.layers.append(nn.Linear(self.hidden_features,hidden_features))\n",
    "        self.out_layer = nn.Linear(self.hidden_features,self.out_features)\n",
    "\n",
    "    def forward(self, inputs, move_input=None):\n",
    "        x, y = inputs.shape\n",
    "        if y != self.in_features:\n",
    "            print(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features')\n",
    "            return 0\n",
    "        output = inputs.matmul(self.weight.t())\n",
    "        if move_input != None:\n",
    "            output = output + move_input.matmul(self.move_weights.t())\n",
    "        if self.bias is not None:\n",
    "            output = output + self.bias\n",
    "        ret = torch.log1p(torch.exp(output))\n",
    "        return ret\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )\n",
    "    \n",
    "    def loss(self,Yhat, Y): \n",
    "        if self.move_features != None:\n",
    "#             l2_reg = self.lam*(torch.linalg.norm(self.weight[:,:-self.move_features],axis=1,ord=2))\n",
    "#             l1_reg = self.alpha*(torch.linalg.norm(self.weight[:,:-self.move_features],axis=1,ord=1))\n",
    "#             l2_regm = self.lam_m*(torch.linalg.norm(self.weight[:,-self.move_features:],axis=1,ord=2))\n",
    "            if self.reg_alph != None:\n",
    "                l1_regm = self.alpha_m*(torch.linalg.norm(self.weight[:,-self.move_features:],axis=1,ord=1))\n",
    "                l1_reg = self.alpha*(torch.linalg.norm(self.weight,axis=1,ord=1))\n",
    "            else: \n",
    "                l1_regm = 0\n",
    "                l1_reg = 0\n",
    "            loss_vec = torch.mean(Yhat-Y*torch.log(Yhat),axis=0) + l1_reg + l1_regm\n",
    "        else:\n",
    "            if self.reg_lam != None:\n",
    "                if self.reg_alph != None:\n",
    "                    l2_reg = self.lam*(torch.linalg.norm(self.weight,axis=1,ord=2))\n",
    "                    l1_reg = self.alpha*(torch.linalg.norm(self.weight,axis=1,ord=1))\n",
    "                    loss_vec = torch.mean(Yhat-Y*torch.log(Yhat),axis=0) + l2_reg + l1_reg\n",
    "                else:\n",
    "                    l2_reg = self.lam*(torch.linalg.norm(self.weight,axis=1,ord=2)) \n",
    "                    loss_vec = torch.mean(Yhat-Y*torch.log(Yhat),axis=0) + l2_reg\n",
    "            else:\n",
    "                if self.reg_alph != None:\n",
    "                    l1_reg = self.alpha*(torch.linalg.norm(self.weight,axis=1,ord=1))\n",
    "                    loss_vec = torch.mean(Yhat-Y*torch.log(Yhat),axis=0) + l1_reg\n",
    "                else:\n",
    "                    loss_vec = torch.mean(Yhat-Y*torch.log(Yhat),axis=0)\n",
    "        return loss_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tr = TensorDataset(torch.from_numpy(x_train).float(), torch.from_numpy(train_nsp).float())\n",
    "dataloader_tr = DataLoader(dataset_tr,batch_size=x_train.shape[0])\n",
    "dataset_te = TensorDataset(torch.from_numpy(x_test).float(), torch.from_numpy(test_nsp).float())\n",
    "dataloader_te = DataLoader(dataset_te,batch_size=x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 1, move_features: None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MovModel = 1\n",
    "# Reshape data (video) into (T*n)xN array\n",
    "if MovModel == 0:\n",
    "    mx_train = move_train[:,perms[ind]]\n",
    "    mx_test = move_test[:,perms[ind]]\n",
    "    xtr = torch.from_numpy(mx_train.astype(np.float32)).to(device)\n",
    "    xte = torch.from_numpy(mx_test.astype(np.float32)).to(device)    \n",
    "    move_features = None # mx_train.shape[-1]\n",
    "    nk = 0\n",
    "    xtrm = None\n",
    "    xtem = None\n",
    "elif MovModel == 1:\n",
    "    x_train_m1 = (rolled_vid[train_idx].reshape(len(train_idx),-1)).astype(np.float32)\n",
    "    x_test_m1 = (rolled_vid[test_idx].reshape(len(test_idx),-1)).astype(np.float32)\n",
    "    xtr = torch.from_numpy(x_train_m1).to(device)\n",
    "    xte = torch.from_numpy(x_test_m1).to(device)\n",
    "    move_features = None\n",
    "    xtrm = None\n",
    "    xtem = None\n",
    "elif MovModel == 2:\n",
    "    xtrm = torch.from_numpy(move_train[:,perms[ind]].astype(np.float32)).to(device)\n",
    "    xtem = torch.from_numpy(move_test[:,perms[ind]].astype(np.float32)).to(device)\n",
    "    xtr = torch.from_numpy(x_train.astype(np.float32)).to(device)\n",
    "    xte = torch.from_numpy(x_test.astype(np.float32)).to(device)\n",
    "    move_features = xtrm.shape[-1]\n",
    "elif MovModel == 3:\n",
    "    x_train_m3 = np.hstack((np.hstack([x_train*move_train[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_train[:,perms[ind]]))\n",
    "    x_test_m3 = np.hstack((np.hstack([x_test*move_test[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_test[:,perms[ind]]))\n",
    "    xtr = torch.from_numpy(x_train.astype(np.float32)).to(device)\n",
    "    xte = torch.from_numpy(x_test.astype(np.float32)).to(device)\n",
    "    xtrm = torch.from_numpy(x_train_m3.astype(np.float32)).to(device)\n",
    "    xtem = torch.from_numpy(x_test_m3.astype(np.float32)).to(device)\n",
    "    move_features = x_train_m3.shape[-1]\n",
    "\n",
    "    \n",
    "ytr = torch.from_numpy(train_nsp.astype(np.float32)).to(device)\n",
    "yte = torch.from_numpy(test_nsp.astype(np.float32)).to(device)\n",
    "input_size = xtr.shape[1]\n",
    "output_size = ytr.shape[1]\n",
    "print('Model: {}, move_features: {}'.format(MovModel, move_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-renewal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486147bb0ec644e88d20aa0d304fcff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d99981cedc44a6c8bb2c0712a52d42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLM:  513.058262348175\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# lossfn = torch.nn.PoissonNLLLoss(log_input=True,reduction='mean')\n",
    "\n",
    "Nbatches = 20000\n",
    "if move_features != None:\n",
    "    reg_params = np.zeros((Nbatches,output_size,4))\n",
    "    reg_titles = ['lambda','lambda_m','alpha','alpha_m']\n",
    "else:\n",
    "    reg_params = np.zeros((Nbatches,output_size,2))\n",
    "    reg_titles = ['lambda','alpha']\n",
    "\n",
    "\n",
    "if MovModel == 0:\n",
    "    sta_init = None\n",
    "    lambdas = [0]#(2**(np.arange(0,10)))\n",
    "    nlam = len(lambdas)\n",
    "    alphas = [0]#np.array([.005,.01,.02]) #np.arange(.01,.5,.05)\n",
    "    nalph = len(alphas)\n",
    "    w_move_traces_all = np.zeros((nalph, nlam, Nbatches, output_size, input_size))\n",
    "elif MovModel == 1:\n",
    "    lambdas = (2**(np.arange(0,10)))/100\n",
    "    nlam = len(lambdas)\n",
    "    alphas = np.array([.0075]) #np.arange(.01,.5,.05)\n",
    "    nalph = len(alphas)\n",
    "    sta_init = torch.from_numpy(((rolled_vid_flat.T@model_nsp)/(10*np.sum(model_nsp,axis=0))).T.astype(np.float32))\n",
    "elif MovModel == 2:\n",
    "    lambdas = (2**(np.arange(0,10)))/100\n",
    "    lambdas_m = (2**(np.arange(0, 10)))/10\n",
    "    nlam = len(lambdas)\n",
    "    alphas = np.array([.0075,]) #np.arange(.01,.5,.05) .005,.01,.02\n",
    "    nalph = len(alphas)\n",
    "    sta_init = torch.from_numpy(((rolled_vid_flat.T@model_nsp)/(10*np.sum(model_nsp,axis=0))).T.astype(np.float32))\n",
    "    w_move_cv = np.zeros((nalph,nlam,output_size,move_features))\n",
    "    w_move_traces_all = np.zeros((nalph, nlam, Nbatches, output_size, move_features))\n",
    "else:\n",
    "    lambdas = (2**(np.arange(0, 10)))\n",
    "    lambdas_m = (2**(np.arange(0, 10)))\n",
    "    nlam = len(lambdas)\n",
    "    alphas = np.array([.01])  # np.arange(.01,.5,.05) .005,.01,.02\n",
    "    nalph = len(alphas)\n",
    "    sta_init = torch.from_numpy(((rolled_vid_flat.T@model_nsp)/(10*np.sum(model_nsp, axis=0))).T.astype(np.float32))\n",
    "    w_move_cv = np.zeros((nalph, nlam, output_size, move_features), dtype=np.float32)\n",
    "    # w_move_traces_all = np.zeros((nalph, nlam, Nbatches, output_size, move_features),dtype=np.float32)\n",
    "\n",
    "#     sta_init = torch.from_numpy(np.hstack((((rolled_vid_flat.T@model_nsp)/(10*np.sum(model_nsp,axis=0))).T,np.zeros((output_size,move_features)))).astype(np.float32))\n",
    "meanbias = torch.log(torch.exp(torch.mean(torch.tensor(model_nsp,dtype=torch.float32),axis=0)) - 1)\n",
    "\n",
    "msetrain = np.zeros((nalph,nlam,output_size))\n",
    "msetest = np.zeros((nalph,nlam,output_size))\n",
    "pred_cv = np.zeros((x_test.shape[0],nalph,nlam,output_size),dtype=np.float32)\n",
    "w_cv = np.zeros((x_train.shape[-1],nalph,nlam,output_size),dtype=np.float32)\n",
    "bias_cv = np.zeros((nalph,nlam,output_size),dtype=np.float32)\n",
    "tloss_trace_all = np.zeros((nalph, nlam, Nbatches, output_size),dtype=np.float32)\n",
    "vloss_trace_all = np.zeros((nalph, nlam, Nbatches, output_size),dtype=np.float32)\n",
    "bias_traces_all = np.zeros((nalph, nlam, Nbatches, output_size),dtype=np.float32)\n",
    "\n",
    "lr_w = [1e-6, 1e-4]\n",
    "lr_b = [1e-5, 5e-3]\n",
    "lr_m = [1e-5, 1e-3]\n",
    "start = time.time()\n",
    "for a, reg_alph in enumerate(tqdm(alphas)):\n",
    "    for l, reg_lam in enumerate(tqdm(lambdas)):\n",
    "#         params = add_weight_decay(l1,lambdas[l])\n",
    "#         optimizer = optim.ASGD(params=[{'params': [l1.weight],'lr':5e-5,'weight_decay':lambdas[l]}, {'params': [l1.bias],'lr':1e-3}], lr=5e-5) #'weight_decay':lambdas[l]\n",
    "        if MovModel == 0: \n",
    "            l1 = PoissonGLM_VM_staticreg(input_size,output_size,reg_lam=None,reg_alph=None,move_features=move_features,meanfr=meanbias,init_sta=sta_init,device=device).to(device)\n",
    "            optimizer = optim.ASGD(params=[{'params': [l1.weight],'lr': 1e-3,},\n",
    "                                           {'params': [l1.bias],'lr':lr_b[1]},], lr=5e-5) #\n",
    "            scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=[lr_m[0],lr_b[0]], max_lr=[lr_m[1],lr_b[1]], cycle_momentum=False)\n",
    "        elif MovModel == 1:\n",
    "            l1 = PoissonGLM_VM_staticreg(input_size,output_size,reg_lam=None,reg_alph=reg_alph,move_features=move_features,meanfr=meanbias,init_sta=sta_init,device=device).to(device)\n",
    "            optimizer = optim.ASGD(params=[{'params': [l1.weight],'lr':lr_w[1],'weight_decay':lambdas[l]},\n",
    "                                           {'params': [l1.bias],'lr':lr_b[1]},], lr=5e-5) #\n",
    "            scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=[lr_w[0],lr_b[0]], max_lr=[lr_w[1],lr_b[1]], cycle_momentum=False)\n",
    "        else:\n",
    "            l1 = PoissonGLM_VM_staticreg(input_size,output_size,reg_lam=None,reg_alph=reg_alph,move_features=move_features,meanfr=meanbias,init_sta=sta_init,device=device).to(device)\n",
    "            optimizer = optim.ASGD(params=[{'params': [l1.weight],'lr':lr_w[1],'weight_decay':lambdas[l]},\n",
    "                                           {'params': [l1.bias],'lr':lr_b[1]},\n",
    "                                           {'params': [l1.move_weights],'lr':1e-3, 'weight_decay': lambdas_m[l]}], lr=5e-5) #\n",
    "            scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=[lr_w[0],lr_b[0],lr_m[0]], max_lr=[lr_w[1],lr_b[1],lr_m[1]], cycle_momentum=False)\n",
    "#         scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=[1e-6,1e-5], max_lr=[1e-4,5e-3], cycle_momentum=False)\n",
    "        early_stopping = EarlyStopping(patience=1000,min_delta=.005)\n",
    "\n",
    "        vloss_trace = np.zeros((Nbatches,output_size),dtype=np.float32)      \n",
    "        tloss_trace = np.zeros((Nbatches,output_size),dtype=np.float32)\n",
    "        for batchn in np.arange(Nbatches):\n",
    "            out = l1(xtr,xtrm)\n",
    "            loss = l1.loss(out,ytr)\n",
    "            pred = l1(xte,xtem)\n",
    "            val_loss = l1.loss(pred,yte)\n",
    "            vloss_trace[batchn] = val_loss.clone().cpu().detach().numpy()\n",
    "            tloss_trace[batchn] = loss.clone().cpu().detach().numpy()\n",
    "            bias_traces_all[a,l,batchn] = l1.bias.clone().cpu().detach().numpy()\n",
    "            # if MovModel == 0:\n",
    "            #     w_move_traces_all[a,l,batchn] = l1.weight.clone().cpu().detach().numpy()  # [:,(nk):]\n",
    "            # elif MovModel != 1:\n",
    "            #     w_move_traces_all[a,l,batchn] = l1.move_weights.clone().cpu().detach().numpy()  # [:,(nk):]\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(torch.ones_like(loss))\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            #     lam_grad[batchn]= l1.lam.grad.detach().cpu().numpy()\n",
    "            early_stopping(np.mean(val_loss.clone().cpu().detach().numpy()))\n",
    "#             if early_stopping.early_stop:\n",
    "#                 break\n",
    "        tloss_trace_all[a,l] = tloss_trace\n",
    "        vloss_trace_all[a,l] = vloss_trace\n",
    "        bias_cv[a,l] = l1.bias.clone().cpu().detach().numpy()\n",
    "        if MovModel != 0:\n",
    "            w_cv[:,a,l] = l1.weight.clone().cpu().detach().numpy().T #[:,:(nk)]\n",
    "        if MovModel == 0: \n",
    "            w_move_cv[a,l] = l1.weight.clone().cpu().detach().numpy()#[:,(nk):]\n",
    "        elif MovModel != 1:\n",
    "            w_move_cv[a,l] = l1.move_weights.clone().cpu().detach().numpy()#[:,(nk):]\n",
    "        pred =  l1(xte,xtem)\n",
    "        msetest[a,l] = torch.mean(pred-yte*torch.log(pred),axis=0).cpu().detach().numpy()\n",
    "        pred_cv[:,a,l] = pred.detach().cpu().numpy().squeeze()\n",
    "  \n",
    "print('GLM: ', time.time()-start)\n",
    "# pred_all = l1(xte).cpu().detach().numpy()\n",
    "if MovModel != 0:\n",
    "    w_cv2 = w_cv.T.reshape((output_size,nlam,nalph,nt_glm_lag,)+nks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "malph,mlam,cellnum  = np.where(msetest==np.nanmin(msetest,axis=(0,1), keepdims=True))\n",
    "cellnum, m_cinds = np.unique(cellnum,return_index=True)\n",
    "malph = malph[m_cinds]\n",
    "mlam = mlam[m_cinds]\n",
    "sortinds = cellnum.argsort()\n",
    "cellnum = cellnum[sortinds]\n",
    "malph = malph[sortinds]\n",
    "mlam = mlam[sortinds]\n",
    "sta_all = w_cv[:,malph,mlam,cellnum].T.reshape((output_size,nt_glm_lag,)+nks)\n",
    "pred_all = pred_cv[:,malph,mlam,cellnum]\n",
    "bias_all = bias_cv[malph,mlam,cellnum]\n",
    "tloss_trace_all2 = tloss_trace_all[malph,mlam,:,cellnum]\n",
    "vloss_trace_all2 = vloss_trace_all[malph,mlam,:,cellnum]\n",
    "# w_move_traces = w_move_traces_all[malph, mlam, :, cellnum]\n",
    "bias_traces = bias_traces_all[malph, mlam, :, cellnum]\n",
    "if MovModel != 1:\n",
    "    w_move = w_move_cv[malph,mlam,cellnum]\n",
    "\n",
    "bin_length=40\n",
    "r2_all = np.zeros((output_size))\n",
    "for celln in range(output_size):\n",
    "    sp_smooth = ((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    pred_smooth = ((np.convolve(pred_all[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    r2_all[celln] = (np.corrcoef(sp_smooth,pred_smooth)[0,1])**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 9, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 5, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-optimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/seuss/Research/SensoryMotorPred_Data/data/070921/J553RT/fm1/GLM_Pytorch_Data_VisMov_dt050_T05_MovModel1.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if MovModel == 0:\n",
    "    GLM_Data = {'r2_all': r2_all,\n",
    "                'test_nsp': test_nsp,\n",
    "                'pred_all': pred_all,\n",
    "                'bias_all': bias_all, \n",
    "                'tloss_trace_all':tloss_trace_all2,\n",
    "                'vloss_trace_all':vloss_trace_all2,\n",
    "                'w_move': w_move}\n",
    "elif MovModel == 1:\n",
    "    GLM_Data = {'r2_all': r2_all,\n",
    "                'sta_all': sta_all,\n",
    "                'test_nsp': test_nsp,\n",
    "                'pred_all': pred_all,\n",
    "                'bias_all': bias_all,\n",
    "                'tloss_trace_all':tloss_trace_all2,\n",
    "                'vloss_trace_all':vloss_trace_all2,\n",
    "               }\n",
    "else:\n",
    "    GLM_Data = {'r2_all': r2_all,\n",
    "                'sta_all': sta_all,\n",
    "                'test_nsp': test_nsp,\n",
    "                'pred_all': pred_all,\n",
    "                'bias_all': bias_all,\n",
    "                'tloss_trace_all':tloss_trace_all2,\n",
    "                'vloss_trace_all':vloss_trace_all2,\n",
    "                'w_move': w_move}\n",
    "\n",
    "if do_shuffle:\n",
    "    save_datafile = save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}_shuffled.h5'.format(model_type,int(model_dt*1000), nt_glm_lag, MovModel)\n",
    "else:\n",
    "    save_datafile = save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag, MovModel)\n",
    "ioh5.save(save_datafile, GLM_Data)\n",
    "print(save_datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae2df1b5b2cc9cafc9aad66187e6d6dd9c60927ae7fe28644cf330a9c23b714e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
