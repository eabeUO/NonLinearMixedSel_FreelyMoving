{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "widespread-cleaners",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "import sys \n",
    "import yaml \n",
    "import glob\n",
    "import h5py \n",
    "import ray\n",
    "import logging \n",
    "import json\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "# import io_dict_to_hdf5 as ioh5\n",
    "import xarray as xr\n",
    "import scipy.linalg as linalg\n",
    "import scipy.sparse as sparse\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize_scalar,minimize\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import shift as imshift\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model as lm \n",
    "from scipy.stats import binned_statistic\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import r2_score, mean_poisson_deviance\n",
    "from pyglmnet import GLMCV, GLM\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sys.path.append('/home/seuss/Research/MyRepos/NonLinearMixedSel_FreelyMoving/')\n",
    "sys.path.append(str(Path('.').absolute()))\n",
    "from utils import *\n",
    "import io_dict_to_hdf5 as ioh5\n",
    "from format_data import load_ephys_data_aligned\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    logging_level=logging.ERROR,\n",
    ")\n",
    "# print(f'Dashboard URL: http://{ray.get_dashboard_url()}')\n",
    "# print('Dashboard URL: http://localhost:{}'.format(ray.get_dashboard_url().split(':')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-growth",
   "metadata": {},
   "source": [
    "# Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test(file_dict, save_dir, model_dt=.1, frac=.1, train_size=.7, do_shuffle=False, do_norm=False, free_move=True, has_imu=True, has_mouse=False,):\n",
    "    ##### Load in preprocessed data #####\n",
    "    data = load_ephys_data_aligned(file_dict, save_dir, model_dt=model_dt, free_move=free_move, has_imu=has_imu, has_mouse=has_mouse,)\n",
    "    if free_move:\n",
    "        ##### Find 'good' timepoints when mouse is active #####\n",
    "        nan_idxs = []\n",
    "        for key in data.keys():\n",
    "            nan_idxs.append(np.where(np.isnan(data[key]))[0])\n",
    "        good_idxs = np.ones(len(data['model_active']),dtype=bool)\n",
    "        good_idxs[data['model_active']<.5] = False\n",
    "        good_idxs[np.unique(np.hstack(nan_idxs))] = False\n",
    "    else:\n",
    "        good_idxs = np.where((np.abs(data['model_th'])<10) & (np.abs(data['model_phi'])<10))[0]\n",
    "    \n",
    "    data['raw_nsp'] = data['model_nsp'].copy()\n",
    "    ##### return only active data #####\n",
    "    for key in data.keys():\n",
    "        if (key != 'model_nsp') & (key != 'model_active') & (key != 'unit_nums'):\n",
    "            data[key] = data[key][good_idxs] # interp_nans(data[key]).astype(float)\n",
    "        elif (key == 'model_nsp'):\n",
    "            data[key] = data[key][good_idxs]\n",
    "        elif (key == 'unit_nums'):\n",
    "            pass\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=train_size, random_state=42)\n",
    "    nT = data['model_nsp'].shape[0]\n",
    "    groups = np.hstack([i*np.ones(int((frac*i)*nT) - int((frac*(i-1))*nT)) for i in range(1,int(1/frac)+1)])\n",
    "\n",
    "    for train_idx, test_idx in gss.split(np.arange(len(data['model_nsp'])), groups=groups):\n",
    "        print(\"TRAIN:\", len(train_idx), \"TEST:\", len(test_idx))\n",
    "\n",
    "\n",
    "    data['model_dth'] = np.diff(data['model_th'],append=0)\n",
    "    data['model_dphi'] = np.diff(data['model_phi'],append=0)\n",
    "\n",
    "    data['model_vid_sm'] = (data['model_vid_sm'] - np.mean(data['model_vid_sm'],axis=0))/np.nanstd(data['model_vid_sm'],axis=0)\n",
    "    data['model_vid_sm'][np.isnan(data['model_vid_sm'])]=0\n",
    "    if do_norm:\n",
    "        data['model_th'] = (data['model_th'] - np.mean(data['model_th'],axis=0))/np.std(data['model_th'],axis=0) \n",
    "        data['model_phi'] = (data['model_phi'] - np.mean(data['model_phi'],axis=0))/np.std(data['model_phi'],axis=0) \n",
    "        if free_move:\n",
    "            data['model_roll'] = (data['model_roll'] - np.mean(data['model_roll'],axis=0))/np.std(data['model_roll'],axis=0) \n",
    "            data['model_pitch'] = (data['model_pitch'] - np.mean(data['model_pitch'],axis=0))/np.std(data['model_pitch'],axis=0) \n",
    "\n",
    "    ##### Split Data by train/test #####\n",
    "    data_train_test = {\n",
    "        'train_vid': data['model_vid_sm'][train_idx],\n",
    "        'test_vid': data['model_vid_sm'][test_idx],\n",
    "        'train_nsp': shuffle(data['model_nsp'][train_idx],random_state=42) if do_shuffle else data['model_nsp'][train_idx],\n",
    "        'test_nsp': shuffle(data['model_nsp'][test_idx],random_state=42) if do_shuffle else data['model_nsp'][test_idx],\n",
    "        'train_th': data['model_th'][train_idx],\n",
    "        'test_th': data['model_th'][test_idx],\n",
    "        'train_phi': data['model_phi'][train_idx],\n",
    "        'test_phi': data['model_phi'][test_idx],\n",
    "        'train_roll': data['model_roll'][train_idx] if free_move else [],\n",
    "        'test_roll': data['model_roll'][test_idx] if free_move else [],\n",
    "        'train_pitch': data['model_pitch'][train_idx] if free_move else [],\n",
    "        'test_pitch': data['model_pitch'][test_idx] if free_move else [],\n",
    "        'train_t': data['model_t'][train_idx],\n",
    "        'test_t': data['model_t'][test_idx],\n",
    "        'train_dth': data['model_dth'][train_idx],\n",
    "        'test_dth': data['model_dth'][test_idx],\n",
    "        'train_dphi': data['model_dphi'][train_idx],\n",
    "        'test_dphi': data['model_dphi'][test_idx],\n",
    "        'train_gz': data['model_gz'][train_idx] if free_move else [],\n",
    "        'test_gz': data['model_gz'][test_idx] if free_move else [],\n",
    "    }\n",
    "\n",
    "    d1 = data\n",
    "    d1.update(data_train_test)\n",
    "    return d1,train_idx,test_idx\n",
    "\n",
    "\n",
    "def f_add(alpha,stat_range,stat_all):\n",
    "    return np.mean((stat_range - (stat_all+alpha))**2)\n",
    "\n",
    "def f_mult(alpha,stat_range,stat_all):\n",
    "    return np.mean((stat_range - (stat_all*alpha))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_move = True\n",
    "if free_move:\n",
    "    stim_type = 'fm1'\n",
    "else:\n",
    "    stim_type = 'hf1_wn' # 'fm1' # \n",
    "# 012821/EE8P6LT\n",
    "# 128: 070921/J553RT\n",
    "date_ani = '070921/J553RT' #'062921/G6HCK1ALTRN'\n",
    "data_dir  = Path('~/Goeppert/freely_moving_ephys/ephys_recordings/').expanduser() / date_ani / stim_type\n",
    "save_dir  = check_path(Path('~/Research/SensoryMotorPred_Data/data/').expanduser() / date_ani, stim_type)\n",
    "FigPath = check_path(Path('~/Research/SensoryMotorPred_Data').expanduser(),'Figures/Encoding')\n",
    "FigPath = check_path(FigPath/date_ani, stim_type)\n",
    "FigPath_SFN = check_path(FigPath,'SFN')\n",
    "\n",
    "print('save_dir:',save_dir)\n",
    "print('data_dir:',data_dir)\n",
    "print('FigPath:', FigPath)\n",
    "# with open(save_dir / 'file_dict.json','r') as fp:\n",
    "#     file_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {'cell': 0,\n",
    "            'drop_slow_frames': True,\n",
    "            'ephys': list(data_dir.glob('*ephys_merge.json'))[0].as_posix(),\n",
    "            'ephys_bin': list(data_dir.glob('*Ephys.bin'))[0].as_posix(),\n",
    "            'eye': list(data_dir.glob('*REYE.nc'))[0].as_posix(),\n",
    "            'imu': list(data_dir.glob('*imu.nc'))[0].as_posix() if stim_type=='fm1' else None,\n",
    "            'mapping_json': '/home/seuss/Research/Github/FreelyMovingEphys/probes/channel_maps.json',\n",
    "            'mp4': True,\n",
    "            'name': '01221_EE8P6LT_control_Rig2_'+stim_type, #070921_J553RT\n",
    "            'probe_name': 'DB_P128-6',\n",
    "            'save': data_dir.as_posix(),\n",
    "            'speed': list(data_dir.glob('*speed.nc'))[0].as_posix() if stim_type=='hf1_wn' else None,\n",
    "            'stim_type': 'light',\n",
    "            'top': list(data_dir.glob('*TOP1.nc'))[0].as_posix() if stim_type=='fm1' else None,\n",
    "            'world': list(data_dir.glob('*world.nc'))[0].as_posix(),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = .05\n",
    "do_shuffle=False\n",
    "do_norm = False\n",
    "data,train_idx,test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=do_shuffle, do_norm=do_norm,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "locals().update(data)\n",
    "\n",
    "lag_list = np.array([-2,-1,0,1,2]) #np.array([-1,0,1,2,3]) #,np.arange(minlag,maxlag,np.floor((maxlag-minlag)/nt_glm_lag).astype(int))\n",
    "nt_glm_lag = len(lag_list)\n",
    "print(lag_list,1000*lag_list*model_dt)\n",
    "do_shuffle=False\n",
    "model_type = 'Pytorch'\n",
    "ncells=model_nsp.shape[-1]\n",
    "bin_length=40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-oklahoma",
   "metadata": {},
   "source": [
    "# Testing Tuning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tuning curve for theta\n",
    "def tuning_curve(model_nsp, var, model_dt = .025, N_bins=10, Nstds=3):\n",
    "    var_range = np.linspace(np.nanmean(var)-Nstds*np.nanstd(var), np.nanmean(var)+Nstds*np.nanstd(var),N_bins)\n",
    "    tuning = np.zeros((model_nsp.shape[-1],len(var_range)-1))\n",
    "    tuning_std = np.zeros((model_nsp.shape[-1],len(var_range)-1))\n",
    "    for n in range(model_nsp.shape[-1]):\n",
    "        for j in range(len(var_range)-1):\n",
    "            usePts = (var>=var_range[j]) & (var<var_range[j+1])\n",
    "            tuning[n,j] = np.nanmean(model_nsp[usePts,n])/model_dt\n",
    "            tuning_std[n,j] = (np.nanstd(model_nsp[usePts,n])/model_dt)/ np.sqrt(np.count_nonzero(usePts))\n",
    "    return tuning, tuning_std, var_range[:-1]\n",
    "\n",
    "\n",
    "def consecutive(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_list = np.array([-2,-1,0,1,2]) #np.array([-1,0,1,2,3]) #,np.arange(minlag,maxlag,np.floor((maxlag-minlag)/nt_glm_lag).astype(int))\n",
    "nt_glm_lag = len(lag_list)\n",
    "print(lag_list,1000*lag_list*model_dt)\n",
    "do_shuffle = False\n",
    "model_type = 'Pytorch'\n",
    "\n",
    "# for do_shuffle in [False,True]:\n",
    "# Load Data\n",
    "data, train_idx, test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=do_shuffle, do_norm=False,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "locals().update(data)\n",
    "\n",
    "# Initialize movement combinations\n",
    "titles = np.array(['Theta','Phi','Roll','Pitch']) # 'dg_p','dg_n' 'roll','pitch'\n",
    "titles_all = []\n",
    "for n in range(1,len(titles)+1):\n",
    "    perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "    for ind in range(perms.shape[0]):\n",
    "        titles_all.append('_'.join([t for t in titles[perms[ind]]]))\n",
    "if free_move:\n",
    "    move_train = np.hstack((train_th[:,np.newaxis],train_phi[:,np.newaxis],train_roll[:,np.newaxis],train_pitch[:,np.newaxis]))\n",
    "    move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_roll[:,np.newaxis],test_pitch[:,np.newaxis])) \n",
    "    model_move = np.hstack((model_th[:,np.newaxis],model_phi[:,np.newaxis],model_roll[:,np.newaxis],model_pitch[:,np.newaxis]))\n",
    "    model_move = model_move - np.mean(model_move,axis=0)\n",
    "    move_test = move_test - np.mean(move_test,axis=0)\n",
    "    move_train = move_train - np.mean(move_train,axis=0)\n",
    "\n",
    "##### Start GLM Parallel Processing #####\n",
    "nks = np.shape(train_vid)[1:]; nk = nks[0]*nks[1]*nt_glm_lag\n",
    "n=4; ind=0\n",
    "perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "##### Start GLM Parallel Processing #####\n",
    "# Reshape data (video) into (T*n)xN array\n",
    "rolled_vid = np.hstack([np.roll(model_vid_sm, nframes, axis=0) for nframes in lag_list]) # nt_glm_lag\n",
    "rolled_vid_flat = rolled_vid.reshape(rolled_vid.shape[0],-1)\n",
    "x_train = rolled_vid[train_idx].reshape(len(train_idx),-1)\n",
    "x_test = rolled_vid[test_idx].reshape(len(test_idx),-1)\n",
    "\n",
    "MovModel = 1\n",
    "GLM_VisMov_shuff = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}_shuffled.h5'.format(model_type,int(model_dt*1000), nt_glm_lag, 1))\n",
    "GLM_VisMov_m0 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,0))\n",
    "GLM_VisMov_m1 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,1))\n",
    "GLM_VisMov_m2 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,2))\n",
    "# Reshape data (video) into (T*n)xN array\n",
    "if MovModel == 0:\n",
    "    mx_train = move_train[:,perms[ind]]\n",
    "    mx_test = move_test[:,perms[ind]]\n",
    "    xtr = torch.from_numpy(mx_train.astype(np.float32)).to(device)\n",
    "    xte = torch.from_numpy(mx_test.astype(np.float32)).to(device)    \n",
    "    move_features = None # mx_train.shape[-1]\n",
    "    nk = 0\n",
    "    xtrm = None\n",
    "    xtem = None\n",
    "    locals().update(GLM_VisMov_m0)\n",
    "elif MovModel == 1:\n",
    "    x_train_m1 = (rolled_vid[train_idx].reshape(len(train_idx),-1)).astype(np.float32)\n",
    "    x_test_m1 = (rolled_vid[test_idx].reshape(len(test_idx),-1)).astype(np.float32)\n",
    "    xtr = torch.from_numpy(x_train_m1).to(device)\n",
    "    xte = torch.from_numpy(x_test_m1).to(device)\n",
    "    move_features = None\n",
    "    xtrm = None\n",
    "    xtem = None\n",
    "    locals().update(GLM_VisMov_m1)\n",
    "elif MovModel == 2:\n",
    "    xtrm = torch.from_numpy(move_train[:,perms[ind]].astype(np.float32)).to(device)\n",
    "    xtem = torch.from_numpy(move_test[:,perms[ind]].astype(np.float32)).to(device)\n",
    "    xtr = torch.from_numpy(x_train.astype(np.float32)).to(device)\n",
    "    xte = torch.from_numpy(x_test.astype(np.float32)).to(device)\n",
    "    move_features = xtrm.shape[-1]\n",
    "    locals().update(GLM_VisMov_m2)\n",
    "elif MovModel == 3:\n",
    "    x_train_m3 = np.hstack((x_train,np.hstack([x_train*move_train[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_train[:,perms[ind]]))\n",
    "    x_test_m3 = np.hstack((x_test,np.hstack([x_test*move_test[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_test[:,perms[ind]]))\n",
    "    xtr = torch.from_numpy(x_train_m3.astype(np.float32)).to(device)\n",
    "    xte = torch.from_numpy(x_test_m3.astype(np.float32)).to(device)    \n",
    "    move_features = x_train_m3.shape[-1]-nk\n",
    "\n",
    "    \n",
    "ytr = torch.from_numpy(train_nsp.astype(np.float32)).to(device)\n",
    "yte = torch.from_numpy(test_nsp.astype(np.float32)).to(device)\n",
    "input_size = xtr.shape[1]\n",
    "output_size = ytr.shape[1]\n",
    "print('Model: {}, move_features: {}'.format(MovModel, move_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, train_idx, test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=do_shuffle, do_norm=False,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "locals().update(data)\n",
    "if do_shuffle:\n",
    "    GLM_Vis = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}_shuffled.h5'.format(model_type,int(model_dt*1000), nt_glm_lag, MovModel))\n",
    "else:\n",
    "    GLM_Vis = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag, MovModel))\n",
    "locals().update(GLM_Vis)\n",
    "##### Explore Neurons #####\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "# Initialize movement combinations\n",
    "titles = np.array(['Theta','Phi','Roll','Pitch']) # 'dg_p','dg_n' 'roll','pitch'\n",
    "titles_all = []\n",
    "for n in range(1,len(titles)+1):\n",
    "    perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "    for ind in range(perms.shape[0]):\n",
    "        titles_all.append('_'.join([t for t in titles[perms[ind]]]))\n",
    "\n",
    "# train_dgaze_p = train_dth + np.diff(train_gz,append=0)\n",
    "# train_dgaze_n = train_dth - np.diff(train_gz,append=0)\n",
    "# test_dgaze_p = test_dth + np.diff(test_gz,append=0)\n",
    "# test_dgaze_n = test_dth - np.diff(test_gz,append=0)\n",
    "move_train = np.hstack((train_th[:,np.newaxis],train_phi[:,np.newaxis],train_roll[:,np.newaxis],train_pitch[:,np.newaxis]))#, train_dth[:,np.newaxis],train_dphi[:,np.newaxis]))\n",
    "move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_roll[:,np.newaxis],test_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "# move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))# test_dth[:,np.newaxis],test_dphi[:,np.newaxis]))\n",
    "model_move = np.hstack((model_th[:,np.newaxis],model_phi[:,np.newaxis],model_roll[:,np.newaxis],model_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "model_move = model_move - np.mean(model_move,axis=0)\n",
    "move_test = move_test - np.mean(move_test,axis=0)\n",
    "move_train = move_train - np.mean(move_train,axis=0)\n",
    "\n",
    "pred_train = np.log1p(np.exp(sta_all.reshape(output_size,-1)@x_train_m1.T + bias_all[:,np.newaxis])).T\n",
    "\n",
    "dataset_type = 'train'\n",
    "\n",
    "if dataset_type == 'train':\n",
    "    nsp_raw = train_nsp.copy()\n",
    "    pred_raw = pred_train.copy()\n",
    "    move_data = move_train.copy()\n",
    "else:\n",
    "    nsp_raw = test_nsp.copy()\n",
    "    pred_raw = pred_all.copy()\n",
    "    move_data = move_test.copy()\n",
    "\n",
    "# Create all tuning curves for plotting\n",
    "N_bins=10\n",
    "ncells = model_nsp.shape[-1]\n",
    "ax_ylims = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "tuning_curves = np.zeros((model_nsp.shape[-1],len(titles),N_bins-1))\n",
    "tuning_stds = np.zeros((model_nsp.shape[-1],len(titles),N_bins-1))\n",
    "var_ranges = np.zeros((len(titles),N_bins-1))\n",
    "for modeln in range(len(titles)):\n",
    "    metric = move_data[:,modeln]\n",
    "    tuning, tuning_std, var_range = tuning_curve(nsp_raw, metric, N_bins=N_bins, model_dt=model_dt, Nstds=2)\n",
    "    tuning_curves[:,modeln] = tuning\n",
    "    tuning_stds[:,modeln] = tuning_std\n",
    "    ax_ylims[:,modeln] = np.nanmax(tuning,axis=1)\n",
    "    var_ranges[modeln] = var_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Summary Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 126# np.argmax(r2_all)\n",
    "bin_length = 40\n",
    "dataset_type = 'train'\n",
    "ncells=model_nsp.shape[-1]\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "quartiles = np.arange(0,1.25,.25)\n",
    "\n",
    "fig, axs = plt.subplots(3,5, figsize=((35,15))) \n",
    "gs = axs[0,0].get_gridspec()\n",
    "gs_sub = gs[0,:].subgridspec(1,nt_glm_lag)\n",
    "for ax in axs[0,:]:\n",
    "    ax.remove()\n",
    "top_grid = np.zeros((nt_glm_lag),dtype=object)\n",
    "for ind in range(nt_glm_lag):\n",
    "    top_grid[ind] = fig.add_subplot(gs_sub[0,ind])\n",
    "\n",
    "\n",
    "if dataset_type == 'train':\n",
    "    predcell = pred_train[:,celln]/model_dt\n",
    "    nspcell = train_nsp[:,celln]/model_dt\n",
    "    nsp_raw = train_nsp[:,celln]\n",
    "    pred_raw = pred_train[:,celln]\n",
    "    move_data = move_train.copy()\n",
    "else: \n",
    "    predcell = pred_all[:,celln]/model_dt\n",
    "    nspcell = test_nsp[:,celln]/model_dt\n",
    "    nsp_raw = test_nsp[:,celln]\n",
    "    pred_raw = pred_all[:,celln]\n",
    "    move_data = move_test.copy()\n",
    "\n",
    "nsp_smooth=((np.convolve(nsp_raw, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth=((np.convolve(pred_raw, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "\n",
    "\n",
    "# Set up predicted spike range between 1-99th percentile\n",
    "stat_bins = 5\n",
    "pred_range = np.quantile(predcell,[.1,.9])\n",
    "test_nsp_range = np.quantile(nspcell,[.01,1])\n",
    "spike_percentiles = np.arange(0,1.25,.25)\n",
    "spike_percentiles[-1]=.99\n",
    "spk_percentile2 = np.arange(.125,1.125,.25)\n",
    "pred_rangelin = np.quantile(predcell,spike_percentiles)\n",
    "xbin_pts = np.quantile(predcell,spk_percentile2)\n",
    "stat_bins = len(pred_rangelin) #5\n",
    "\n",
    "\n",
    "axs[1,0].plot(np.arange(len(nsp_smooth))*model_dt,nsp_smooth,'k',label='test FR')\n",
    "axs[1,0].plot(np.arange(len(pred_smooth))*model_dt,pred_smooth,'r', label='pred FR')\n",
    "axs[1,0].set_xlabel('Time (s)')\n",
    "axs[1,0].set_ylabel('Firing Rate (spks/s)')\n",
    "axs[1,0].legend()\n",
    "axs[1,0].set_title('Smoothed FRs')\n",
    "\n",
    "crange = np.max(np.abs(sta_all[celln]))\n",
    "for n in range(nt_glm_lag):\n",
    "    img = top_grid[n].imshow(sta_all[celln,n],cmap='RdBu_r',vmin=-crange,vmax=crange)\n",
    "    top_grid[n].axis('off')\n",
    "    top_grid[n].set_title('Lag:{:03d} ms'.format(int(1000*lag_list[n]*model_dt)))\n",
    "    top_grid[n].axis('off')\n",
    "add_colorbar(img)\n",
    "\n",
    "# Eye Tuning Curve\n",
    "top_yaxs = np.max(ax_ylims[celln])+2*np.max(tuning_stds[celln])\n",
    "for i,modeln in enumerate(range(len(titles)-2)):\n",
    "    metric = move_data[:,modeln]\n",
    "    nranges = np.quantile(metric,quartiles)\n",
    "    stat_range, edges, _ = binned_statistic(metric,nsp_raw,statistic='mean',bins=nranges)\n",
    "    edge_mids = np.quantile(metric,spk_percentile2)#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    # cmap = mpl.colors.ListedColormap(colors, N=colors.shape[0])\n",
    "    # norm = mpl.colors.BoundaryNorm(boundaries=np.floor(nranges), ncolors=len(cmap.colors))\n",
    "    for m in range(len(nranges)-1):\n",
    "        axs[1,1].axvspan(nranges[m], nranges[m+1],ymin=i*1/2,ymax=(i+1)*1/2,alpha=0.8, color=colors[m],zorder=0)\n",
    "    #     axs[1,1].errorbar(var_ranges[modeln],tuning_curves[celln,modeln], yerr=tuning_stds[celln,modeln],label=titles[modeln],c=clrs[modeln],lw=4,elinewidth=3)\n",
    "    axs[1,1].plot(edge_mids,stat_range/model_dt,'.-', ms=20, lw=4,c=clrs[modeln])\n",
    "\n",
    "axs[1,1].set_ylim(bottom=0,top=np.max(ax_ylims,axis=1)[celln]+2*np.nanmax(tuning_stds,axis=(1,2))[celln])\n",
    "axs[1,1].set_xlim(-30,30)\n",
    "axs[1,1].set_xlabel('Angle ($ ^{\\degree}$)')\n",
    "axs[1,1].set_ylabel('Spikes/s')\n",
    "axs[1,1].set_title('Eye Tuning Curves')\n",
    "lines = axs[1,1].get_lines()\n",
    "legend1 = axs[1,1].legend([lines[0]],[titles[0]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "legend2 = axs[1,1].legend([lines[1]],[titles[1]],bbox_to_anchor=(1.01, .9), fontsize=12)\n",
    "axs[1,1].add_artist(legend1)\n",
    "\n",
    "# Head Tuning Curves\n",
    "top_yaxs = np.max(ax_ylims[celln])+2*np.nanmax(tuning_stds[celln])\n",
    "for i, modeln in enumerate(range(2,len(titles))):\n",
    "    metric = move_data[:,modeln]\n",
    "#     nranges = np.round(np.quantile(var_ranges[modeln],quartiles),decimals=1)\n",
    "    nranges = np.round(np.quantile(metric,quartiles),decimals=1)\n",
    "    stat_range, edges, _ = binned_statistic(metric,nsp_raw,statistic='mean',bins=nranges)\n",
    "    edge_mids = np.quantile(metric,spk_percentile2)#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    # cmap = mpl.colors.ListedColormap(colors, N=colors.shape[0])\n",
    "    # norm = mpl.colors.BoundaryNorm(boundaries=np.floor(nranges), ncolors=len(cmap.colors))\n",
    "    for m in range(len(nranges)-1):\n",
    "        axs[1,2].axvspan(nranges[m], nranges[m+1],ymin=i*1/2,ymax=(i+1)*1/2,alpha=0.8, color=colors[m],zorder=0)\n",
    "#     axs[1,2].errorbar(var_ranges[modeln], tuning_curves[celln,modeln], yerr=tuning_stds[celln,modeln], label=titles[modeln], c=clrs[modeln],lw=4,elinewidth=3)\n",
    "    axs[1,2].plot(edge_mids,stat_range/model_dt,'.-', ms=20, lw=4,c=clrs[modeln])\n",
    "\n",
    "axs[1,2].set_ylim(bottom=0,top=top_yaxs)\n",
    "axs[1,2].set_xlim(-30,30)\n",
    "axs[1,2].set_xlabel('Angle ($ ^{\\degree}$)')\n",
    "axs[1,2].set_ylabel('Spikes/s')\n",
    "axs[1,2].set_title('Head Tuning Curves')\n",
    "lines = axs[1,2].get_lines()\n",
    "legend1 = axs[1,2].legend([lines[0]],[titles[2]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "legend2 = axs[1,2].legend([lines[1]],[titles[3]],bbox_to_anchor=(1.01, .9), fontsize=12)\n",
    "axs[1,2].add_artist(legend1)\n",
    "\n",
    "# axs[1,2].legend(bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "\n",
    "\n",
    "# pred_rangelin = np.linspace(pred_range[0],pred_range[1],stat_bins)\n",
    "axs[1,3].scatter(predcell,nspcell,c='k',s=15)\n",
    "axs[1,3].plot(np.linspace(test_nsp_range[0],test_nsp_range[1]),np.linspace(test_nsp_range[0],test_nsp_range[1]),'k--',zorder=0)\n",
    "axs[1,3].set_xlabel('Predicted Spike Rate')\n",
    "axs[1,3].set_ylabel('Actual Spike Rate')\n",
    "cbar = add_colorbar(img)\n",
    "# cbar.set_label('count')\n",
    "\n",
    "if MovModel == 1:\n",
    "    w_move = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "elif MovModel == 3:\n",
    "    Msta = w_move[:,:-len(titles)].reshape((model_nsp.shape[-1],nt_glm_lag,len(titles))+nks)\n",
    "    w_move = w_move[:,-len(titles):]\n",
    "for modeln in range(len(titles)):\n",
    "    axs[1,4].bar(modeln, w_move[celln,modeln], color=clrs[modeln])\n",
    "    axs[1,4].set_xticks(np.arange(0,len(titles)))\n",
    "    axs[1,4].set_xticklabels(titles)\n",
    "    axs[1,4].set_ylabel('GLM Weight')\n",
    "\n",
    "\n",
    "mse_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "mse_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "alpha_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "alpha_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "\n",
    "traces = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "traces_mean = np.zeros((ncells,len(titles),stat_bins-1)) # (model_type,quartile,FR)\n",
    "edges_all = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "# df_traces = pd.DataFrame([],columns=['modeln','quartile','FR']) \n",
    "for modeln in range(len(titles)):\n",
    "    metric = move_data[:,modeln]\n",
    "    nranges = np.quantile(metric,quartiles)# np.linspace(np.nanmean(metric)-2*np.nanstd(metric), np.nanmean(metric)+2*np.nanstd(metric),N_bins)\n",
    "    stat_all, edges, _ = binned_statistic(predcell,nspcell,statistic='mean',bins=pred_rangelin)\n",
    "    edge_mids = xbin_pts#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    traces_mean[celln,modeln]=stat_all\n",
    "    max_fr = np.max(stat_all)\n",
    "#     axs[1,modeln].set_xlim(0,pred_range[1]+np.std(pred_range))\n",
    "#     axs[1,modeln].set_ylim(0,np.max(stat)+np.std(stat))\n",
    "\n",
    "    for n in range(len(nranges)-1):\n",
    "        ind = np.where(((metric<=nranges[n+1])&(metric>nranges[n])))[0]\n",
    "        pred = predcell[ind]\n",
    "        sp = nspcell[ind]\n",
    "\n",
    "        stat_range, edges, _ = binned_statistic(pred, sp, statistic='mean',bins=pred_rangelin)\n",
    "        edge_mids = xbin_pts #np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "        traces[celln,modeln,n]=stat_range\n",
    "        edges_all[celln,modeln,n]=edge_mids\n",
    "        res_add = minimize_scalar(f_add,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "        res_mult = minimize_scalar(f_mult,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "        mse_add[celln, modeln, n] = res_add.fun\n",
    "        mse_mult[celln, modeln, n] = res_mult.fun\n",
    "        alpha_add[celln, modeln, n] = res_add.x\n",
    "        alpha_mult[celln, modeln, n] = res_mult.x\n",
    "\n",
    "        axs[2,modeln].plot(edge_mids, stat_range,'.-', c=colors[n],label='{:.02f} : {:.02f}'.format(nranges[n],nranges[n+1]),lw=4,ms=20,alpha=.9)\n",
    "        axs[2,modeln].set_title('Metric: {}'.format(titles[modeln]), color=clrs[modeln])\n",
    "        axs[2,modeln].set_xlabel('Predicted Spike Rate')\n",
    "        axs[2,modeln].set_ylabel('Actual Spike Rate')\n",
    "    \n",
    "    lim_max = np.nanmax(np.hstack((edge_mids,traces[celln,modeln].flatten())))+.5*np.std(edges)\n",
    "    lim_min = np.nanmin(np.hstack((edge_mids,traces[celln,modeln].flatten())))-.5*np.std(edges)\n",
    "    lims = (0, lim_max) if (lim_min)<0 else (lim_min,lim_max) \n",
    "    axs[2,modeln].plot(np.linspace(lims[0],lims[1]),np.linspace(lims[0],lims[1]),'k--',zorder=0)\n",
    "    axs[2,modeln].plot(edge_mids, stat_all,'.-', c='k', lw=5, ms=20, label='All_data', alpha=.8)\n",
    "    axs[2,modeln].legend(bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "    axs[2,modeln].axis('equal')\n",
    "#     axs[2,modeln].set_xlim(left=0)\n",
    "    axs[2,modeln].set(xlim=lims, ylim=lims)\n",
    "#     axs[2,modeln].set_xlim([0,xbin_pts[-1]])\n",
    "    axs[2,modeln].set_ylim(bottom=0)\n",
    "\n",
    "dmodel = mse_add[celln]-mse_mult[celln]\n",
    "crange = np.max(np.abs(dmodel))\n",
    "im = axs[2,-1].imshow(dmodel,cmap='seismic',vmin=-crange,vmax=crange)\n",
    "axs[2,-1].set_yticks(np.arange(0,4))\n",
    "axs[2,-1].set_yticklabels(titles)\n",
    "axs[2,-1].set_ylabel('Movement Model')\n",
    "axs[2,-1].set_xticks(np.arange(0,4))\n",
    "axs[2,-1].set_xticklabels(['.25','.5','.75','1'])\n",
    "axs[2,-1].set_xlabel('Quantile Range')\n",
    "axs[2,-1].set_title('$MSE_{add}$ - $MSE_{mult}$')\n",
    "cbar = add_colorbar(im)\n",
    "\n",
    "plt.suptitle('Celln:{}, r2={:.03f}'.format(celln,r2_all[celln]),y=1,fontsize=30)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# fig.savefig(FigPath/'CellSummary_N{}_T{:02d}.png'.format(celln,nt_glm_lag), facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulated FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# celln = 51# np.argmax(r2_all)\n",
    "stat_bins = 5\n",
    "ncells = model_nsp.shape[-1]\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "quartiles = np.arange(0,1.25,.25)\n",
    "mse_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "mse_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "alpha_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "alpha_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "\n",
    "traces = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "traces_mean = np.zeros((ncells,len(titles),stat_bins-1)) # (model_type,quartile,FR)\n",
    "edges_all = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "for celln in tqdm(range(train_nsp.shape[-1])): \n",
    "    predcell = pred_train[:,celln]/model_dt\n",
    "    nspcell = train_nsp[:,celln]/model_dt\n",
    "\n",
    "    # Set up predicted spike range between 1-99th percentile\n",
    "    pred_range = np.quantile(predcell,[.1,.9])\n",
    "    test_nsp_range = np.quantile(nspcell,[.01,1])\n",
    "    spike_percentiles = np.arange(0,1.25,.25)\n",
    "    spike_percentiles[-1]=.99\n",
    "    spk_percentile2 = np.arange(.125,1.125,.25)\n",
    "    pred_rangelin = np.quantile(predcell,spike_percentiles)\n",
    "    xbin_pts = np.quantile(predcell,spk_percentile2)\n",
    "    stat_bins = len(pred_rangelin) #5\n",
    "    for modeln in range(len(titles)):\n",
    "        metric = move_train[:,modeln]\n",
    "        nranges = np.quantile(metric,quartiles)# np.linspace(np.nanmean(metric)-2*np.nanstd(metric), np.nanmean(metric)+2*np.nanstd(metric),N_bins)\n",
    "        stat_all, edges, _ = binned_statistic(predcell,nspcell,statistic='mean',bins=pred_rangelin)\n",
    "        edge_mids = xbin_pts#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "        traces_mean[celln,modeln]=stat_all\n",
    "        max_fr = np.max(stat_all)\n",
    "\n",
    "        for n in range(len(nranges)-1):\n",
    "            ind = np.where(((metric<=nranges[n+1])&(metric>nranges[n])))[0]\n",
    "            pred = predcell[ind]\n",
    "            sp = nspcell[ind]\n",
    "\n",
    "            stat_range, edges, _ = binned_statistic(pred, sp, statistic='mean',bins=pred_rangelin)\n",
    "            edge_mids = xbin_pts #np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "            traces[celln,modeln,n]=stat_range\n",
    "            edges_all[celln,modeln,n]=edge_mids\n",
    "            res_add = minimize_scalar(f_add,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "            res_mult = minimize_scalar(f_mult,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "            mse_add[celln, modeln, n] = res_add.fun\n",
    "            mse_mult[celln, modeln, n] = res_mult.fun\n",
    "            alpha_add[celln, modeln, n] = res_add.x\n",
    "            alpha_mult[celln, modeln, n] = res_mult.x\n",
    "\n",
    "\n",
    "\n",
    "dmodel = mse_add-mse_mult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Modulated Pred. and R2\n",
    "r2_mod_mult = np.zeros((ncells, len(titles)+1))\n",
    "r2_mod_add = np.zeros((ncells, len(titles)+1))\n",
    "test_nsp_smooth = ((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth = ((np.convolve(pred_all[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_multadd_all = np.zeros((2,len(titles)+1,ncells,) + pred_all[:,celln].shape)\n",
    "pred_multadd_smooth_all = np.zeros((2,len(titles)+1,ncells,) + pred_smooth.shape)\n",
    "for celln in tqdm(range(ncells)):\n",
    "    predcell = pred_all[:,celln]/model_dt\n",
    "    nspcell = test_nsp[:,celln]/model_dt\n",
    "    test_nsp_smooth = ((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    pred_smooth = ((np.convolve(pred_all[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    pred_mult_all = pred_all[:,celln].copy()\n",
    "    pred_add_all = pred_all[:,celln].copy()\n",
    "    for modeln in range(len(titles)):\n",
    "        metric = move_test[:,modeln]\n",
    "        nranges = np.quantile(metric,quartiles)\n",
    "        stat_range, edges, _ = binned_statistic(metric,test_nsp[:,celln], statistic='mean',bins=nranges)\n",
    "        pred_mult = pred_all[:,celln].copy()\n",
    "        pred_add = pred_all[:, celln].copy()\n",
    "        for i in range(len(edges)-1):    \n",
    "            metric_bounds = consecutive(np.where((metric>edges[i])&(metric<edges[i+1]))[0])\n",
    "            metric_bounds = [row for row in metric_bounds]\n",
    "            metric_length = [len(row) for row in metric_bounds]\n",
    "            for n, row in enumerate(metric_bounds):\n",
    "                pred_mult[row] = alpha_mult[celln,modeln,i]*pred_mult[row]\n",
    "                pred_mult_all[row] = alpha_mult[celln,modeln,i]*pred_mult[row]\n",
    "                pred_add_all[row] = alpha_add[celln,modeln,i]+ pred_add_all[row]\n",
    "                pred_add[row] = alpha_add[celln,modeln,i] + pred_add[row]\n",
    "        pred_multadd_all[0,modeln,celln] = pred_mult\n",
    "        pred_multadd_all[1,modeln,celln] = pred_add\n",
    "        pred_smooth_mult = ((np.convolve(pred_mult, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "        pred_smooth_add = ((np.convolve(pred_add, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "        pred_multadd_smooth_all[0,modeln,celln] = pred_smooth_mult\n",
    "        pred_multadd_smooth_all[1,modeln,celln] = pred_smooth_add\n",
    "        cc_mult = np.corrcoef(test_nsp_smooth,pred_smooth_mult)[0,1]\n",
    "        cc_add = np.corrcoef(test_nsp_smooth, pred_smooth_add)[0, 1]\n",
    "        r2_mod_mult[celln, modeln] = cc_mult**2\n",
    "        r2_mod_add[celln, modeln] = cc_add**2\n",
    "\n",
    "    pred_multadd_all[0,-1,celln] = pred_mult_all\n",
    "    pred_multadd_all[1,-1,celln] = pred_add_all\n",
    "    pred_smooth_mult_all = ((np.convolve(pred_mult_all, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    pred_smooth_add_all = ((np.convolve(pred_add_all, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    pred_multadd_smooth_all[0,-1,celln] = pred_smooth_mult_all\n",
    "    pred_multadd_smooth_all[1,-1,celln] = pred_smooth_add_all\n",
    "    cc_mult = np.corrcoef(test_nsp_smooth,pred_smooth_mult_all)[0,1]\n",
    "    cc_add = np.corrcoef(test_nsp_smooth, pred_smooth_add_all)[0, 1]\n",
    "    r2_mod_mult[celln, -1] = cc_mult**2\n",
    "    r2_mod_add[celln, -1] = cc_add**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr2 = np.max(r2_mod_add,axis=1)-np.max(r2_mod_mult,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 126\n",
    "t = 4500\n",
    "modeln = 3\n",
    "dataset_type = 'test'\n",
    "if dataset_type == 'train':\n",
    "    predcell = pred_train[:,celln]/model_dt\n",
    "    nspcell = train_nsp[:,celln]/model_dt\n",
    "    nsp_raw = train_nsp[:,celln]\n",
    "    pred_raw = pred_train[:,celln]\n",
    "    move_data = move_train.copy()\n",
    "else: \n",
    "    predcell = pred_all[:,celln]/model_dt\n",
    "    nspcell = test_nsp[:,celln]/model_dt\n",
    "    nsp_raw = test_nsp[:,celln]\n",
    "    pred_raw = pred_all[:,celln]\n",
    "    move_data = move_test.copy()\n",
    "\n",
    "metric = move_data[:,modeln]\n",
    "dt = pred_multadd_smooth_all.shape[-1]-t-1\n",
    "fig2, axs2 = plt.subplots(1,figsize=(10,5))\n",
    "nsp_smooth=((np.convolve(nsp_raw, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth=((np.convolve(pred_raw, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "\n",
    "timem1 = (np.arange(0,dt)*model_dt)\n",
    "# pred_smooth_mult = pred_smooth.copy()\n",
    "nranges = np.quantile(metric,quartiles)\n",
    "stat_range, edges, _ = binned_statistic(metric,nsp_raw, statistic='mean',bins=nranges)\n",
    "pred_mult = pred_all[:,celln].copy()\n",
    "for i in range(len(edges)-1):    \n",
    "    metric_bounds = consecutive(np.where((metric>edges[i])&(metric<edges[i+1]))[0])\n",
    "    metric_bounds = [row for row in metric_bounds]\n",
    "    metric_length = [len(row) for row in metric_bounds]\n",
    "    for n, row in enumerate(metric_bounds):\n",
    "        axs2.axvspan(metric_bounds[n][0],metric_bounds[n][-1], color=colors[i], zorder=0)\n",
    "# pred_smooth_m2=((np.convolve(GLM_VisMov_m2['pred_all'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "p1 = axs2.plot(timem1,nsp_smooth[t:t+dt],'k',lw=3, label='Actual V1 Activity', alpha=.75)\n",
    "p2 = axs2.plot(timem1,pred_smooth[t:t+dt], 'r',lw=3, label='Predicted Visual $r^2$: {:.02f}'.format(GLM_VisMov_m1['r2_all'][celln]), alpha=.75)\n",
    "p3 = axs2.plot(timem1,pred_multadd_smooth_all[0,modeln,celln,t:t+dt], 'g',lw=3, label='Predicted Visual*Movement $r^2$: {:.02f}'.format(r2_mod_mult[celln,-1]), alpha=.75)\n",
    "axs2.set_xlabel('time (s)')\n",
    "axs2.set_ylabel('sp/sec')\n",
    "axs2.set_ylim((0,60))\n",
    "axs2.set_xlim((0,140))\n",
    "# axs2.set_xticks(np.arange(0,dt,60)*model_dt)\n",
    "# axs2.legend(labelcolor='linecolor', bbox_to_anchor=(.55, .7), fontsize=14, handlelength=0, handletextpad=0, fancybox=True)\n",
    "plt.tight_layout()\n",
    "# fig2.savefig(FigPath_SFN/'PredictedMod_FR.png', facecolor='white', transparent=True,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "metric_bounds = consecutive(np.where((metric>edges[i])&(metric<edges[i+1]))[0])\n",
    "temp = pred_smooth[metric_bounds[0]] \n",
    "for modeln in range(4):\n",
    "    temp = alpha_mult[celln,modeln,-1]*temp\n",
    "    print(temp)\n",
    "    plt.plot(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in range(len(nranges)-1):\n",
    "n=0\n",
    "ind = np.where(((metric<=nranges[n+1])&(metric>nranges[n])))[0]\n",
    "pred = predcell[ind]\n",
    "sp = nspcell[ind]\n",
    "stat_all, edges, _ = binned_statistic(predcell,nspcell,statistic='mean',bins=pred_rangelin)\n",
    "stat_range, edges, _ = binned_statistic(pred, sp, statistic='mean',bins=pred_rangelin)\n",
    "edge_mids = xbin_pts #np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "traces[celln,modeln,n]=stat_range\n",
    "edges_all[celln,modeln,n]=edge_mids\n",
    "res_add = minimize_scalar(f_add,args=(stat_range, stat_all))\n",
    "res_mult = minimize_scalar(f_mult,args=(stat_range, stat_all))\n",
    "mse_add[celln, modeln, n] = res_add.fun\n",
    "mse_mult[celln, modeln, n] = res_mult.fun\n",
    "alpha_add[celln, modeln, n] = res_add.x\n",
    "alpha_mult[celln, modeln, n] = res_mult.x\n",
    "\n",
    "plt.plot(edge_mids, stat_range,'.-', c=colors[n],label='{:.02f} : {:.02f}'.format(nranges[n],nranges[n+1]),lw=4,ms=20,alpha=.9)\n",
    "# plt.set_title('Metric: {}'.format(titles[modeln]), color=clrs[modeln])\n",
    "# plt.set_xlabel('Predicted Spike Rate')\n",
    "# plt.set_ylabel('Actual Spike Rate')\n",
    "plt.plot(edge_mids, stat_all,'.-', c='k', lw=5, ms=20, label='All_data', alpha=.8)\n",
    "plt.plot(edge_mids,stat_all*alpha_mult[celln,modeln,n])\n",
    "alpha_mult[celln, modeln]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_length=40\n",
    "\n",
    "for n, celln in enumerate(tqdm([13,67])):\n",
    "    fig2 = plt.figure(constrained_layout=False, figsize=(20,7))\n",
    "    spec2 = gridspec.GridSpec(ncols=nt_glm_lag, nrows=2, figure=fig2)\n",
    "    axs = np.array([fig2.add_subplot(spec2[0, n]) for n in range(nt_glm_lag)])\n",
    "    f2_ax6 = fig2.add_subplot(spec2[1, :nt_glm_lag//2])\n",
    "    f2_ax7 = fig2.add_subplot(spec2[1, nt_glm_lag//2:])\n",
    "    crange = np.max(np.abs(sta_all[celln]))\n",
    "    for n,ax in enumerate(axs):\n",
    "        im = ax.imshow(sta_all[celln,n],'RdBu_r',vmin=-crange,vmax=crange)\n",
    "        cbar = add_colorbar(im)\n",
    "        ax.axis('off')\n",
    "\n",
    "    sp_smooth = ((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    f2_ax6.plot(np.arange(len(sp_smooth))*model_dt,sp_smooth, 'k', lw=2)\n",
    "    pred_smooth = ((np.convolve(pred_all[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    f2_ax6.plot(np.arange(len(pred_smooth))*model_dt,pred_smooth,'r', lw=2)\n",
    "    f2_ax6.set_xlabel('Time (s)')\n",
    "    f2_ax6.set_ylabel('Spike Rate')\n",
    "    f2_ax7.plot(tloss_trace[:,celln])\n",
    "    f2_ax7.plot(vloss_trace[:,celln])\n",
    "    f2_ax7.set_xlabel('Batch #')\n",
    "    f2_ax7.set_ylabel('Loss')\n",
    "    r2 = (np.corrcoef(sp_smooth,pred_smooth)[0,1])**2\n",
    "    plt.suptitle('celln: {} $r^2$:{:.03f}'.format(celln, r2))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-valve",
   "metadata": {},
   "source": [
    "## Shuffle Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt=.05\n",
    "# for model_dt in [.025,.05,.1]:\n",
    "GLM_VisMov_shuff = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}_shuffled.h5'.format(model_type,int(model_dt*1000), nt_glm_lag, 1))\n",
    "GLM_VisMov_m0 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,0))\n",
    "GLM_VisMov_m1 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,1))\n",
    "GLM_VisMov_m2 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,2))\n",
    "# GLM_VisMov_m3 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,3))\n",
    "\n",
    "max_shuff = np.max(GLM_VisMov_shuff['r2_all'])\n",
    "fig,ax = plt.subplots(1,1,figsize=(7,5))\n",
    "\n",
    "sig = GLM_VisMov_m1['r2_all'][GLM_VisMov_m1['r2_all']>max_shuff]\n",
    "non_sig = GLM_VisMov_m1['r2_all'][GLM_VisMov_m1['r2_all']<max_shuff]\n",
    "non_sig_vm = GLM_VisMov_m2['r2_all'][GLM_VisMov_m2['r2_all']<max_shuff]\n",
    "\n",
    "hbins=.02\n",
    "count,edges = np.histogram(GLM_VisMov_m1['r2_all'],bins=np.arange(0,1,hbins))\n",
    "count_m2,edges_m2 = np.histogram(GLM_VisMov_m2['r2_all'],bins=np.arange(0,1,hbins))\n",
    "count_shuff,edges_shuff = np.histogram(non_sig,bins=np.arange(0,1,hbins))\n",
    "edges_mid = np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "edges_mid_m2 = np.array([(edges_m2[i]+edges_m2[i+1])/2 for i in range(len(edges_m2)-1)])\n",
    "edges_mid_shuff = np.array([(edges_shuff[i]+edges_shuff[i+1])/2 for i in range(len(edges_shuff)-1)])\n",
    "ax.bar(edges_mid, count/len(GLM_VisMov_m1['r2_all']),color='k',width=hbins,alpha=.5, label='Significant $R^2$')\n",
    "ax.bar(edges_mid_m2, count_m2/len(GLM_VisMov_m2['r2_all']),color='b',width=hbins,alpha=.5, label='Significant VisMov $R^2$')\n",
    "ax.bar(edges_mid_shuff, count_shuff/len(GLM_VisMov_shuff['r2_all']),color='r',width=hbins,alpha=1, label='NonSignificant $R^2$')\n",
    "ax.set_xlabel('$R^2$')\n",
    "ax.set_yticks(np.arange(0,1,.1))\n",
    "ax.set_yticklabels(np.round(np.arange(0,1,.1),decimals=3))\n",
    "ax.set_xlim(-.01,.5)\n",
    "ax.set_ylim(0,.2)\n",
    "ax.legend(fontsize=12,loc=(.3,.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-scope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM_VisMov_m0 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,0))\n",
    "GLM_VisMov_m1 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,1))\n",
    "GLM_VisMov_m2 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,2))\n",
    "r_vpm = GLM_VisMov_m1['r2_all']+GLM_VisMov_m0['r2_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_max = np.max((GLM_VisMov_m0['r2_all'],GLM_VisMov_m1['r2_all'],GLM_VisMov_m2['r2_all']))+1.5*np.std((GLM_VisMov_m0['r2_all'],GLM_VisMov_m1['r2_all'],GLM_VisMov_m2['r2_all']))\n",
    "lims = (0, lim_max)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.scatter(GLM_VisMov_m1['r2_all'],GLM_VisMov_m2['r2_all'],2,c='k',label='Significant $R^2$')\n",
    "# ax.scatter(non_sig,non_sig,c='r', label='Nonsignificant $R^2$')\n",
    "ax.plot(np.linspace(lims[0],lims[1]),np.linspace(lims[0],lims[1]),'k--',zorder=0)\n",
    "ax.legend(fontsize=12,loc=(.3,.9))\n",
    "ax.set_xlabel('Visual only $R^2$')\n",
    "ax.set_ylabel('VisMov $R^2$')\n",
    "rect = patches.Rectangle((0,0), max_shuff, max_shuff, linewidth=1, edgecolor='r', facecolor='r')\n",
    "ax.add_patch(rect)\n",
    "for i, txt in enumerate(np.arange(ncells)):\n",
    "    ax.annotate(txt, (GLM_VisMov_m1['r2_all'][i], GLM_VisMov_m2['r2_all'][i]),fontsize=10)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FigPath/'M1M2_R2_Comparison.png', facecolor='white', transparent=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.scatter(GLM_VisMov_m0['r2_all'],GLM_VisMov_m2['r2_all'],2,c='k',label='Significant $R^2$')\n",
    "# ax.scatter(non_sig,non_sig_vm,c='r', label='Nonsignificant $R^2$')\n",
    "ax.plot(np.linspace(lims[0],lims[1]),np.linspace(lims[0],lims[1]),'k--',zorder=0)\n",
    "ax.legend(fontsize=12,loc=(.3,.9))\n",
    "ax.set_xlabel('Movement Only $R^2$')\n",
    "ax.set_ylabel('VisMov $R^2$')\n",
    "rect = patches.Rectangle((0,0), max_shuff, max_shuff, linewidth=1, edgecolor='r', facecolor='r')\n",
    "ax.add_patch(rect)\n",
    "for i, txt in enumerate(np.arange(ncells)):\n",
    "    ax.annotate(txt, (GLM_VisMov_m0['r2_all'][i], GLM_VisMov_m2['r2_all'][i]),fontsize=10)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FigPath/'M0M2_R2_Comparison.png', facecolor='white', transparent=True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.scatter(GLM_VisMov_m0['r2_all'],GLM_VisMov_m1['r2_all'],2,c='k',label='Significant $R^2$')\n",
    "# ax.scatter(non_sig,non_sig_vm,c='r', label='Nonsiagnificant $R^2$')\n",
    "ax.plot(np.linspace(lims[0],lims[1]),np.linspace(lims[0],lims[1]),'k--',zorder=0)\n",
    "ax.legend(fontsize=12,loc=(.3,.9))\n",
    "ax.set_xlabel('Movement Only $R^2$')\n",
    "ax.set_ylabel('Visual $R^2$')\n",
    "rect = patches.Rectangle((0,0), max_shuff, max_shuff, linewidth=1, edgecolor='r', facecolor='r')\n",
    "ax.add_patch(rect)\n",
    "for i, txt in enumerate(np.arange(ncells)):\n",
    "    ax.annotate(txt, (GLM_VisMov_m0['r2_all'][i], GLM_VisMov_m1['r2_all'][i]),fontsize=10)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FigPath/'M0M1_R2_Comparison.png', facecolor='white', transparent=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.scatter(r_vpm,GLM_VisMov_m2['r2_all'],2,c='k',label='Significant $R^2$')\n",
    "# ax.scatter(non_sig,non_sig_vm,c='r', label='Nonsiagnificant $R^2$')\n",
    "ax.plot(np.linspace(lims[0],lims[1]),np.linspace(lims[0],lims[1]),'k--',zorder=0)\n",
    "ax.legend(fontsize=12,loc=(.3,.9))\n",
    "ax.set_xlabel('V+M $R^2$')\n",
    "ax.set_ylabel('VisMov $R^2$')\n",
    "rect = patches.Rectangle((0,0), max_shuff, max_shuff, linewidth=1, edgecolor='r', facecolor='r')\n",
    "ax.add_patch(rect)\n",
    "for i, txt in enumerate(np.arange(ncells)):\n",
    "    ax.annotate(txt, (r_vpm[i], GLM_VisMov_m2['r2_all'][i]),fontsize=10)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FigPath/'VPM_R2_Comparison.png', facecolor='white', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-prescription",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cutting-theater",
   "metadata": {},
   "source": [
    "## Plotting Motor Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_length=40\n",
    "data, train_idx, test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=do_shuffle, do_norm=False,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "locals().update(data)\n",
    "# if do_shuffle:\n",
    "#     save_datafile = save_dir/'GLM_{}_Data_Mov_dt{:03d}_T{:02d}_MovModel{:d}_shuffled.h5'.format(model_type,int(model_dt*1000), nt_glm_lag, MovModel)\n",
    "# else:\n",
    "#     save_datafile = save_dir/'GLM_{}_Data_Mov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,MovModel)\n",
    "# GLM_Vis = ioh5.load(save_datafile)\n",
    "# locals().update(GLM_Vis)\n",
    "##### Explore Neurons #####\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "# Initialize movement combinations\n",
    "titles = np.array(['Theta','Phi','Roll','Pitch']) # 'dg_p','dg_n' 'roll','pitch'\n",
    "titles_all = []\n",
    "for n in range(1,len(titles)+1):\n",
    "    perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "    for ind in range(perms.shape[0]):\n",
    "        titles_all.append('_'.join([t for t in titles[perms[ind]]]))\n",
    "\n",
    "# train_dgaze_p = train_dth + np.diff(train_gz,append=0)\n",
    "# train_dgaze_n = train_dth - np.diff(train_gz,append=0)\n",
    "# test_dgaze_p = test_dth + np.diff(test_gz,append=0)\n",
    "# test_dgaze_n = test_dth - np.diff(test_gz,append=0)\n",
    "move_train = np.hstack((train_th[:,np.newaxis],train_phi[:,np.newaxis],train_roll[:,np.newaxis],train_pitch[:,np.newaxis]))#, train_dth[:,np.newaxis],train_dphi[:,np.newaxis]))\n",
    "move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_roll[:,np.newaxis],test_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "# move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))# test_dth[:,np.newaxis],test_dphi[:,np.newaxis]))\n",
    "model_move = np.hstack((model_th[:,np.newaxis],model_phi[:,np.newaxis],model_roll[:,np.newaxis],model_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "model_move = model_move - np.mean(model_move,axis=0)\n",
    "move_test = move_test - np.mean(move_test,axis=0)\n",
    "# Create all tuning curves for plotting\n",
    "N_bins=10\n",
    "ncells = model_nsp.shape[-1]\n",
    "ax_ylims = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "tuning_curves = np.zeros((model_nsp.shape[-1],len(titles),N_bins-1))\n",
    "tuning_stds = np.zeros((model_nsp.shape[-1],len(titles),N_bins-1))\n",
    "var_ranges = np.zeros((len(titles),N_bins-1))\n",
    "for modeln in range(len(titles)):\n",
    "    metric = move_test[:,modeln]\n",
    "    tuning, tuning_std, var_range = tuning_curve(test_nsp, metric, N_bins=N_bins, model_dt=model_dt)\n",
    "    tuning_curves[:,modeln] = tuning\n",
    "    tuning_stds[:,modeln] = tuning_std\n",
    "    ax_ylims[:,modeln] = np.max(tuning,axis=1)\n",
    "    var_ranges[modeln] = var_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 49 #np.argmax(mr2)\n",
    "bin_length = 40\n",
    "ncells=model_nsp.shape[-1]\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "quartiles = np.arange(0,1.25,.25)\n",
    "\n",
    "fig, axs = plt.subplots(2,5, figsize=((35,10))) \n",
    "\n",
    "predcell = pred_all[:,celln]/model_dt\n",
    "nspcell = test_nsp[:,celln]/model_dt\n",
    "test_nsp_smooth=(np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt)\n",
    "pred_smooth=(np.convolve(pred_all[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt)\n",
    "# Set up predicted spike range between 1-99th percentile\n",
    "stat_bins = 5\n",
    "pred_range = np.quantile(predcell,[.1,.9])\n",
    "test_nsp_range = np.quantile(nspcell,[.01,1])\n",
    "spike_percentiles = np.arange(0,1.25,.25)\n",
    "spike_percentiles[-1]=.99\n",
    "spk_percentile2 = np.arange(.125,1.125,.25)\n",
    "pred_rangelin = np.quantile(predcell,spike_percentiles)\n",
    "xbin_pts = np.quantile(predcell,spk_percentile2)\n",
    "stat_bins = len(pred_rangelin) #5\n",
    "\n",
    "\n",
    "axs[0,0].plot(np.arange(len(test_nsp_smooth))*model_dt,test_nsp_smooth,'k',label='test FR')\n",
    "axs[0,0].plot(np.arange(len(pred_smooth))*model_dt,pred_smooth,'r', label='pred FR')\n",
    "axs[0,0].set_xlabel('Time (s)')\n",
    "axs[0,0].set_ylabel('Firing Rate (spks/s)')\n",
    "axs[0,0].legend()\n",
    "axs[0,0].set_title('Smoothed FRs')\n",
    "\n",
    "# Eye Tuning Curve\n",
    "top_yaxs = np.max(ax_ylims[celln])+2*np.max(tuning_stds[celln])\n",
    "for i,modeln in enumerate(range(len(titles)-2)):\n",
    "    metric = move_test[:,modeln]\n",
    "    nranges = np.quantile(metric,quartiles)\n",
    "    stat_range, edges, _ = binned_statistic(metric,test_nsp[:,celln],statistic='mean',bins=nranges)\n",
    "    edge_mids = np.quantile(metric,spk_percentile2)#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    cmap = mpl.colors.ListedColormap(colors, N=colors.shape[0])\n",
    "    norm = mpl.colors.BoundaryNorm(boundaries=np.floor(nranges), ncolors=len(cmap.colors))\n",
    "    for m in range(len(nranges)-1):\n",
    "        axs[0,1].axvspan(nranges[m], nranges[m+1],ymin=i*1/2,ymax=(i+1)*1/2,alpha=0.8, color=colors[m],zorder=0)\n",
    "    #     axs[0,1].errorbar(var_ranges[modeln],tuning_curves[celln,modeln], yerr=tuning_stds[celln,modeln],label=titles[modeln],c=clrs[modeln],lw=4,elinewidth=3)\n",
    "    axs[0,1].plot(edge_mids,stat_range/model_dt,'.-', ms=20, lw=4,c=clrs[modeln])\n",
    "\n",
    "axs[0,1].set_ylim(bottom=0,top=np.max(ax_ylims,axis=1)[celln]+2*np.max(tuning_stds,axis=(1,2))[celln])\n",
    "axs[0,1].set_xlim(-30,30)\n",
    "axs[0,1].set_xlabel('Angle ($ ^{\\degree}$)')\n",
    "axs[0,1].set_ylabel('Spikes/s')\n",
    "axs[0,1].set_title('Eye Tuning Curves')\n",
    "lines = axs[0,1].get_lines()\n",
    "legend1 = axs[0,1].legend([lines[0]],[titles[0]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "legend2 = axs[0,1].legend([lines[1]],[titles[1]],bbox_to_anchor=(1.01, .9), fontsize=12)\n",
    "axs[0,1].add_artist(legend1)\n",
    "\n",
    "# Head Tuning Curves\n",
    "top_yaxs = np.max(ax_ylims[celln])+2*np.max(tuning_stds[celln])\n",
    "for i, modeln in enumerate(range(2,len(titles))):\n",
    "    metric = move_test[:,modeln]\n",
    "#     nranges = np.round(np.quantile(var_ranges[modeln],quartiles),decimals=1)\n",
    "    nranges = np.round(np.quantile(metric,quartiles),decimals=1)\n",
    "    stat_range, edges, _ = binned_statistic(metric,test_nsp[:,celln],statistic='mean',bins=nranges)\n",
    "    edge_mids = np.quantile(metric,spk_percentile2)#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    cmap = mpl.colors.ListedColormap(colors, N=colors.shape[0])\n",
    "    norm = mpl.colors.BoundaryNorm(boundaries=np.floor(nranges), ncolors=len(cmap.colors))\n",
    "    for m in range(len(nranges)-1):\n",
    "        axs[0,2].axvspan(nranges[m], nranges[m+1],ymin=i*1/2,ymax=(i+1)*1/2,alpha=0.8, color=colors[m],zorder=0)\n",
    "#     axs[0,2].errorbar(var_ranges[modeln], tuning_curves[celln,modeln], yerr=tuning_stds[celln,modeln], label=titles[modeln], c=clrs[modeln],lw=4,elinewidth=3)\n",
    "    axs[0,2].plot(edge_mids,stat_range/model_dt,'.-', ms=20, lw=4,c=clrs[modeln])\n",
    "\n",
    "axs[0,2].set_ylim(bottom=0,top=top_yaxs)\n",
    "axs[0,2].set_xlim(-30,30)\n",
    "axs[0,2].set_xlabel('Angle ($ ^{\\degree}$)')\n",
    "axs[0,2].set_ylabel('Spikes/s')\n",
    "axs[0,2].set_title('Head Tuning Curves')\n",
    "lines = axs[0,2].get_lines()\n",
    "legend1 = axs[0,2].legend([lines[0]],[titles[2]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "legend2 = axs[0,2].legend([lines[1]],[titles[3]],bbox_to_anchor=(1.01, .9), fontsize=12)\n",
    "axs[0,2].add_artist(legend1)\n",
    "\n",
    "# axs[0,2].legend(bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "\n",
    "\n",
    "# pred_rangelin = np.linspace(pred_range[0],pred_range[1],stat_bins)\n",
    "axs[0,3].scatter(pred_all[celln]/model_dt,test_nsp[celln]/model_dt,c='k',s=15)\n",
    "axs[0,3].plot(np.linspace(test_nsp_range[0],test_nsp_range[1]),np.linspace(test_nsp_range[0],test_nsp_range[1]),'k--',zorder=0)\n",
    "axs[0,3].set_xlabel('Predicted Spike Rate')\n",
    "axs[0,3].set_ylabel('Actual Spike Rate')\n",
    "\n",
    "# cbar = add_colorbar(img)\n",
    "# cbar.set_label('count')\n",
    "\n",
    "if MovModel == 1:\n",
    "    w_move = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "elif MovModel == 3:\n",
    "    Msta = w_move[:,:-len(titles)].reshape((model_nsp.shape[-1],nt_glm_lag,len(titles))+nks)\n",
    "    w_move = w_move[:,-len(titles):]\n",
    "for modeln in range(len(titles)):\n",
    "    axs[0,4].bar(modeln, w_move[celln,modeln], color=clrs[modeln])\n",
    "    axs[0,4].set_xticks(np.arange(0,len(titles)))\n",
    "    axs[0,4].set_xticklabels(titles)\n",
    "    axs[0,4].set_ylabel('GLM Weight')\n",
    "\n",
    "\n",
    "mse_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "mse_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "alpha_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "alpha_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "\n",
    "traces = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "traces_mean = np.zeros((ncells,len(titles),stat_bins-1)) # (model_type,quartile,FR)\n",
    "edges_all = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "# df_traces = pd.DataFrame([],columns=['modeln','quartile','FR']) \n",
    "for modeln in range(len(titles)):\n",
    "    metric = move_test[:,modeln]\n",
    "    nranges = np.quantile(metric,quartiles)# np.linspace(np.nanmean(metric)-2*np.nanstd(metric), np.nanmean(metric)+2*np.nanstd(metric),N_bins)\n",
    "    stat_all, edges, _ = binned_statistic(predcell,nspcell, statistic='mean',bins=pred_rangelin)\n",
    "    edge_mids = xbin_pts#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    traces_mean[celln,modeln]=stat_all\n",
    "    max_fr = np.max(stat_all)\n",
    "#     axs[0,modeln].set_xlim(0,pred_range[1]+np.std(pred_range))\n",
    "#     axs[0,modeln].set_ylim(0,np.max(stat)+np.std(stat))\n",
    "\n",
    "    for n in range(len(nranges)-1):\n",
    "        ind = np.where(((metric<=nranges[n+1])&(metric>nranges[n])))[0]\n",
    "        pred = predcell[ind]\n",
    "        sp = nspcell[ind]\n",
    "\n",
    "        stat_range, edges, _ = binned_statistic(pred, sp, statistic='mean',bins=pred_rangelin)\n",
    "        edge_mids = xbin_pts #np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "        traces[celln,modeln,n]=stat_range\n",
    "        edges_all[celln,modeln,n]=edge_mids\n",
    "        res_add = minimize_scalar(f_add,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "        res_mult = minimize_scalar(f_mult,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "        mse_add[celln, modeln, n] = res_add.fun\n",
    "        mse_mult[celln, modeln, n] = res_mult.fun\n",
    "        alpha_add[celln, modeln, n] = res_add.x\n",
    "        alpha_mult[celln, modeln, n] = res_mult.x\n",
    "\n",
    "        axs[1,modeln].plot(edge_mids, stat_range,'.-', c=colors[n],label='{:.02f} : {:.02f}'.format(nranges[n],nranges[n+1]),lw=4,ms=20,alpha=.9)\n",
    "        axs[1,modeln].set_title('Metric: {}'.format(titles[modeln]), color=clrs[modeln])\n",
    "        axs[1,modeln].set_xlabel('Predicted Spike Rate')\n",
    "        axs[1,modeln].set_ylabel('Actual Spike Rate')\n",
    "    \n",
    "    axs[1,modeln].plot([0, 1], [0, 1], 'k--', transform=axs[1,modeln].transAxes, lw=2, zorder=0)\n",
    "    axs[1,modeln].plot(edge_mids, stat_all,'.-', c='k', lw=5, ms=20, label='All_data', alpha=.8)\n",
    "    axs[1,modeln].legend(bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "#     axs[1,modeln].axis('equal')\n",
    "    axs[1,modeln].set_xlim(left=0)\n",
    "#     axs[1,modeln].set(xlim=lims, ylim=lims)\n",
    "#     axs[1,modeln].set_xlim([0,xbin_pts[-1]])\n",
    "    axs[1,modeln].set_ylim(bottom=0)\n",
    "\n",
    "dmodel = mse_add[celln]-mse_mult[celln]\n",
    "crange = np.max(np.abs(dmodel))\n",
    "im = axs[1,-1].imshow(dmodel,cmap='seismic',vmin=-crange,vmax=crange)\n",
    "axs[1,-1].set_yticks(np.arange(0,4))\n",
    "axs[1,-1].set_yticklabels(titles)\n",
    "axs[1,-1].set_ylabel('Movement Model')\n",
    "axs[1,-1].set_xticks(np.arange(0,4))\n",
    "axs[1,-1].set_xticklabels(['.25','.5','.75','1'])\n",
    "axs[1,-1].set_xlabel('Quantile Range')\n",
    "axs[1,-1].set_title('$MSE_{add}$ - $MSE_{mult}$')\n",
    "cbar = add_colorbar(im)\n",
    "\n",
    "plt.suptitle('Celln:{}, r2={:.03f}'.format(celln,r2_all[celln]),y=1,fontsize=30)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# fig.savefig(FigPath/'CellSummary_N{}_T{:02d}.png'.format(celln,nt_glm_lag), facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Make PDF of All Cells #####\n",
    "bin_length=40\n",
    "MovModel = 1\n",
    "do_shuffle = False\n",
    "ncells=model_nsp.shape[-1]\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "for model_dt in [.05]: #\n",
    "    data, train_idx, test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=do_shuffle, do_norm=False,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "    locals().update(data)\n",
    "    if do_shuffle:\n",
    "        GLM_Vis = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}_shuffled.h5'.format(model_type,int(model_dt*1000), nt_glm_lag, MovModel))\n",
    "    else:\n",
    "        GLM_Vis = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,MovModel))\n",
    "    locals().update(GLM_Vis)\n",
    "    ##### Explore Neurons #####\n",
    "    colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "    clrs = ['blue','orange','green','red']\n",
    "    # Initialize movement combinations\n",
    "    titles = np.array(['Theta','Phi','Roll','Pitch']) # 'dg_p','dg_n' 'roll','pitch'\n",
    "    titles_all = []\n",
    "    for n in range(1,len(titles)+1):\n",
    "        perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "        for ind in range(perms.shape[0]):\n",
    "            titles_all.append('_'.join([t for t in titles[perms[ind]]]))\n",
    "\n",
    "    # train_dgaze_p = train_dth + np.diff(train_gz,append=0)\n",
    "    # train_dgaze_n = train_dth - np.diff(train_gz,append=0)\n",
    "    # test_dgaze_p = test_dth + np.diff(test_gz,append=0)\n",
    "    # test_dgaze_n = test_dth - np.diff(test_gz,append=0)\n",
    "    move_train = np.hstack((train_th[:,np.newaxis],train_phi[:,np.newaxis],train_roll[:,np.newaxis],train_pitch[:,np.newaxis]))#, train_dth[:,np.newaxis],train_dphi[:,np.newaxis]))\n",
    "    move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_roll[:,np.newaxis],test_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "    # move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))# test_dth[:,np.newaxis],test_dphi[:,np.newaxis]))\n",
    "    model_move = np.hstack((model_th[:,np.newaxis],model_phi[:,np.newaxis],model_roll[:,np.newaxis],model_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "    model_move = model_move - np.mean(model_move,axis=0)\n",
    "    move_test = move_test - np.mean(move_test,axis=0)\n",
    "    \n",
    "    # Create all tuning curves for plotting\n",
    "    N_bins=10\n",
    "    ncells = model_nsp.shape[-1]\n",
    "    ax_ylims = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "    tuning_curves = np.zeros((model_nsp.shape[-1],len(titles),N_bins-1))\n",
    "    tuning_stds = np.zeros((model_nsp.shape[-1],len(titles),N_bins-1))\n",
    "    var_ranges = np.zeros((len(titles),N_bins-1))\n",
    "    for modeln in range(len(titles)):\n",
    "        metric = move_test[:,modeln]\n",
    "        tuning, tuning_std, var_range = tuning_curve(test_nsp, metric, N_bins=N_bins, model_dt=model_dt)\n",
    "        tuning_curves[:,modeln] = tuning\n",
    "        tuning_stds[:,modeln] = tuning_std\n",
    "        ax_ylims[:,modeln] = np.max(tuning,axis=1)\n",
    "        var_ranges[modeln] = var_range\n",
    "        \n",
    "    quartiles = np.arange(0,1.25,.25)\n",
    "    if do_shuffle:\n",
    "        pdf_name = FigPath/ 'VisMov_dt{:03d}_T{:02d}_MovModel{:d}_CellSummary_shuff.pdf'.format(model_type,int(model_dt*1000), nt_glm_lag, MovModel)\n",
    "    else:\n",
    "        pdf_name = FigPath/ 'VisMov_dt{:03d}_T{:02d}_MovModel{:d}_CellSummary.pdf'.format(model_type,int(model_dt*1000),nt_glm_lag, MovModel)\n",
    "    with PdfPages(pdf_name) as pdf:\n",
    "        for celln in tqdm(range(model_nsp.shape[1])):            \n",
    "\n",
    "            fig, axs = plt.subplots(2,5, figsize=((35,10))) \n",
    "\n",
    "            predcell = pred_all[:,celln]/model_dt\n",
    "            nspcell = test_nsp[:,celln]/model_dt\n",
    "            test_nsp_smooth=(np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt)\n",
    "            pred_smooth=(np.convolve(pred_all[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt)\n",
    "            # Set up predicted spike range between 1-99th percentile\n",
    "            stat_bins = 5\n",
    "            pred_range = np.quantile(predcell,[.1,.9])\n",
    "            test_nsp_range = np.quantile(nspcell,[.01,1])\n",
    "            spike_percentiles = np.arange(0,1.25,.25)\n",
    "            spike_percentiles[-1]=.99\n",
    "            spk_percentile2 = np.arange(.125,1.125,.25)\n",
    "            pred_rangelin = np.quantile(predcell,spike_percentiles)\n",
    "            xbin_pts = np.quantile(predcell,spk_percentile2)\n",
    "            stat_bins = len(pred_rangelin) #5\n",
    "\n",
    "\n",
    "            axs[0,0].plot(np.arange(len(test_nsp_smooth))*model_dt,test_nsp_smooth,'k',label='test FR')\n",
    "            axs[0,0].plot(np.arange(len(pred_smooth))*model_dt,pred_smooth,'r', label='pred FR')\n",
    "            axs[0,0].set_xlabel('Time (s)')\n",
    "            axs[0,0].set_ylabel('Firing Rate (spks/s)')\n",
    "            axs[0,0].legend()\n",
    "            axs[0,0].set_title('Smoothed FRs')\n",
    "\n",
    "            # Eye Tuning Curve\n",
    "            top_yaxs = np.max(ax_ylims[celln])+2*np.max(tuning_stds[celln])\n",
    "            for i,modeln in enumerate(range(len(titles)-2)):\n",
    "                metric = move_test[:,modeln]\n",
    "                nranges = np.quantile(metric,quartiles)\n",
    "                stat_range, edges, _ = binned_statistic(metric,test_nsp[:,celln],statistic='mean',bins=nranges)\n",
    "                edge_mids = np.quantile(metric,spk_percentile2)#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "                cmap = mpl.colors.ListedColormap(colors, N=colors.shape[0])\n",
    "                norm = mpl.colors.BoundaryNorm(boundaries=np.floor(nranges), ncolors=len(cmap.colors))\n",
    "                for m in range(len(nranges)-1):\n",
    "                    axs[0,1].axvspan(nranges[m], nranges[m+1],ymin=i*1/2,ymax=(i+1)*1/2,alpha=0.8, color=colors[m],zorder=0)\n",
    "                #     axs[0,1].errorbar(var_ranges[modeln],tuning_curves[celln,modeln], yerr=tuning_stds[celln,modeln],label=titles[modeln],c=clrs[modeln],lw=4,elinewidth=3)\n",
    "                axs[0,1].plot(edge_mids,stat_range/model_dt,'.-', ms=20, lw=4,c=clrs[modeln])\n",
    "\n",
    "            axs[0,1].set_ylim(bottom=0,top=np.max(ax_ylims,axis=1)[celln]+2*np.max(tuning_stds,axis=(1,2))[celln])\n",
    "            axs[0,1].set_xlim(-30,30)\n",
    "            axs[0,1].set_xlabel('Angle ($ ^{\\degree}$)')\n",
    "            axs[0,1].set_ylabel('Spikes/s')\n",
    "            axs[0,1].set_title('Eye Tuning Curves')\n",
    "            lines = axs[0,1].get_lines()\n",
    "            legend1 = axs[0,1].legend([lines[0]],[titles[0]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "            legend2 = axs[0,1].legend([lines[1]],[titles[1]],bbox_to_anchor=(1.01, .9), fontsize=12)\n",
    "            axs[0,1].add_artist(legend1)\n",
    "\n",
    "            # Head Tuning Curves\n",
    "            top_yaxs = np.max(ax_ylims[celln])+2*np.max(tuning_stds[celln])\n",
    "            for i, modeln in enumerate(range(2,len(titles))):\n",
    "                metric = move_test[:,modeln]\n",
    "            #     nranges = np.round(np.quantile(var_ranges[modeln],quartiles),decimals=1)\n",
    "                nranges = np.round(np.quantile(metric,quartiles),decimals=1)\n",
    "                stat_range, edges, _ = binned_statistic(metric,test_nsp[:,celln],statistic='mean',bins=nranges)\n",
    "                edge_mids = np.quantile(metric,spk_percentile2)#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "                cmap = mpl.colors.ListedColormap(colors, N=colors.shape[0])\n",
    "                norm = mpl.colors.BoundaryNorm(boundaries=np.floor(nranges), ncolors=len(cmap.colors))\n",
    "                for m in range(len(nranges)-1):\n",
    "                    axs[0,2].axvspan(nranges[m], nranges[m+1],ymin=i*1/2,ymax=(i+1)*1/2,alpha=0.8, color=colors[m],zorder=0)\n",
    "            #     axs[0,2].errorbar(var_ranges[modeln], tuning_curves[celln,modeln], yerr=tuning_stds[celln,modeln], label=titles[modeln], c=clrs[modeln],lw=4,elinewidth=3)\n",
    "                axs[0,2].plot(edge_mids,stat_range/model_dt,'.-', ms=20, lw=4,c=clrs[modeln])\n",
    "\n",
    "            axs[0,2].set_ylim(bottom=0,top=top_yaxs)\n",
    "            axs[0,2].set_xlim(-30,30)\n",
    "            axs[0,2].set_xlabel('Angle ($ ^{\\degree}$)')\n",
    "            axs[0,2].set_ylabel('Spikes/s')\n",
    "            axs[0,2].set_title('Head Tuning Curves')\n",
    "            lines = axs[0,2].get_lines()\n",
    "            legend1 = axs[0,2].legend([lines[0]],[titles[2]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "            legend2 = axs[0,2].legend([lines[1]],[titles[3]],bbox_to_anchor=(1.01, .9), fontsize=12)\n",
    "            axs[0,2].add_artist(legend1)\n",
    "\n",
    "            # axs[0,2].legend(bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "\n",
    "\n",
    "            # pred_rangelin = np.linspace(pred_range[0],pred_range[1],stat_bins)\n",
    "            axs[0,3].scatter(pred_all[celln]/model_dt,test_nsp[celln]/model_dt,c='k',s=15)\n",
    "            axs[0,3].plot(np.linspace(test_nsp_range[0],test_nsp_range[1]),np.linspace(test_nsp_range[0],test_nsp_range[1]),'k--',zorder=0)\n",
    "            axs[0,3].set_xlabel('Predicted Spike Rate')\n",
    "            axs[0,3].set_ylabel('Actual Spike Rate')\n",
    "            cbar = add_colorbar(img)\n",
    "            # cbar.set_label('count')\n",
    "\n",
    "            if MovModel == 1:\n",
    "                w_move = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "            elif MovModel == 3:\n",
    "                Msta = w_move[:,:-len(titles)].reshape((model_nsp.shape[-1],nt_glm_lag,len(titles))+nks)\n",
    "                w_move = w_move[:,-len(titles):]\n",
    "            for modeln in range(len(titles)):\n",
    "                axs[0,4].bar(modeln, w_move[celln,modeln], color=clrs[modeln])\n",
    "                axs[0,4].set_xticks(np.arange(0,len(titles)))\n",
    "                axs[0,4].set_xticklabels(titles)\n",
    "                axs[0,4].set_ylabel('GLM Weight')\n",
    "\n",
    "\n",
    "            mse_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "            mse_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "            alpha_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "            alpha_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "\n",
    "            traces = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "            traces_mean = np.zeros((ncells,len(titles),stat_bins-1)) # (model_type,quartile,FR)\n",
    "            edges_all = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "            # df_traces = pd.DataFrame([],columns=['modeln','quartile','FR']) \n",
    "            for modeln in range(len(titles)):\n",
    "                metric = move_test[:,modeln]\n",
    "                nranges = np.quantile(metric,quartiles)# np.linspace(np.nanmean(metric)-2*np.nanstd(metric), np.nanmean(metric)+2*np.nanstd(metric),N_bins)\n",
    "                stat_all, edges, _ = binned_statistic(predcell,nspcell, statistic='mean',bins=pred_rangelin)\n",
    "                edge_mids = xbin_pts#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "                traces_mean[celln,modeln]=stat_all\n",
    "                max_fr = np.max(stat_all)\n",
    "            #     axs[0,modeln].set_xlim(0,pred_range[1]+np.std(pred_range))\n",
    "            #     axs[0,modeln].set_ylim(0,np.max(stat)+np.std(stat))\n",
    "\n",
    "                for n in range(len(nranges)-1):\n",
    "                    ind = np.where(((metric<=nranges[n+1])&(metric>nranges[n])))[0]\n",
    "                    pred = predcell[ind]\n",
    "                    sp = nspcell[ind]\n",
    "\n",
    "                    stat_range, edges, _ = binned_statistic(pred, sp, statistic='mean',bins=pred_rangelin)\n",
    "                    edge_mids = xbin_pts #np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "                    traces[celln,modeln,n]=stat_range\n",
    "                    edges_all[celln,modeln,n]=edge_mids\n",
    "                    res_add = minimize_scalar(f_add,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "                    res_mult = minimize_scalar(f_mult,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "                    mse_add[celln, modeln, n] = res_add.fun\n",
    "                    mse_mult[celln, modeln, n] = res_mult.fun\n",
    "                    alpha_add[celln, modeln, n] = res_add.x\n",
    "                    alpha_mult[celln, modeln, n] = res_mult.x\n",
    "\n",
    "                    axs[1,modeln].plot(edge_mids, stat_range,'.-', c=colors[n],label='{:.02f} : {:.02f}'.format(nranges[n],nranges[n+1]),lw=4,ms=20,alpha=.9)\n",
    "                    axs[1,modeln].set_title('Metric: {}'.format(titles[modeln]), color=clrs[modeln])\n",
    "                    axs[1,modeln].set_xlabel('Predicted Spike Rate')\n",
    "                    axs[1,modeln].set_ylabel('Actual Spike Rate')\n",
    "\n",
    "                axs[1,modeln].plot([0, 1], [0, 1], 'k--', transform=axs[1,modeln].transAxes, lw=2, zorder=0)\n",
    "                axs[1,modeln].plot(edge_mids, stat_all,'.-', c='k', lw=5, ms=20, label='All_data', alpha=.8)\n",
    "                axs[1,modeln].legend(bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "            #     axs[1,modeln].axis('equal')\n",
    "                axs[1,modeln].set_xlim(left=0)\n",
    "            #     axs[1,modeln].set(xlim=lims, ylim=lims)\n",
    "            #     axs[1,modeln].set_xlim([0,xbin_pts[-1]])\n",
    "                axs[1,modeln].set_ylim(bottom=0)\n",
    "\n",
    "            dmodel = mse_add[celln]-mse_mult[celln]\n",
    "            crange = np.max(np.abs(dmodel))\n",
    "            im = axs[1,-1].imshow(dmodel,cmap='seismic',vmin=-crange,vmax=crange)\n",
    "            axs[1,-1].set_yticks(np.arange(0,4))\n",
    "            axs[1,-1].set_yticklabels(titles)\n",
    "            axs[1,-1].set_ylabel('Movement Model')\n",
    "            axs[1,-1].set_xticks(np.arange(0,4))\n",
    "            axs[1,-1].set_xticklabels(['.25','.5','.75','1'])\n",
    "            axs[1,-1].set_xlabel('Quantile Range')\n",
    "            axs[1,-1].set_title('$MSE_{add}$ - $MSE_{mult}$')\n",
    "            cbar = add_colorbar(im)\n",
    "\n",
    "            plt.suptitle('Celln:{}, r2={:.03f}'.format(celln,r2_all[celln]),y=1,fontsize=30)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "    # fig.savefig(FigPath/'CellSummary_N{}.png'.format(celln), facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_length= 40\n",
    "fig, axs = plt.subplots(figsize=(15,5))\n",
    "test_nsp_smooth=(np.convolve(GLM_VisMov_m2['test_nsp'][:,21], np.ones(bin_length), 'same')) / (bin_length * model_dt)\n",
    "pred_smooth=(np.convolve(GLM_VisMov_m2['pred_all'][:,21], np.ones(bin_length), 'same')) / (bin_length * model_dt)\n",
    "axs.plot(np.arange(len(test_nsp_smooth))*model_dt,test_nsp_smooth,'k',label='test FR')\n",
    "axs.plot(np.arange(len(pred_smooth))*model_dt,pred_smooth,'r', label='pred FR')\n",
    "axs.set_xlabel('Time (s)')\n",
    "axs.set_ylabel('Firing Rate (spks/s)')\n",
    "axs.legend()\n",
    "axs.set_title('Smoothed FRs')\n",
    "plt.tight_layout()\n",
    "fig.savefig(FigPath/'TestPred_example.png', facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-mainstream",
   "metadata": {},
   "source": [
    "## Test Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "celln = 49# np.argmax(r2_all)\n",
    "bin_length = 40\n",
    "ncells = model_nsp.shape[-1]\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "quartiles = np.arange(0,1.25,.25)\n",
    "bin_length=40\n",
    "alph = 0#malph[celln]\n",
    "lam = 0 #mlam[celln]\n",
    "for n, celln in enumerate(tqdm([21,49,51,25,117,125,126])):\n",
    "    fig2 = plt.figure(constrained_layout=False, figsize=(20,7))\n",
    "    spec2 = gridspec.GridSpec(ncols=nt_glm_lag, nrows=2, figure=fig2)\n",
    "    axs = np.array([fig2.add_subplot(spec2[0, n]) for n in range(nt_glm_lag)])\n",
    "    f2_ax6 = fig2.add_subplot(spec2[1, :nt_glm_lag//2])\n",
    "    f2_ax7 = fig2.add_subplot(spec2[1, nt_glm_lag//2:-1])\n",
    "    f2_ax8 = fig2.add_subplot(spec2[1,-1])\n",
    "    if MovModel != 0:\n",
    "        crange = np.max(np.abs(sta_all[alph,lam,celln]))\n",
    "        for n,ax in enumerate(axs):\n",
    "            im = ax.imshow(sta_all[alph,lam,celln,n],'RdBu_r',vmin=-crange,vmax=crange)\n",
    "            cbar = add_colorbar(im)\n",
    "            ax.axis('off')\n",
    "\n",
    "    sp_smooth = ((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    f2_ax6.plot(np.arange(len(sp_smooth))*model_dt,sp_smooth, 'k', lw=2)\n",
    "    pred_smooth = ((np.convolve(pred_all[alph,lam,:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    f2_ax6.plot(np.arange(len(pred_smooth))*model_dt,pred_smooth,'r', lw=2)\n",
    "    f2_ax6.set_xlabel('Time (s)')\n",
    "    f2_ax6.set_ylabel('Spike Rate')\n",
    "    f2_ax7.plot(tloss_trace_all[alph,lam,:,celln])\n",
    "    f2_ax7.plot(vloss_trace_all[alph,lam,:,celln])\n",
    "    f2_ax7.set_xlabel('Batch #')\n",
    "    f2_ax7.set_ylabel('Loss')\n",
    "    r2 = (np.corrcoef(sp_smooth,pred_smooth)[0,1])**2\n",
    "    \n",
    "    if MovModel == 1:\n",
    "        w_move = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "    elif MovModel == 3:\n",
    "        Msta = w_move[:,:-len(titles)].reshape((model_nsp.shape[-1],nt_glm_lag,len(titles))+nks)\n",
    "        w_move = w_move[:,-len(titles):]\n",
    "    for modeln in range(len(titles)):\n",
    "        f2_ax8.bar(modeln, w_move[celln,modeln], color=clrs[modeln])\n",
    "        f2_ax8.set_xticks(np.arange(0,len(titles)))\n",
    "        f2_ax8.set_xticklabels(titles)\n",
    "        f2_ax8.set_ylabel('GLM Weight')\n",
    "    \n",
    "    plt.suptitle('celln: {} $r^2$:{:.03f}'.format(celln, r2))\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 49# np.argmax(r2_all)\n",
    "bin_length = 40\n",
    "ncells = model_nsp.shape[-1]\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "quartiles = np.arange(0,1.25,.25)\n",
    "bin_length=40\n",
    "alph = malph[celln]\n",
    "lam = mlam[celln]\n",
    "for n, celln in enumerate(tqdm([21,49,51,25,117,126])):\n",
    "    fig2 = plt.figure(constrained_layout=False, figsize=(20,7))\n",
    "    spec2 = gridspec.GridSpec(ncols=nt_glm_lag, nrows=2, figure=fig2)\n",
    "    axs = np.array([fig2.add_subplot(spec2[0, n]) for n in range(nt_glm_lag)])\n",
    "    f2_ax6 = fig2.add_subplot(spec2[1, :nt_glm_lag//2])\n",
    "    f2_ax7 = fig2.add_subplot(spec2[1, nt_glm_lag//2:-1])\n",
    "    f2_ax8 = fig2.add_subplot(spec2[1,-1])\n",
    "    if MovModel != 0:\n",
    "        crange = np.max(np.abs(sta_all[celln]))\n",
    "        for n,ax in enumerate(axs):\n",
    "            im = ax.imshow(sta_all[celln,n],'RdBu_r',vmin=-crange,vmax=crange)\n",
    "            cbar = add_colorbar(im)\n",
    "            ax.axis('off')\n",
    "\n",
    "    sp_smooth = ((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    f2_ax6.plot(np.arange(len(sp_smooth))*model_dt,sp_smooth, 'k', lw=2)\n",
    "    pred_smooth = ((np.convolve(pred_all.T[celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    f2_ax6.plot(np.arange(len(pred_smooth))*model_dt,pred_smooth,'r', lw=2)\n",
    "    f2_ax6.set_xlabel('Time (s)')\n",
    "    f2_ax6.set_ylabel('Spike Rate')\n",
    "    f2_ax7.plot(tloss_trace_all[alph,lam,:,celln])\n",
    "    f2_ax7.plot(vloss_trace_all[alph,lam,:,celln])\n",
    "    f2_ax7.set_xlabel('Batch #')\n",
    "    f2_ax7.set_ylabel('Loss')\n",
    "    r2 = (np.corrcoef(sp_smooth,pred_smooth)[0,1])**2\n",
    "    \n",
    "    if MovModel == 1:\n",
    "        w_move = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "    elif MovModel == 3:\n",
    "        Msta = w_move[:,:-len(titles)].reshape((model_nsp.shape[-1],nt_glm_lag,len(titles))+nks)\n",
    "        w_move = w_move[:,-len(titles):]\n",
    "    for modeln in range(len(titles)):\n",
    "        f2_ax8.bar(modeln, w_move[celln,modeln], color=clrs[modeln])\n",
    "        f2_ax8.set_xticks(np.arange(0,len(titles)))\n",
    "        f2_ax8.set_xticklabels(titles)\n",
    "        f2_ax8.set_ylabel('GLM Weight')\n",
    "    \n",
    "    plt.suptitle('celln: {} $r^2$:{:.03f}'.format(celln, r2))\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_length=40\n",
    "alph = 0\n",
    "lam = np.argmin(msetest[0,:,celln])\n",
    "print(lam)\n",
    "pdf_name = FigPath/ 'VisMov_{}_dt{:03d}_Lags{:02d}_MovModel{:d}_FitSummary.pdf'.format(model_type,int(model_dt*1000),nt_glm_lag, MovModel)\n",
    "with PdfPages(pdf_name) as pdf:\n",
    "    for n, celln in enumerate(tqdm(range(output_size))):\n",
    "        fig2 = plt.figure(constrained_layout=False, figsize=(20,7))\n",
    "        spec2 = gridspec.GridSpec(ncols=nt_glm_lag, nrows=2, figure=fig2)\n",
    "        axs = np.array([fig2.add_subplot(spec2[0, n]) for n in range(nt_glm_lag)])\n",
    "        f2_ax6 = fig2.add_subplot(spec2[1, :nt_glm_lag//2])\n",
    "        f2_ax7 = fig2.add_subplot(spec2[1, nt_glm_lag//2:-1])\n",
    "        f2_ax8 = fig2.add_subplot(spec2[1,-1])\n",
    "        if MovModel != 0:\n",
    "            crange = np.max(np.abs(sta_all[celln]))\n",
    "            for n,ax in enumerate(axs):\n",
    "                im = ax.imshow(sta_all[celln,n],'RdBu_r',vmin=-crange,vmax=crange)\n",
    "                cbar = add_colorbar(im)\n",
    "                ax.axis('off')\n",
    "\n",
    "        sp_smooth = ((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "        f2_ax6.plot(np.arange(len(sp_smooth))*model_dt,sp_smooth, 'k', lw=2)\n",
    "        pred_smooth = ((np.convolve(pred_all.T[celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "        f2_ax6.plot(np.arange(len(pred_smooth))*model_dt,pred_smooth,'r', lw=2)\n",
    "        f2_ax6.set_xlabel('Time (s)')\n",
    "        f2_ax6.set_ylabel('Spike Rate')\n",
    "        f2_ax7.plot(tloss_trace_all[alph,lam,:,celln])\n",
    "        f2_ax7.plot(vloss_trace_all[alph,lam,:,celln])\n",
    "        f2_ax7.set_xlabel('Batch #')\n",
    "        f2_ax7.set_ylabel('Loss')\n",
    "        r2 = (np.corrcoef(sp_smooth,pred_smooth)[0,1])**2\n",
    "\n",
    "        if MovModel == 1:\n",
    "            w_move = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "        elif MovModel == 3:\n",
    "            Msta = w_move[:,:-len(titles)].reshape((model_nsp.shape[-1],nt_glm_lag,len(titles))+nks)\n",
    "            w_move = w_move[:,-len(titles):]\n",
    "        for modeln in range(len(titles)):\n",
    "            f2_ax8.bar(modeln, w_move[celln,modeln], color=clrs[modeln])\n",
    "            f2_ax8.set_xticks(np.arange(0,len(titles)))\n",
    "            f2_ax8.set_xticklabels(titles)\n",
    "            f2_ax8.set_ylabel('GLM Weight')\n",
    "\n",
    "        plt.suptitle('celln: {} $r^2$:{:.03f}'.format(celln, r2))\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-logging",
   "metadata": {},
   "source": [
    "# SFN Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 4\n",
    "FM_sta_up = np.zeros((GLM_VisMov_m2['sta_all'].shape[0], GLM_VisMov_m2['sta_all'].shape[1],sf*GLM_VisMov_m2['sta_all'].shape[-2], sf*GLM_VisMov_m2['sta_all'].shape[-1]))\n",
    "for n in range(GLM_VisMov_m2['sta_all'].shape[0]):\n",
    "    for t in range(GLM_VisMov_m2['sta_all'].shape[1]):\n",
    "        FM_sta_up[n, t] = cv2.resize(GLM_VisMov_m2['sta_all'][n, t], (sf*GLM_VisMov_m2['sta_all'].shape[-1], sf*GLM_VisMov_m2['sta_all'].shape[-2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell1 = 51\n",
    "cell2 = 117 # 49\n",
    "\n",
    "\n",
    "fig1 = plt.figure(constrained_layout=False, figsize=(10,5))\n",
    "spec2 = gridspec.GridSpec(ncols=2, nrows=1, figure=fig1, wspace=.1,hspace=.02)\n",
    "axs1 = np.array([fig1.add_subplot(spec2[n]) for n in range(2)])\n",
    "crange2 = np.max(np.abs(GLM_VisMov_m2['sta_all'][cell1]))\n",
    "im2 = axs1[0].imshow(FM_sta_up[cell1, 2],'RdBu_r', vmin=-crange2, vmax=crange2)\n",
    "axs1[0].set_title('Unit 1')\n",
    "crange4 = np.max(np.abs(GLM_VisMov_m2['sta_all'][cell2]))\n",
    "im4 = axs1[1].imshow(FM_sta_up[cell2, 2],'RdBu_r', vmin=-crange4, vmax=crange4)\n",
    "axs1[1].set_title('Unit 2')\n",
    "\n",
    "# axs1[1,1].axis('off')\n",
    "# axs1[1,0].axis('off')\n",
    "# cbar2 = add_colorbar(im1)#,location='bottom',orientation='horizontal')\n",
    "cbar2 = fig.colorbar(im4, ax=axs1.ravel().tolist(),fraction=0.015, pad=0.04)\n",
    "# crange = np.max(np.stack((np.abs(GLM_VisMov_m2['sta_all'][cell1]),np.abs(GLM_HF_m1['sta_all'][cell1,:,5:-5,5:-5]))))\n",
    "cbar2.set_ticks([-crange4, crange4])\n",
    "cbar2.set_ticklabels(['Dark', 'Light'])\n",
    "cbar2.outline.set_linewidth(1.5)\n",
    "for ax in axs1.flat:\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.5)\n",
    "        ax.spines[axis].set_visible(True)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])    \n",
    "# fig1.savefig(FigPath_SFN/'HF_FM_receptivefields.png', facecolor='white', transparent=True, bbox_inches='tight',dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "celln = 126\n",
    "t = 4000\n",
    "dt = pred_multadd_smooth_all.shape[-1]-t-1\n",
    "fig2, axs2 = plt.subplots(1,figsize=(10,5))\n",
    "msp_smooth=((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth_m1 = ((np.convolve(GLM_VisMov_m1['pred_all'][:, celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "timem1 = (np.arange(0,dt)*model_dt)\n",
    "# pred_smooth_m2=((np.convolve(GLM_VisMov_m2['pred_all'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "p1 = axs2.plot(timem1,msp_smooth[t:t+dt],'k',lw=3, label='Actual V1 Activity', alpha=.75)\n",
    "p2 = axs2.plot(timem1,pred_smooth_m1[t:t+dt], 'r',lw=3, label='Predicted Visual $r^2$: {:.02f}'.format(GLM_VisMov_m1['r2_all'][celln]), alpha=.75)\n",
    "# p3 = axs2.plot(timem1,pred_multadd_smooth_all[0,-1,celln,t:t+dt], 'g',lw=3, label='Predicted Visual*Movement $r^2$: {:.03f}'.format(r2_mod_mult[celln,-1]), alpha=.75)\n",
    "axs2.set_xlabel('time (s)')\n",
    "axs2.set_ylabel('sp/sec')\n",
    "axs2.set_ylim((0,60))\n",
    "axs2.set_xlim((0,140))\n",
    "# axs2.set_xticks(np.arange(0,dt,60)*model_dt)\n",
    "axs2.legend(labelcolor='linecolor', bbox_to_anchor=(.55, .8), fontsize=14, handlelength=0, handletextpad=0, fancybox=True)\n",
    "plt.tight_layout()\n",
    "fig2.savefig(FigPath_SFN/'Predicted_FR.png', facecolor='white', transparent=True,bbox_inches='tight')\n",
    "\n",
    "celln = 126\n",
    "t = 4000\n",
    "dt = pred_multadd_smooth_all.shape[-1]-t-1\n",
    "fig2, axs2 = plt.subplots(1,figsize=(10,5))\n",
    "msp_smooth=((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth_m1 = ((np.convolve(GLM_VisMov_m1['pred_all'][:, celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "timem1 = (np.arange(0,dt)*model_dt)\n",
    "# pred_smooth_m2=((np.convolve(GLM_VisMov_m2['pred_all'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "p1 = axs2.plot(timem1,msp_smooth[t:t+dt],'k',lw=3, label='Actual V1 Activity', alpha=.75)\n",
    "p2 = axs2.plot(timem1,pred_smooth_m1[t:t+dt], 'r',lw=3, label='Predicted Visual $r^2$: {:.02f}'.format(GLM_VisMov_m1['r2_all'][celln]), alpha=.75)\n",
    "p3 = axs2.plot(timem1,pred_multadd_smooth_all[0,-1,celln,t:t+dt], 'g',lw=3, label='Predicted Visual*Movement $r^2$: {:.02f}'.format(r2_mod_mult[celln,-1]), alpha=.75)\n",
    "axs2.set_xlabel('time (s)')\n",
    "axs2.set_ylabel('sp/sec')\n",
    "axs2.set_ylim((0,60))\n",
    "axs2.set_xlim((0,140))\n",
    "# axs2.set_xticks(np.arange(0,dt,60)*model_dt)\n",
    "axs2.legend(labelcolor='linecolor', bbox_to_anchor=(.55, .7), fontsize=14, handlelength=0, handletextpad=0, fancybox=True)\n",
    "plt.tight_layout()\n",
    "fig2.savefig(FigPath_SFN/'PredictedMod_FR.png', facecolor='white', transparent=True,bbox_inches='tight')\n",
    "\n",
    "# fig1, axs3 = plt.subplots(2,1,figsize=(10,5))\n",
    "# axs3.scatter(GLM_VisMov_m1['r2_all'],GLM_VisMov_m2['r2_all'],10,c='k',label='Significant $R^2$')\n",
    "# axs3.plot(np.linspace(0,.5),np.linspace(0,.5),'k--',zorder=0)\n",
    "# # axs3.legend(fontsize=12,loc=(.3,.9))\n",
    "# axs3.set_xlabel('Visual only $R^2$')\n",
    "# axs3.set_ylabel('VisMov $R^2$')\n",
    "# axs3.axis('square')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 126\n",
    "modeln = -1\n",
    "fig3, axs3 = plt.subplots(1,2,figsize=(9,5))\n",
    "# Head Tuning Curves\n",
    "top_yaxs = np.max(ax_ylims[celln])+2*np.nanmax(tuning_stds[celln])\n",
    "metric = move_data[:,modeln]\n",
    "nranges = np.round(np.quantile(metric,quartiles),decimals=1)\n",
    "stat_range, edges, _ = binned_statistic(metric,nsp_raw,statistic='mean',bins=nranges)\n",
    "edge_mids = np.quantile(metric,spk_percentile2)\n",
    "for m in range(len(nranges)-1):\n",
    "    axs3[0].axvspan(nranges[m], nranges[m+1],ymin=0,ymax=1,alpha=0.75, color=colors[m],zorder=0)\n",
    "axs3[0].plot(edge_mids,stat_range/model_dt,'.-', ms=20, lw=4,c='k')\n",
    "axs3[0].set_ylim(bottom=0,top=50)\n",
    "axs3[0].set_xlim(-30,30)\n",
    "axs3[0].set_xlabel('Head Pitch (deg)')\n",
    "axs3[0].set_ylabel('sp/sec')\n",
    "# axs3[0].set_title('Pitch Tuning Curves')\n",
    "lines = axs3[0].get_lines()\n",
    "# legend1 = axs3[0].legend([lines[0]],[titles[2]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "# legend2 = axs3[0].legend([lines[1]],[titles[3]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "# axs3[0].add_artist(legend1)\n",
    "# axs3[0].axis('equal')\n",
    "\n",
    "\n",
    "##########################################\n",
    "predcell = pred_train[:,celln]/model_dt\n",
    "nspcell = train_nsp[:,celln]/model_dt\n",
    "nsp_raw = train_nsp[:,celln]\n",
    "pred_raw = pred_train[:,celln]\n",
    "move_data = move_train.copy()\n",
    "# Set up predicted spike range between 1-99th percentile\n",
    "stat_bins = 5\n",
    "pred_range = np.quantile(predcell,[.1,.9])\n",
    "test_nsp_range = np.quantile(nspcell,[.01,1])\n",
    "spike_percentiles = np.arange(0,1.25,.25)\n",
    "spike_percentiles[-1]=.99\n",
    "spk_percentile2 = np.arange(.125,1.125,.25)\n",
    "pred_rangelin = np.quantile(predcell,spike_percentiles)\n",
    "xbin_pts = np.quantile(predcell,spk_percentile2)\n",
    "stat_bins = len(pred_rangelin) #5\n",
    "\n",
    "metric = move_data[:,modeln]\n",
    "nranges = np.quantile(metric,quartiles)# np.linspace(np.nanmean(metric)-2*np.nanstd(metric), np.nanmean(metric)+2*np.nanstd(metric),N_bins)\n",
    "stat_all, edges, _ = binned_statistic(predcell,nspcell,statistic='mean',bins=pred_rangelin)\n",
    "edge_mids = xbin_pts\n",
    "traces_mean[celln,modeln]=stat_all\n",
    "max_fr = np.max(stat_all)\n",
    "for n in range(len(nranges)-1):\n",
    "    ind = np.where(((metric<=nranges[n+1])&(metric>nranges[n])))[0]\n",
    "    pred = predcell[ind]\n",
    "    sp = nspcell[ind]\n",
    "\n",
    "    stat_range, edges, _ = binned_statistic(pred, sp, statistic='mean',bins=pred_rangelin)\n",
    "    edge_mids = xbin_pts #np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    traces[celln,modeln,n]=stat_range\n",
    "    edges_all[celln,modeln,n]=edge_mids\n",
    "    res_add = minimize_scalar(f_add,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "    res_mult = minimize_scalar(f_mult,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "    mse_add[celln, modeln, n] = res_add.fun\n",
    "    mse_mult[celln, modeln, n] = res_mult.fun\n",
    "    alpha_add[celln, modeln, n] = res_add.x\n",
    "    alpha_mult[celln, modeln, n] = res_mult.x\n",
    "\n",
    "    axs3[1].plot(edge_mids, stat_range,'.-', c=colors[n],label='{:.02f} : {:.02f}'.format(nranges[n],nranges[n+1]),lw=4,ms=20,alpha=.9)\n",
    "    # axs3[1].set_title('Metric: {}'.format(titles[modeln]), color=clrs[modeln])\n",
    "    axs3[1].set_xlabel('Predicted (sp/sec)')\n",
    "    axs3[1].set_ylabel('Actual (sp/sec)')\n",
    "\n",
    "lim_max = np.nanmax(np.hstack((edge_mids,traces[celln,modeln].flatten())))+.5*np.std(edges)\n",
    "lim_min = np.nanmin(np.hstack((edge_mids,traces[celln,modeln].flatten())))-.5*np.std(edges)\n",
    "lims = (0, lim_max) if (lim_min)<0 else (lim_min,lim_max) \n",
    "axs3[1].plot(np.linspace(0,lims[1]),np.linspace(0,lims[1]),'k--',zorder=0)\n",
    "axs3[1].plot(edge_mids, stat_all,'.-', c='k', lw=5, ms=20, label='All_data', alpha=.8)\n",
    "# axs3[1].legend(bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "axs3[1].axis('square')\n",
    "# axs3[1].set(xlim=(10,lims[1]), ylim=lims)\n",
    "axs3[1].set_xlim(left=0)\n",
    "axs3[1].set_ylim(bottom=0)\n",
    "plt.tight_layout()\n",
    "fig3.savefig(FigPath_SFN/'Tuning_PitchMult.png', facecolor='white', transparent=True, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter $r^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_max = np.max((GLM_VisMov_m0['r2_all'], GLM_VisMov_m1['r2_all'], GLM_VisMov_m2['r2_all'])) + \\\n",
    "    1.0*np.std((GLM_VisMov_m0['r2_all'], GLM_VisMov_m1['r2_all'], GLM_VisMov_m2['r2_all']))\n",
    "lims = (0, lim_max)\n",
    "\n",
    "fontsize=24\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(GLM_VisMov_m1['r2_all'], np.max(r2_mod_mult,axis=1),10, c='k', label='Mult $R^2$')\n",
    "# ax.scatter(non_sig,non_sig,c='r', label='Nonsignificant $R^2$')\n",
    "ax.plot(np.linspace(lims[0], lims[1]), np.linspace(lims[0], lims[1]), 'k--', zorder=0)\n",
    "# ax.legend(fontsize=12, loc=(.3, .9))\n",
    "ax.set_xlabel('Visual only $r^2$',fontsize=fontsize)\n",
    "ax.set_ylabel('Visual*Movement $r^2$',fontsize=fontsize)\n",
    "ax.set_xticks([0,.1,.2,.3,.4,.5,.6],)\n",
    "ax.set_yticks([0,.1,.2,.3,.4,.5,.6],)\n",
    "ax.set_xticklabels([0,.1,.2,.3,.4,.5,.6], fontsize=fontsize)\n",
    "ax.set_yticklabels([0,.1,.2,.3,.4,.5,.6], fontsize=fontsize)\n",
    "# rect = patches.Rectangle((0, 0), max_shuff, max_shuff, linewidth=1, edgecolor='r', facecolor='r')\n",
    "# ax.add_patch(rect)\n",
    "# for i, txt in enumerate(np.arange(ncells)):\n",
    "#     ax.annotate(txt, (GLM_VisMov_m1['r2_all'][i], np.max(r2_mod_mult,axis=1)[i]), fontsize=10)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FigPath_SFN/'Vis_MultMod_R2_Comparison.png', facecolor='white', transparent=True, bbox_inches='tight')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(GLM_VisMov_m1['r2_all'], np.max(r2_mod_add,axis=1),10, c='r', label='Add $R^2$')\n",
    "# ax.scatter(non_sig,non_sig,c='r', label='Nonsignificant $R^2$')\n",
    "ax.plot(np.linspace(lims[0], lims[1]), np.linspace(lims[0], lims[1]), 'k--', zorder=0)\n",
    "ax.legend(fontsize=12, loc=(.3, .9))\n",
    "ax.set_xlabel('Visual only $R^2$')\n",
    "ax.set_ylabel('Vis+Mov $R^2$')\n",
    "# rect = patches.Rectangle((0, 0), max_shuff, max_shuff, linewidth=1, edgecolor='r', facecolor='r')\n",
    "# ax.add_patch(rect)\n",
    "# for i, txt in enumerate(np.arange(ncells)):\n",
    "#     ax.annotate(txt, (GLM_VisMov_m1['r2_all'][i], np.max(r2_mod_add,axis=1)[i]), fontsize=10, color='r')\n",
    "plt.tight_layout()\n",
    "fig.savefig(FigPath/'Vis_AddMod_R2_Comparison.png', facecolor='white', transparent=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(np.max(r2_mod_add,axis=1),np.max(r2_mod_mult,axis=1),10, c='k', label='Add $R^2$')\n",
    "ax.plot(np.linspace(lims[0], lims[1]), np.linspace(lims[0], lims[1]), 'k--', zorder=0)\n",
    "# ax.legend(fontsize=12, loc=(.3, .9))\n",
    "ax.set_xlabel('Visual+Movement $r^2$', fontsize=fontsize)\n",
    "ax.set_ylabel('Visual*Movement $r^2$', fontsize=fontsize)\n",
    "ax.set_xticks([0,.1,.2,.3,.4,.5,.6],)\n",
    "ax.set_yticks([0,.1,.2,.3,.4,.5,.6],)\n",
    "ax.set_xticklabels([0,.1,.2,.3,.4,.5,.6], fontsize=fontsize)\n",
    "ax.set_yticklabels([0,.1,.2,.3,.4,.5,.6], fontsize=fontsize)\n",
    "# for i, txt in enumerate(np.arange(ncells)):\n",
    "#     ax.annotate(txt, (np.max(r2_mod_add,axis=1)[i],np.max(r2_mod_mult,axis=1)[i]), fontsize=10, color='k')\n",
    "plt.tight_layout()\n",
    "fig.savefig(FigPath_SFN/'AddMod_MultMod_R2_Comparison.png', facecolor='white', transparent=True, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hbins=.03\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "count_vis, edges_vis = np.histogram(GLM_VisMov_m1['r2_all'],bins=np.arange(0,1,hbins))\n",
    "count_mult, edges_mult = np.histogram(np.max(r2_mod_mult,axis=1),bins=np.arange(0,1,hbins))\n",
    "count_add, edges_add = np.histogram(np.max(r2_mod_add,axis=1),bins=np.arange(0,1,hbins))\n",
    "edges_mid_vis = np.array([(edges_vis[i]+edges_vis[i+1])/2 for i in range(len(edges_vis)-1)])\n",
    "edges_mid_mult = np.array([(edges_mult[i]+edges_mult[i+1])/2 for i in range(len(edges_mult)-1)])\n",
    "edges_mid_add = np.array([(edges_add[i]+edges_add[i+1])/2 for i in range(len(edges_add)-1)])\n",
    "ax.bar(edges_mid_vis, count_vis/len(GLM_VisMov_m1['r2_all']), color='k',width=hbins,alpha=.5, label='Vis Only $r^2$')\n",
    "ax.bar(edges_mid_mult, count_mult/len(np.max(r2_mod_mult,axis=1)),color='b',width=hbins,alpha=.5, label='Vis*Mov $r^2$')\n",
    "# ax.bar(edges_mid_add, count_add/len(np.max(r2_mod_add,axis=1)),color='r',width=hbins,alpha=1, label='Vis+Mov $r^2$')\n",
    "ax.axvline(x=np.mean(GLM_VisMov_m1['r2_all']),ls='--',c='k')\n",
    "ax.axvline(x=np.mean(np.max(r2_mod_mult,axis=1)),ls='--',c='b')\n",
    "\n",
    "ax.set_xlabel('$r^2$')\n",
    "ax.set_yticks(np.arange(0,1,.1))\n",
    "ax.set_yticklabels(np.round(np.arange(0,1,.1),decimals=3))\n",
    "ax.set_xlim(-.01,.5)\n",
    "ax.set_ylim(0,.2)\n",
    "ax.legend(fontsize=12,loc=(.75,.9))\n",
    "print(np.mean(GLM_VisMov_m1['r2_all']),np.mean(np.max(r2_mod_mult,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "guilty-motion",
   "metadata": {},
   "source": [
    "# Head Fix and FM Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load package\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator,FormatStrFormatter,MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size':         24,\n",
    "                     'axes.linewidth':    3,\n",
    "                     'xtick.major.size':  5,\n",
    "                     'xtick.major.width': 3,\n",
    "                     'ytick.major.size':  5,\n",
    "                     'ytick.major.width': 2,\n",
    "                     'axes.spines.right': False,\n",
    "                     'axes.spines.top':   False,\n",
    "                     'font.family':      \"Arial\",\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_type = 'hf1_wn'  # 'fm1' #\n",
    "data_dir = Path('~/Goeppert/freely_moving_ephys/ephys_recordings/').expanduser() / date_ani / stim_type\n",
    "save_dir_hf = check_path(Path('~/Research/SensoryMotorPred_Data/data/').expanduser() / date_ani, stim_type)\n",
    "file_dict_hf = {'cell': 0,\n",
    "             'drop_slow_frames': True,\n",
    "             'ephys': list(data_dir.glob('*ephys_merge.json'))[0].as_posix(),\n",
    "             'ephys_bin': list(data_dir.glob('*Ephys.bin'))[0].as_posix(),\n",
    "             'eye': list(data_dir.glob('*REYE.nc'))[0].as_posix(),\n",
    "             'imu': list(data_dir.glob('*imu.nc'))[0].as_posix() if stim_type == 'fm1' else None,\n",
    "             'mapping_json': '/home/seuss/Research/Github/FreelyMovingEphys/probes/channel_maps.json',\n",
    "             'mp4': True,\n",
    "             'name': '01221_EE8P6LT_control_Rig2_' + stim_type,  # 070921_J553RT\n",
    "             'probe_name': 'DB_P128-6',\n",
    "             'save': data_dir.as_posix(),\n",
    "             'speed': list(data_dir.glob('*speed.nc'))[0].as_posix() if stim_type == 'hf1_wn' else None,\n",
    "             'stim_type': 'light',\n",
    "             'top': list(data_dir.glob('*TOP1.nc'))[0].as_posix() if stim_type == 'fm1' else None,\n",
    "             'world': list(data_dir.glob('*world.nc'))[0].as_posix(), }\n",
    "GLM_HF_m1 = ioh5.load(save_dir_hf/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type, int(model_dt*1000), nt_glm_lag, 1))\n",
    "data_hf, train_idx, test_idx = load_train_test(file_dict_hf, save_dir_hf, model_dt=model_dt, do_shuffle=False, do_norm=False, free_move=False, has_imu=False, has_mouse=False)\n",
    "# locals().update(data_hf)\n",
    "# np.array([-1,0,1,2,3]) #,np.arange(minlag,maxlag,np.floor((maxlag-minlag)/nt_glm_lag).astype(int))\n",
    "# lag_list = np.array([-2, -1, 0, 1, 2])\n",
    "# nt_glm_lag = len(lag_list)\n",
    "# print(lag_list, 1000*lag_list*model_dt)\n",
    "# nks = np.shape(data_hf['model_vid_sm'])[1:];nk = nks[0]*nks[1]*nt_glm_lag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM_VisMov_m0 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,0))\n",
    "GLM_VisMov_m1 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,1))\n",
    "GLM_VisMov_m2 = ioh5.load(save_dir/'GLM_{}_Data_VisMov_dt{:03d}_T{:02d}_MovModel{:d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag,2))\n",
    "locals().update(GLM_VisMov_m1)\n",
    "bin_length=40\n",
    "\n",
    "data, train_idx, test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=False, do_norm=False,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "locals().update(data)\n",
    "##### Explore Neurons #####\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "# Initialize movement combinations\n",
    "titles = np.array(['Theta','Phi','Roll','Pitch']) # 'dg_p','dg_n' 'roll','pitch'\n",
    "titles_all = []\n",
    "for n in range(1,len(titles)+1):\n",
    "    perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "    for ind in range(perms.shape[0]):\n",
    "        titles_all.append('_'.join([t for t in titles[perms[ind]]]))\n",
    "\n",
    "# train_dgaze_p = train_dth + np.diff(train_gz,append=0)\n",
    "# train_dgaze_n = train_dth - np.diff(train_gz,append=0)\n",
    "# test_dgaze_p = test_dth + np.diff(test_gz,append=0)\n",
    "# test_dgaze_n = test_dth - np.diff(test_gz,append=0)\n",
    "move_train = np.hstack((train_th[:,np.newaxis],train_phi[:,np.newaxis],train_roll[:,np.newaxis],train_pitch[:,np.newaxis]))#, train_dth[:,np.newaxis],train_dphi[:,np.newaxis]))\n",
    "move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_roll[:,np.newaxis],test_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "# move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))# test_dth[:,np.newaxis],test_dphi[:,np.newaxis]))\n",
    "model_move = np.hstack((model_th[:,np.newaxis],model_phi[:,np.newaxis],model_roll[:,np.newaxis],model_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "model_move = model_move - np.mean(model_move,axis=0)\n",
    "move_test = move_test - np.mean(move_test,axis=0)\n",
    "move_train = move_train - np.mean(move_train,axis=0)\n",
    "\n",
    "# Create all tuning curves for plotting\n",
    "N_bins=10\n",
    "ncells = model_nsp.shape[-1]\n",
    "ax_ylims = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "tuning_curves = np.zeros((model_nsp.shape[-1],len(titles),N_bins-1))\n",
    "tuning_stds = np.zeros((model_nsp.shape[-1],len(titles),N_bins-1))\n",
    "var_ranges = np.zeros((len(titles),N_bins-1))\n",
    "for modeln in range(len(titles)):\n",
    "    metric = move_test[:,modeln]\n",
    "    tuning, tuning_std, var_range = tuning_curve(test_nsp, metric, N_bins=N_bins, model_dt=model_dt, Nstds=2)\n",
    "    tuning_curves[:,modeln] = tuning\n",
    "    tuning_stds[:,modeln] = tuning_std\n",
    "    ax_ylims[:,modeln] = np.nanmax(tuning,axis=1)\n",
    "    var_ranges[modeln] = var_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsample RFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 4\n",
    "FM_sta_up = np.zeros((GLM_VisMov_m2['sta_all'].shape[0], GLM_VisMov_m2['sta_all'].shape[1],sf*GLM_VisMov_m2['sta_all'].shape[-2], sf*GLM_VisMov_m2['sta_all'].shape[-1]))\n",
    "HF_sta_up = np.zeros((GLM_HF_m1['sta_all'].shape[0], GLM_HF_m1['sta_all'].shape[1], sf*(GLM_HF_m1['sta_all'].shape[-2]), sf*(GLM_HF_m1['sta_all'].shape[-1])))\n",
    "for n in range(GLM_HF_m1['sta_all'].shape[0]):\n",
    "    for t in range(GLM_HF_m1['sta_all'].shape[1]):\n",
    "        HF_sta_up[n, t] = cv2.resize(GLM_HF_m1['sta_all'][n, t], (sf*(GLM_HF_m1['sta_all'].shape[-1]), sf*(GLM_HF_m1['sta_all'].shape[-2])))\n",
    "for n in range(GLM_VisMov_m2['sta_all'].shape[0]):\n",
    "    for t in range(GLM_VisMov_m2['sta_all'].shape[1]):\n",
    "        FM_sta_up[n, t] = cv2.resize(GLM_VisMov_m2['sta_all'][n, t], (sf*GLM_VisMov_m2['sta_all'].shape[-1], sf*GLM_VisMov_m2['sta_all'].shape[-2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = [25,117] # 49,78\n",
    "num_cells = len(cells)\n",
    "\n",
    "FigPath_SFN = check_path(FigPath,'UT_Austin_Talk')\n",
    "\n",
    "# fig1, axs1 = plt.subplots(2,2,figsize=(10,5),)\n",
    "fig1 = plt.figure(constrained_layout=False, figsize=(int(5*num_cells),5))\n",
    "spec2 = gridspec.GridSpec(ncols=num_cells, nrows=2, figure=fig1, wspace=.1,hspace=.05)\n",
    "axs1 = np.array([fig1.add_subplot(spec2[n,m]) for n in range(2) for m in range(num_cells)]).reshape(2,num_cells)\n",
    "for n, cell in enumerate(cells):\n",
    "    crange1 = np.max(np.abs(HF_sta_up[cell,2]))\n",
    "    im1 = axs1[0,n].imshow(HF_sta_up[cell, 2, 40:,20:-20], 'RdBu_r', vmin=-crange1, vmax=crange1)\n",
    "    axs1[0,n].set_title('Unit: {}'.format(n+1))\n",
    "    crange2 = np.max(np.abs(FM_sta_up[cell,2]))\n",
    "    im2 = axs1[1,n].imshow(FM_sta_up[cell, 2],'RdBu_r', vmin=-crange2, vmax=crange2)\n",
    "\n",
    "axs1[0,0].set_ylabel('Head-fixed')\n",
    "axs1[1,0].set_ylabel('Freely-moving')\n",
    "\n",
    "cbar2 = fig.colorbar(im2, ax=axs1.ravel().tolist())\n",
    "cbar2.set_ticks([-crange2, crange2])\n",
    "cbar2.set_ticklabels(['Dark', 'Light'])\n",
    "for ax in axs1.flat:\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.5)\n",
    "        ax.spines[axis].set_visible(True)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])    \n",
    "fig1.savefig(FigPath_SFN/'HF_FM_RFComparison_SFN.png', facecolor='white', transparent=True, bbox_inches='tight')\n",
    "\n",
    "\n",
    "celln = 126\n",
    "t = 4000\n",
    "dt = pred_multadd_smooth_all.shape[-1]-t-1\n",
    "fig2, axs2 = plt.subplots(1,figsize=(10,5))\n",
    "msp_smooth=((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth_m1 = ((np.convolve(GLM_VisMov_m1['pred_all'][:, celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "timem1 = (np.arange(0,dt)*model_dt)\n",
    "# pred_smooth_m2=((np.convolve(GLM_VisMov_m2['pred_all'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "p1 = axs2.plot(timem1,msp_smooth[t:t+dt],'k',lw=3, label='Actual V1 Activity', alpha=.75)\n",
    "p2 = axs2.plot(timem1,pred_smooth_m1[t:t+dt], 'r',lw=3, label='Predicted Visual $r^2$: {:.02f}'.format(GLM_VisMov_m1['r2_all'][celln]), alpha=.75)\n",
    "p3 = axs2.plot(timem1,pred_multadd_smooth_all[0,-1,celln,t:t+dt], 'g',lw=3, label='Predicted Visual*Movement $r^2$: {:.02f}'.format(r2_mod_mult[celln,-1]), alpha=.75)\n",
    "axs2.set_xlabel('Time (s)')\n",
    "axs2.set_ylabel('sp/sec')\n",
    "axs2.set_ylim((0,60))\n",
    "axs2.set_xlim((0,140))\n",
    "# axs2.set_xticks(np.arange(0,dt,60)*model_dt)\n",
    "axs2.legend(labelcolor='linecolor', bbox_to_anchor=(.55, .7), fontsize=14, handlelength=0, handletextpad=0, fancybox=True)\n",
    "plt.tight_layout()\n",
    "# fig2.savefig(FigPath_SFN/'PredictedModulated_FR.png', facecolor='white', transparent=True,bbox_inches='tight')\n",
    "\n",
    "# fig1, axs3 = plt.subplots(2,1,figsize=(10,5))\n",
    "# axs3.scatter(GLM_VisMov_m1['r2_all'],GLM_VisMov_m2['r2_all'],10,c='k',label='Significant $R^2$')\n",
    "# axs3.plot(np.linspace(0,.5),np.linspace(0,.5),'k--',zorder=0)\n",
    "# # axs3.legend(fontsize=12,loc=(.3,.9))\n",
    "# axs3.set_xlabel('Visual only $R^2$')\n",
    "# axs3.set_ylabel('VisMov $R^2$')\n",
    "# axs3.axis('square')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Gray FM RF #####\n",
    "cell = 78\n",
    "fig1, axs1 = plt.subplots(figsize=(5,5),)\n",
    "\n",
    "crange2 = np.max(np.abs(FM_sta_up[cell,2]))\n",
    "im2 = axs1.imshow(FM_sta_up[cell, 2],'gray', vmin=-crange2, vmax=crange2)\n",
    "axs1.set_title('Free-moving RF')\n",
    "cbar2 = add_colorbar(im2)\n",
    "cbar2.set_ticks([-crange2, crange2])\n",
    "cbar2.set_ticklabels(['Dark', 'Light'])\n",
    "for ax in [axs1]:\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.5)\n",
    "        ax.spines[axis].set_visible(True)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig1.savefig(FigPath_SFN/'FM_RF_gray.png', facecolor='white', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 126\n",
    "modeln = -1\n",
    "fig3, axs3 = plt.subplots(1,2,figsize=(9,5))\n",
    "# Head Tuning Curves\n",
    "top_yaxs = np.max(ax_ylims[celln])+2*np.nanmax(tuning_stds[celln])\n",
    "metric = move_data[:,modeln]\n",
    "nranges = np.round(np.quantile(metric,quartiles),decimals=1)\n",
    "stat_range, edges, _ = binned_statistic(metric,nsp_raw,statistic='mean',bins=nranges)\n",
    "edge_mids = np.quantile(metric,spk_percentile2)\n",
    "for m in range(len(nranges)-1):\n",
    "    axs3[0].axvspan(nranges[m], nranges[m+1],ymin=0,ymax=1,alpha=0.8, color=colors[m],zorder=0)\n",
    "axs3[0].plot(edge_mids,stat_range/model_dt,'.-', ms=20, lw=4,c=clrs[modeln])\n",
    "\n",
    "axs3[0].set_ylim(bottom=0,top=top_yaxs)\n",
    "axs3[0].set_xlim(-30,30)\n",
    "axs3[0].set_xlabel('Angle ($ ^{\\degree}$)')\n",
    "axs3[0].set_ylabel('Spikes/s')\n",
    "axs3[0].set_title('Pitch Tuning Curves')\n",
    "lines = axs3[0].get_lines()\n",
    "# legend1 = axs3[0].legend([lines[0]],[titles[2]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "# legend2 = axs3[0].legend([lines[1]],[titles[3]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "# axs3[0].add_artist(legend1)\n",
    "\n",
    "\n",
    "\n",
    "##########################################\n",
    "predcell = pred_train[:,celln]/model_dt\n",
    "nspcell = train_nsp[:,celln]/model_dt\n",
    "nsp_raw = train_nsp[:,celln]\n",
    "pred_raw = pred_train[:,celln]\n",
    "move_data = move_train.copy()\n",
    "# Set up predicted spike range between 1-99th percentile\n",
    "stat_bins = 5\n",
    "pred_range = np.quantile(predcell,[.1,.9])\n",
    "test_nsp_range = np.quantile(nspcell,[.01,1])\n",
    "spike_percentiles = np.arange(0,1.25,.25)\n",
    "spike_percentiles[-1]=.99\n",
    "spk_percentile2 = np.arange(.125,1.125,.25)\n",
    "pred_rangelin = np.quantile(predcell,spike_percentiles)\n",
    "xbin_pts = np.quantile(predcell,spk_percentile2)\n",
    "stat_bins = len(pred_rangelin) #5\n",
    "\n",
    "metric = move_data[:,modeln]\n",
    "nranges = np.quantile(metric,quartiles)# np.linspace(np.nanmean(metric)-2*np.nanstd(metric), np.nanmean(metric)+2*np.nanstd(metric),N_bins)\n",
    "stat_all, edges, _ = binned_statistic(predcell,nspcell,statistic='mean',bins=pred_rangelin)\n",
    "edge_mids = xbin_pts\n",
    "traces_mean[celln,modeln]=stat_all\n",
    "max_fr = np.max(stat_all)\n",
    "for n in range(len(nranges)-1):\n",
    "    ind = np.where(((metric<=nranges[n+1])&(metric>nranges[n])))[0]\n",
    "    pred = predcell[ind]\n",
    "    sp = nspcell[ind]\n",
    "\n",
    "    stat_range, edges, _ = binned_statistic(pred, sp, statistic='mean',bins=pred_rangelin)\n",
    "    edge_mids = xbin_pts #np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    traces[celln,modeln,n]=stat_range\n",
    "    edges_all[celln,modeln,n]=edge_mids\n",
    "    res_add = minimize_scalar(f_add,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "    res_mult = minimize_scalar(f_mult,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "    mse_add[celln, modeln, n] = res_add.fun\n",
    "    mse_mult[celln, modeln, n] = res_mult.fun\n",
    "    alpha_add[celln, modeln, n] = res_add.x\n",
    "    alpha_mult[celln, modeln, n] = res_mult.x\n",
    "\n",
    "    axs3[1].plot(edge_mids, stat_range,'.-', c=colors[n],label='{:.02f} : {:.02f}'.format(nranges[n],nranges[n+1]),lw=4,ms=20,alpha=.9)\n",
    "    axs3[1].set_title('Metric: {}'.format(titles[modeln]), color=clrs[modeln])\n",
    "    axs3[1].set_xlabel('Predicted Spike Rate')\n",
    "    axs3[1].set_ylabel('Actual Spike Rate')\n",
    "\n",
    "lim_max = np.nanmax(np.hstack((edge_mids,traces[celln,modeln].flatten())))+.5*np.std(edges)\n",
    "lim_min = np.nanmin(np.hstack((edge_mids,traces[celln,modeln].flatten())))-.5*np.std(edges)\n",
    "lims = (0, lim_max) if (lim_min)<0 else (lim_min,lim_max) \n",
    "axs3[1].plot(np.linspace(lims[0],lims[1]),np.linspace(lims[0],lims[1]),'k--',zorder=0)\n",
    "axs3[1].plot(edge_mids, stat_all,'.-', c='k', lw=5, ms=20, label='All_data', alpha=.8)\n",
    "# axs3[1].legend(bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "axs3[1].axis('equal')\n",
    "axs3[1].set(xlim=lims, ylim=lims)\n",
    "axs3[1].set_ylim(bottom=0)\n",
    "plt.tight_layout()\n",
    "fig2.savefig(FigPath_SFN/'Tuning_PitchMult.png', facecolor='white', transparent=True, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 126\n",
    "r2_mod_mult = np.zeros((ncells, len(titles)+1))\n",
    "r2_mod_add = np.zeros((ncells, len(titles)+1))\n",
    "test_nsp_smooth = ((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth = ((np.convolve(pred_all[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_multadd_all = np.zeros((2,len(titles)+1,ncells,) + pred_all[:,celln].shape)\n",
    "pred_multadd_smooth_all = np.zeros((2,len(titles)+1,ncells,) + pred_smooth.shape)\n",
    "for celln in tqdm(range(ncells)):\n",
    "    predcell = pred_all[:,celln]/model_dt\n",
    "    nspcell = test_nsp[:,celln]/model_dt\n",
    "    test_nsp_smooth = ((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    pred_smooth = ((np.convolve(pred_all[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    pred_mult_all = pred_all[:,celln].copy()\n",
    "    pred_add_all = pred_all[:,celln].copy()\n",
    "    for modeln in range(len(titles)):\n",
    "        metric = move_test[:,modeln]\n",
    "        nranges = np.quantile(metric,quartiles)\n",
    "        stat_range, edges, _ = binned_statistic(metric,test_nsp[:,celln], statistic='mean',bins=nranges)\n",
    "        pred_mult = pred_all[:,celln].copy()\n",
    "        pred_add = pred_all[:, celln].copy()\n",
    "        for i in range(len(edges)-1):    \n",
    "            metric_bounds = consecutive(np.where((metric>edges[i])&(metric<edges[i+1]))[0])\n",
    "            metric_bounds = [row for row in metric_bounds]\n",
    "            metric_length = [len(row) for row in metric_bounds]\n",
    "            for n, row in enumerate(metric_bounds):\n",
    "                pred_mult[row] = alpha_mult[celln,modeln,i]*pred_mult[row]\n",
    "                pred_mult_all[row] = alpha_mult[celln,modeln,i]*pred_mult[row]\n",
    "                pred_add_all[row] = alpha_add[celln,modeln,i]+ pred_add_all[row]\n",
    "                pred_add[row] = alpha_add[celln,modeln,i] + pred_add[row]\n",
    "        pred_multadd_all[0,modeln,celln] = pred_mult\n",
    "        pred_multadd_all[1,modeln,celln] = pred_add\n",
    "        pred_smooth_mult = ((np.convolve(pred_mult, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "        pred_smooth_add = ((np.convolve(pred_add, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "        pred_multadd_smooth_all[0,modeln,celln] = pred_smooth_mult\n",
    "        pred_multadd_smooth_all[1,modeln,celln] = pred_smooth_add\n",
    "        cc_mult = np.corrcoef(test_nsp_smooth,pred_smooth_mult)[0,1]\n",
    "        cc_add = np.corrcoef(test_nsp_smooth, pred_smooth_add)[0, 1]\n",
    "        r2_mod_mult[celln, modeln] = cc_mult**2\n",
    "        r2_mod_mult[celln, modeln] = cc_add**2\n",
    "\n",
    "    pred_multadd_all[0,-1,celln] = pred_mult_all\n",
    "    pred_multadd_all[1,-1,celln] = pred_add_all\n",
    "    pred_smooth_mult_all = ((np.convolve(pred_mult_all, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    pred_smooth_add_all = ((np.convolve(pred_add_all, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    pred_multadd_smooth_all[0,-1,celln] = pred_smooth_mult_all\n",
    "    pred_multadd_smooth_all[1,-1,celln] = pred_smooth_add_all\n",
    "    cc_mult = np.corrcoef(test_nsp_smooth,pred_smooth_mult_all)[0,1]\n",
    "    cc_add = np.corrcoef(test_nsp_smooth, pred_smooth_add_all)[0, 1]\n",
    "    r2_mod_mult[celln, -1] = cc_mult**2\n",
    "    r2_mod_add[celln, -1] = cc_add**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-cooling",
   "metadata": {},
   "source": [
    "## Head Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bin_length = 40\n",
    "ncells = model_nsp.shape[-1]\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "quartiles = np.arange(0,1.25,.25)\n",
    "bin_length=40\n",
    "alph = 0\n",
    "lam = 0\n",
    "for n, celln in enumerate(tqdm([21,49,51,25,117,125,126])):\n",
    "    fig2 = plt.figure(constrained_layout=False, figsize=(20,7))\n",
    "    spec2 = gridspec.GridSpec(ncols=nt_glm_lag, nrows=2, figure=fig2)\n",
    "    axs = np.array([fig2.add_subplot(spec2[0, n]) for n in range(nt_glm_lag)])\n",
    "    f2_ax6 = fig2.add_subplot(spec2[1, :nt_glm_lag//2])\n",
    "    f2_ax7 = fig2.add_subplot(spec2[1, nt_glm_lag//2:-1])\n",
    "    f2_ax8 = fig2.add_subplot(spec2[1,-1])\n",
    "    if MovModel != 0:\n",
    "        crange = np.max(np.abs(GLM_HF_m1['sta_all'][celln]))\n",
    "        for n,ax in enumerate(axs):\n",
    "            im = ax.imshow(GLM_HF_m1['sta_all'][celln,n],'RdBu_r',vmin=-crange,vmax=crange)\n",
    "            cbar = add_colorbar(im)\n",
    "            ax.axis('off')\n",
    "\n",
    "    sp_smooth = ((np.convolve(data_hf['test_nsp'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    f2_ax6.plot(np.arange(len(sp_smooth))*model_dt,sp_smooth, 'k', lw=2)\n",
    "    pred_smooth = ((np.convolve(GLM_HF_m1['pred_all'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "    f2_ax6.plot(np.arange(len(pred_smooth))*model_dt,pred_smooth,'r', lw=2)\n",
    "    f2_ax6.set_xlabel('Time (s)')\n",
    "    f2_ax6.set_ylabel('Spike Rate')\n",
    "    # f2_ax7.plot(tloss_trace_all[alph,lam,:,celln])\n",
    "    # f2_ax7.plot(vloss_trace_all[alph,lam,:,celln])\n",
    "    # f2_ax7.set_xlabel('Batch #')\n",
    "    # f2_ax7.set_ylabel('Loss')\n",
    "    r2 = (np.corrcoef(sp_smooth,pred_smooth)[0,1])**2\n",
    "    \n",
    "    # if MovModel == 1:\n",
    "    #     w_move = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "    # elif MovModel == 3:\n",
    "    #     Msta = w_move[:,:-len(titles)].reshape((model_nsp.shape[-1],nt_glm_lag,len(titles))+nks)\n",
    "    #     w_move = w_move[:,-len(titles):]\n",
    "    # for modeln in range(len(titles)):\n",
    "    #     f2_ax8.bar(modeln, w_move[celln,modeln], color=clrs[modeln])\n",
    "    #     f2_ax8.set_xticks(np.arange(0,len(titles)))\n",
    "    #     f2_ax8.set_xticklabels(titles)\n",
    "    #     f2_ax8.set_ylabel('GLM Weight')\n",
    "    \n",
    "    plt.suptitle('celln: {} $r^2$:{:.03f}'.format(celln, r2))\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(constrained_layout=False, figsize=(20,7))\n",
    "spec2 = gridspec.GridSpec(ncols=nt_glm_lag, nrows=3, figure=fig2)\n",
    "axs1 = np.array([fig2.add_subplot(spec2[0, n]) for n in range(nt_glm_lag)])\n",
    "axs2 = np.array([fig2.add_subplot(spec2[1, n]) for n in range(nt_glm_lag)])\n",
    "axs3 = np.array([fig2.add_subplot(spec2[2, :2]),fig2.add_subplot(spec2[2, 3:]) ])\n",
    "if MovModel != 0:\n",
    "    crange = np.max(np.abs(GLM_HF_m1['sta_all'][celln]))\n",
    "    crange2 = np.max(np.abs(GLM_VisMov_m1['sta_all'][celln]))\n",
    "    for m,(ax1,ax2) in enumerate(zip(axs1,axs2)):\n",
    "        im = ax1.imshow(GLM_HF_m1['sta_all'][celln,m],'RdBu_r',vmin=-crange,vmax=crange)\n",
    "        im2 = ax2.imshow(GLM_VisMov_m1['sta_all'][celln,m],'RdBu_r',vmin=-crange2,vmax=crange2)\n",
    "        ax1.axis('off')\n",
    "        ax2.axis('off')\n",
    "    cbar = add_colorbar(im)\n",
    "    cbar2 = add_colorbar(im2)\n",
    "\n",
    "sp_smooth_HF = ((np.convolve(GLM_HF_m1['test_nsp'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth_HF = ((np.convolve(GLM_HF_m1['pred_all'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "axs3[0].plot(sp_smooth_HF,'k')\n",
    "axs3[0].plot(pred_smooth_HF,'r')\n",
    "axs3[0].set_title('$r^2$:{:.02f}'.format(GLM_HF_m1['r2_all'][celln]**2))\n",
    "sp_smooth_FM = ((np.convolve(GLM_VisMov_m1['test_nsp'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth_FM = ((np.convolve(GLM_VisMov_m1['pred_all'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "axs3[1].plot(sp_smooth_FM,'k')\n",
    "axs3[1].plot(pred_smooth_FM,'r')\n",
    "axs3[1].set_title('$r^2$:{:.02f}'.format(GLM_VisMov_m1['r2_all'][celln]**2))\n",
    "plt.suptitle('celln: {}'.format(celln))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_name = FigPath/ 'VisMov_{}_dt{:03d}_Lags{:02d}_MovModel{:d}_FMHFComparison.pdf'.format(model_type,int(model_dt*1000),nt_glm_lag, 1)\n",
    "with PdfPages(pdf_name) as pdf:\n",
    "    for n, celln in enumerate(tqdm(range(ncells))):\n",
    "        fig2 = plt.figure(constrained_layout=False, figsize=(20,7))\n",
    "        spec2 = gridspec.GridSpec(ncols=nt_glm_lag, nrows=3, figure=fig2)\n",
    "        axs1 = np.array([fig2.add_subplot(spec2[0, n]) for n in range(nt_glm_lag)])\n",
    "        axs2 = np.array([fig2.add_subplot(spec2[1, n]) for n in range(nt_glm_lag)])\n",
    "        axs3 = np.array([fig2.add_subplot(spec2[2, :2]),fig2.add_subplot(spec2[2, 3:]) ])\n",
    "        if MovModel != 0:\n",
    "            crange = np.max(np.abs(GLM_HF_m1['sta_all'][celln]))\n",
    "            crange2 = np.max(np.abs(GLM_VisMov_m1['sta_all'][celln]))\n",
    "            for m,(ax1,ax2) in enumerate(zip(axs1,axs2)):\n",
    "                im = ax1.imshow(GLM_HF_m1['sta_all'][celln,m],'RdBu_r',vmin=-crange,vmax=crange)\n",
    "                im2 = ax2.imshow(GLM_VisMov_m1['sta_all'][celln,m],'RdBu_r',vmin=-crange2,vmax=crange2)\n",
    "                ax1.axis('off')\n",
    "                ax2.axis('off')\n",
    "            cbar = add_colorbar(im)\n",
    "            cbar2 = add_colorbar(im2)\n",
    "\n",
    "        sp_smooth_HF = ((np.convolve(GLM_HF_m1['test_nsp'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "        pred_smooth_HF = ((np.convolve(GLM_HF_m1['pred_all'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "        axs3[0].plot(sp_smooth_HF,'k')\n",
    "        axs3[0].plot(pred_smooth_HF,'r')\n",
    "        axs3[0].set_title('$r^2$:{:.02f}'.format(GLM_HF_m1['r2_all'][celln]))\n",
    "        sp_smooth_FM = ((np.convolve(GLM_VisMov_m1['test_nsp'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "        pred_smooth_FM = ((np.convolve(GLM_VisMov_m1['pred_all'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "        axs3[1].plot(sp_smooth_FM,'k')\n",
    "        axs3[1].plot(pred_smooth_FM,'r')\n",
    "        axs3[1].set_title('$r^2$:{:.02f}'.format(GLM_VisMov_m1['r2_all'][celln]))\n",
    "        plt.suptitle('celln: {}'.format(celln))\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FM RF's Clean Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = [25,49,78,117] # 49\n",
    "num_cells = len(cells)\n",
    "\n",
    "fig1 = plt.figure(constrained_layout=False, figsize=(int(5*nt_glm_lag),int(3*num_cells)))\n",
    "spec2 = gridspec.GridSpec(ncols=nt_glm_lag, nrows=num_cells, figure=fig1, wspace=.05,hspace=.1)\n",
    "axs1 = np.array([fig1.add_subplot(spec2[n,m]) for n in range(num_cells) for m in range(nt_glm_lag)]).reshape(num_cells,nt_glm_lag)\n",
    "for n, cell in enumerate(cells):\n",
    "    for lag in range(nt_glm_lag):\n",
    "        crange2 = np.max(np.abs(FM_sta_up[cell,lag]))\n",
    "        im2 = axs1[n,lag].imshow(FM_sta_up[cell, lag],'RdBu_r', vmin=-crange2, vmax=crange2)\n",
    "        axs1[0,lag].set_title('Lag:{:03d} ms'.format(int(1000*lag_list[lag]*model_dt)))\n",
    "    axs1[n,0].set_ylabel('Unit {}'.format(n+1))\n",
    "cbar2 = fig.colorbar(im2, ax=axs1.ravel().tolist())\n",
    "cbar2.set_ticks([-crange2, crange2])\n",
    "cbar2.set_ticklabels(['Dark', 'Light'])\n",
    "for ax in axs1.flat:\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.5)\n",
    "        ax.spines[axis].set_visible(True)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig1.savefig(FigPath_SFN/'FM_RFs.png', facecolor='white', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-florence",
   "metadata": {},
   "source": [
    "# Predicting FR Join VisMov Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 126\n",
    "msp_smooth=((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth_m1=((np.convolve(GLM_VisMov_m1['pred_all'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth_m2=((np.convolve(GLM_VisMov_m2['pred_all'][:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig2, axs = plt.subplots(figsize=(10,5))\n",
    "axs.plot(np.arange(len(msp_smooth))*model_dt,msp_smooth,'k',lw=3, label='Test FR')\n",
    "axs.plot(np.arange(len(pred_smooth_m1))*model_dt,pred_smooth_m1,'r',lw=3, label='Pred. FR V')\n",
    "axs.plot(np.arange(len(pred_smooth_m2))*model_dt,pred_smooth_m2,'g',lw=3, label='Pred. FR VM')\n",
    "axs.set_xlabel('Time (s)')\n",
    "axs.set_ylabel('Firing Rate (spks/s)')\n",
    "axs.set_xticks(np.arange(0,len(pred_smooth_m1)*model_dt,30))\n",
    "axs.legend()\n",
    "# axs.set_title('Smoothed FRs')\n",
    "# axs.set_title('$R^2$={:.02f}'.format(GLM_Vis['mcc'][celln]**2))\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive(data, stepsize=1):\n",
    "    return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-avatar",
   "metadata": {},
   "source": [
    "scatter R2 of visual only and the slope fit of vis+movement. \n",
    "RFs of time 0, \n",
    "Predictions of slope fits with train data then do fit on test data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "ax.plot(test_nsp_smooth, color='k',lw=3,label='Test')\n",
    "ax.plot(pred_smooth, color='r',lw=3,label='Pred')\n",
    "pred_smooth_mult_all = ((np.convolve(pred_mult_all, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length][t:t+dt]\n",
    "ax.plot(pred_smooth_mult_all,'g',lw=3,zorder=3,label='Modulated')\n",
    "cc_mult = np.corrcoef(test_nsp_smooth,pred_smooth_mult_all)[0,1]\n",
    "ax.set_title('All $R^2_o$:{:.03f}, $R^2_m$:{:.03f}'.format(r2_all[celln],cc_mult**2))\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 51# np.argmax(r2_all)\n",
    "bin_length = 40\n",
    "ncells=model_nsp.shape[-1]\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "quartiles = np.arange(0,1.25,.25)\n",
    "\n",
    "fig, axs = plt.subplots(3,5, figsize=((35,15))) \n",
    "gs = axs[0,0].get_gridspec()\n",
    "gs_sub = gs[0,:].subgridspec(1,nt_glm_lag)\n",
    "for ax in axs[0,:]:\n",
    "    ax.remove()\n",
    "top_grid = np.zeros((nt_glm_lag),dtype=object)\n",
    "for ind in range(nt_glm_lag):\n",
    "    top_grid[ind] = fig.add_subplot(gs_sub[0,ind])\n",
    "\n",
    "predcell = pred_all[:,celln]/model_dt\n",
    "nspcell = test_nsp[:,celln]/model_dt\n",
    "test_nsp_smooth=((np.convolve(test_nsp[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth=((np.convolve(pred_all[:,celln], np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "# Set up predicted spike range between 1-99th percentile\n",
    "stat_bins = 5\n",
    "pred_range = np.quantile(predcell,[.1,.9])\n",
    "test_nsp_range = np.quantile(nspcell,[.01,1])\n",
    "spike_percentiles = np.arange(0,1.25,.25)\n",
    "spike_percentiles[-1]=.99\n",
    "spk_percentile2 = np.arange(.125,1.125,.25)\n",
    "pred_rangelin = np.quantile(predcell,spike_percentiles)\n",
    "xbin_pts = np.quantile(predcell,spk_percentile2)\n",
    "stat_bins = len(pred_rangelin) #5\n",
    "\n",
    "\n",
    "axs[1,0].plot(np.arange(len(test_nsp_smooth))*model_dt,test_nsp_smooth,'k',label='test FR')\n",
    "axs[1,0].plot(np.arange(len(pred_smooth))*model_dt,pred_smooth,'r', label='pred FR')\n",
    "axs[1,0].set_xlabel('Time (s)')\n",
    "axs[1,0].set_ylabel('Firing Rate (spks/s)')\n",
    "axs[1,0].legend()\n",
    "axs[1,0].set_title('Smoothed FRs')\n",
    "\n",
    "crange = np.max(np.abs(sta_all[celln]))\n",
    "for n in range(nt_glm_lag):\n",
    "    img = top_grid[n].imshow(sta_all[celln,n],cmap='RdBu_r',vmin=-crange,vmax=crange)\n",
    "    top_grid[n].axis('off')\n",
    "    top_grid[n].set_title('Lag:{:03d} ms'.format(int(1000*lag_list[n]*model_dt)))\n",
    "    top_grid[n].axis('off')\n",
    "add_colorbar(img)\n",
    "\n",
    "# Eye Tuning Curve\n",
    "top_yaxs = np.max(ax_ylims[celln])+2*np.max(tuning_stds[celln])\n",
    "for i,modeln in enumerate(range(len(titles)-2)):\n",
    "    metric = move_test[:,modeln]\n",
    "    nranges = np.quantile(metric,quartiles)\n",
    "    stat_range, edges, _ = binned_statistic(metric,test_nsp[:,celln],statistic='mean',bins=nranges)\n",
    "    edge_mids = np.quantile(metric,spk_percentile2)#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    # cmap = mpl.colors.ListedColormap(colors, N=colors.shape[0])\n",
    "    # norm = mpl.colors.BoundaryNorm(boundaries=np.floor(nranges), ncolors=len(cmap.colors))\n",
    "    for m in range(len(nranges)-1):\n",
    "        axs[1,1].axvspan(nranges[m], nranges[m+1],ymin=i*1/2,ymax=(i+1)*1/2,alpha=0.8, color=colors[m],zorder=0)\n",
    "    #     axs[1,1].errorbar(var_ranges[modeln],tuning_curves[celln,modeln], yerr=tuning_stds[celln,modeln],label=titles[modeln],c=clrs[modeln],lw=4,elinewidth=3)\n",
    "    axs[1,1].plot(edge_mids,stat_range/model_dt,'.-', ms=20, lw=4,c=clrs[modeln])\n",
    "\n",
    "axs[1,1].set_ylim(bottom=0,top=np.max(ax_ylims,axis=1)[celln]+2*np.nanmax(tuning_stds,axis=(1,2))[celln])\n",
    "axs[1,1].set_xlim(-30,30)\n",
    "axs[1,1].set_xlabel('Angle ($ ^{\\degree}$)')\n",
    "axs[1,1].set_ylabel('Spikes/s')\n",
    "axs[1,1].set_title('Eye Tuning Curves')\n",
    "lines = axs[1,1].get_lines()\n",
    "legend1 = axs[1,1].legend([lines[0]],[titles[0]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "legend2 = axs[1,1].legend([lines[1]],[titles[1]],bbox_to_anchor=(1.01, .9), fontsize=12)\n",
    "axs[1,1].add_artist(legend1)\n",
    "\n",
    "# Head Tuning Curves\n",
    "top_yaxs = np.max(ax_ylims[celln])+2*np.nanmax(tuning_stds[celln])\n",
    "for i, modeln in enumerate(range(2,len(titles))):\n",
    "    metric = move_test[:,modeln]\n",
    "#     nranges = np.round(np.quantile(var_ranges[modeln],quartiles),decimals=1)\n",
    "    nranges = np.round(np.quantile(metric,quartiles),decimals=1)\n",
    "    stat_range, edges, _ = binned_statistic(metric,test_nsp[:,celln],statistic='mean',bins=nranges)\n",
    "    edge_mids = np.quantile(metric,spk_percentile2)#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    # cmap = mpl.colors.ListedColormap(colors, N=colors.shape[0])\n",
    "    # norm = mpl.colors.BoundaryNorm(boundaries=np.floor(nranges), ncolors=len(cmap.colors))\n",
    "    for m in range(len(nranges)-1):\n",
    "        axs[1,2].axvspan(nranges[m], nranges[m+1],ymin=i*1/2,ymax=(i+1)*1/2,alpha=0.8, color=colors[m],zorder=0)\n",
    "#     axs[1,2].errorbar(var_ranges[modeln], tuning_curves[celln,modeln], yerr=tuning_stds[celln,modeln], label=titles[modeln], c=clrs[modeln],lw=4,elinewidth=3)\n",
    "    axs[1,2].plot(edge_mids,stat_range/model_dt,'.-', ms=20, lw=4,c=clrs[modeln])\n",
    "\n",
    "axs[1,2].set_ylim(bottom=0,top=top_yaxs)\n",
    "axs[1,2].set_xlim(-30,30)\n",
    "axs[1,2].set_xlabel('Angle ($ ^{\\degree}$)')\n",
    "axs[1,2].set_ylabel('Spikes/s')\n",
    "axs[1,2].set_title('Head Tuning Curves')\n",
    "lines = axs[1,2].get_lines()\n",
    "legend1 = axs[1,2].legend([lines[0]],[titles[2]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "legend2 = axs[1,2].legend([lines[1]],[titles[3]],bbox_to_anchor=(1.01, .9), fontsize=12)\n",
    "axs[1,2].add_artist(legend1)\n",
    "\n",
    "# axs[1,2].legend(bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "\n",
    "\n",
    "# pred_rangelin = np.linspace(pred_range[0],pred_range[1],stat_bins)\n",
    "axs[1,3].scatter(pred_all[celln]/model_dt,test_nsp[celln]/model_dt,c='k',s=15)\n",
    "axs[1,3].plot(np.linspace(test_nsp_range[0],test_nsp_range[1]),np.linspace(test_nsp_range[0],test_nsp_range[1]),'k--',zorder=0)\n",
    "axs[1,3].set_xlabel('Predicted Spike Rate')\n",
    "axs[1,3].set_ylabel('Actual Spike Rate')\n",
    "cbar = add_colorbar(img)\n",
    "# cbar.set_label('count')\n",
    "\n",
    "if MovModel == 1:\n",
    "    w_move = np.zeros((model_nsp.shape[-1],len(titles)))\n",
    "elif MovModel == 3:\n",
    "    Msta = w_move[:,:-len(titles)].reshape((model_nsp.shape[-1],nt_glm_lag,len(titles))+nks)\n",
    "    w_move = w_move[:,-len(titles):]\n",
    "for modeln in range(len(titles)):\n",
    "    axs[1,4].bar(modeln, w_move[celln,modeln], color=clrs[modeln])\n",
    "    axs[1,4].set_xticks(np.arange(0,len(titles)))\n",
    "    axs[1,4].set_xticklabels(titles)\n",
    "    axs[1,4].set_ylabel('GLM Weight')\n",
    "\n",
    "\n",
    "mse_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "mse_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "alpha_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "alpha_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "\n",
    "traces = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "traces_mean = np.zeros((ncells,len(titles),stat_bins-1)) # (model_type,quartile,FR)\n",
    "edges_all = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "# df_traces = pd.DataFrame([],columns=['modeln','quartile','FR']) \n",
    "for modeln in range(len(titles)):\n",
    "    metric = move_test[:,modeln]\n",
    "    nranges = np.quantile(metric,quartiles)# np.linspace(np.nanmean(metric)-2*np.nanstd(metric), np.nanmean(metric)+2*np.nanstd(metric),N_bins)\n",
    "    stat_all, edges, _ = binned_statistic(predcell,nspcell, statistic='mean',bins=pred_rangelin)\n",
    "    edge_mids = xbin_pts#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    traces_mean[celln,modeln]=stat_all\n",
    "    max_fr = np.max(stat_all)\n",
    "#     axs[1,modeln].set_xlim(0,pred_range[1]+np.std(pred_range))\n",
    "#     axs[1,modeln].set_ylim(0,np.max(stat)+np.std(stat))\n",
    "\n",
    "    for n in range(len(nranges)-1):\n",
    "        ind = np.where(((metric<=nranges[n+1])&(metric>nranges[n])))[0]\n",
    "        pred = predcell[ind]\n",
    "        sp = nspcell[ind]\n",
    "\n",
    "        stat_range, edges, _ = binned_statistic(pred, sp, statistic='mean',bins=pred_rangelin)\n",
    "        edge_mids = xbin_pts #np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "        traces[celln,modeln,n]=stat_range\n",
    "        edges_all[celln,modeln,n]=edge_mids\n",
    "        res_add = minimize_scalar(f_add,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "        res_mult = minimize_scalar(f_mult,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "        mse_add[celln, modeln, n] = res_add.fun\n",
    "        mse_mult[celln, modeln, n] = res_mult.fun\n",
    "        alpha_add[celln, modeln, n] = res_add.x\n",
    "        alpha_mult[celln, modeln, n] = res_mult.x\n",
    "\n",
    "        axs[2,modeln].plot(edge_mids, stat_range,'.-', c=colors[n],label='{:.02f} : {:.02f}'.format(nranges[n],nranges[n+1]),lw=4,ms=20,alpha=.9)\n",
    "        axs[2,modeln].set_title('Metric: {}'.format(titles[modeln]), color=clrs[modeln])\n",
    "        axs[2,modeln].set_xlabel('Predicted Spike Rate')\n",
    "        axs[2,modeln].set_ylabel('Actual Spike Rate')\n",
    "    \n",
    "    lim_max = np.max(np.hstack((edge_mids,traces[celln,modeln].flatten())))+.5*np.std(edges)\n",
    "    lim_min = np.min(np.hstack((edge_mids,traces[celln,modeln].flatten())))-.5*np.std(edges)\n",
    "    lims = (0, lim_max) if (lim_min)<0 else (lim_min,lim_max) \n",
    "    axs[2,modeln].plot(np.linspace(lims[0],lims[1]),np.linspace(lims[0],lims[1]),'k--',zorder=0)\n",
    "    axs[2,modeln].plot(edge_mids, stat_all,'.-', c='k', lw=5, ms=20, label='All_data', alpha=.8)\n",
    "    axs[2,modeln].legend(bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "    axs[2,modeln].axis('equal')\n",
    "#     axs[2,modeln].set_xlim(left=0)\n",
    "    axs[2,modeln].set(xlim=lims, ylim=lims)\n",
    "#     axs[2,modeln].set_xlim([0,xbin_pts[-1]])\n",
    "    axs[2,modeln].set_ylim(bottom=0)\n",
    "\n",
    "dmodel = mse_add[celln]-mse_mult[celln]\n",
    "crange = np.max(np.abs(dmodel))\n",
    "im = axs[2,-1].imshow(dmodel,cmap='seismic',vmin=-crange,vmax=crange)\n",
    "axs[2,-1].set_yticks(np.arange(0,4))\n",
    "axs[2,-1].set_yticklabels(titles)\n",
    "axs[2,-1].set_ylabel('Movement Model')\n",
    "axs[2,-1].set_xticks(np.arange(0,4))\n",
    "axs[2,-1].set_xticklabels(['.25','.5','.75','1'])\n",
    "axs[2,-1].set_xlabel('Quantile Range')\n",
    "axs[2,-1].set_title('$MSE_{add}$ - $MSE_{mult}$')\n",
    "cbar = add_colorbar(im)\n",
    "\n",
    "plt.suptitle('Celln:{}, r2={:.03f}'.format(celln,r2_all[celln]),y=1,fontsize=30)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# fig.savefig(FigPath/'CellSummary_N{}_T{:02d}.png'.format(celln,nt_glm_lag), facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-cleanup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weight_decay(net, l2_value, skip_list=()):\n",
    "    decay, no_decay = [], []\n",
    "    for name, param in net.named_parameters():\n",
    "        if not param.requires_grad: continue # frozen weights\t\t            \n",
    "        if len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list: no_decay.append(param)\n",
    "        else: decay.append(param)\n",
    "    return [{'params': no_decay, 'weight_decay': 0.}, {'params': decay, 'weight_decay': l2_value}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schematics of Add and Mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_type = 'fm1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schematic of Addative vs. Multiplicative\n",
    "\n",
    "celln = 126\n",
    "modeln=3\n",
    "quartiles = np.arange(0,1.25,.25)\n",
    "\n",
    "dataset_type = 'train'\n",
    "\n",
    "if dataset_type == 'train':\n",
    "    predcell = pred_train[:,celln]/model_dt\n",
    "    nspcell = train_nsp[:,celln]/model_dt\n",
    "    nsp_raw = train_nsp[:,celln]\n",
    "    pred_raw = pred_train[:,celln]\n",
    "    move_data = move_train.copy()\n",
    "else: \n",
    "    predcell = pred_all[:,celln]/model_dt\n",
    "    nspcell = test_nsp[:,celln]/model_dt\n",
    "    nsp_raw = test_nsp[:,celln]\n",
    "    pred_raw = pred_all[:,celln]\n",
    "    move_data = move_test.copy()\n",
    "\n",
    "angn=0\n",
    "\n",
    "metric = move_data[:,modeln]\n",
    "nranges = np.quantile(var_ranges[modeln],quartiles)# np.linspace(np.nanmean(metric)-2*np.nanstd(metric), np.nanmean(metric)+2*np.nanstd(metric),N_bins)\n",
    "stat_all, edges, _ = binned_statistic(predcell,nspcell, statistic='mean',bins=pred_rangelin)\n",
    "edge_mids = xbin_pts#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "traces_mean[celln,modeln]=stat_all\n",
    "max_fr = np.max(stat_all)\n",
    "\n",
    "lim_max = 40\n",
    "lim_min = 0\n",
    "lims = (0, lim_max) if (lim_min)<0 else (lim_min,lim_max) \n",
    "spike_percentiles = np.arange(0,1.25,.25)\n",
    "spike_percentiles[-1]=.99\n",
    "spk_percentile2 = np.arange(.125,1.125,.25)\n",
    "pred_rangelin = np.quantile(predcell,spike_percentiles)\n",
    "xbin_pts = np.quantile(predcell,spk_percentile2)\n",
    "stat_bins = len(pred_rangelin) #5\n",
    "mult_range = np.flip(np.linspace(1.2,.7,4))\n",
    "for angn in range(5):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(8,5))\n",
    "    metric = move_test[:,modeln]\n",
    "    \n",
    "    nranges = np.quantile(var_ranges[modeln],np.flip(quartiles))# np.linspace(np.nanmean(metric)-2*np.nanstd(metric), np.nanmean(metric)+2*np.nanstd(metric),N_bins)\n",
    "#     stat_all, edges, _ = binned_statistic(predcell,nspcell, statistic='mean',bins=pred_rangelin)\n",
    "    stat_all = np.linspace(10,30,4)\n",
    "    edge_mids = stat_all #np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    traces_mean[celln,modeln]=stat_all\n",
    "    ax = axs\n",
    "    max_fr = np.max(stat_all)\n",
    "    for n in np.flip(np.arange(angn)):\n",
    "        stat_mult = np.linspace(10,30*mult_range[n],4)\n",
    "#         stat_mult[1:] = stat_mult[1:]*mult_range[n]\n",
    "        ax.plot(edge_mids, stat_mult,'.-', c=colors[n],label='{:d}$\\degree$ : {:d}$\\degree$'.format(int(nranges[n]),int(nranges[n+1])),lw=4,ms=20,alpha=1)\n",
    "    ax.set_title('Metric: {} Multiplicative'.format(titles[modeln]), color=clrs[modeln])\n",
    "    ax.set_xlabel('Predicted (sp/sec)')\n",
    "    ax.set_ylabel('Actual (sp/sec)')\n",
    "\n",
    "    ax.plot(np.linspace(lims[0],lims[1]),np.linspace(lims[0],lims[1]),'k--',zorder=0)\n",
    "    \n",
    "    ax.plot(edge_mids, stat_all,'.-', c='k', lw=5, ms=20, label='All_data', alpha=.8)\n",
    "    # ax.legend(bbox_to_anchor=(1.02, .8), fontsize=12)\n",
    "    ax.set(xlim=lims, ylim=lims)\n",
    "    ax.set_xticks(np.arange(0,lims[-1],10))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(FigPath/'Schematic_mult_{}_N{}.png'.format(stim_type,angn), facecolor='white', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schematic of Addative vs. Multiplicative\n",
    "\n",
    "celln = 121\n",
    "modeln=3\n",
    "quartiles = np.arange(0,1.25,.25)\n",
    "add_range = np.flip(np.linspace(8,-8,4))\n",
    "dataset_type = 'train'\n",
    "\n",
    "if dataset_type == 'train':\n",
    "    predcell = pred_train[:,celln]/model_dt\n",
    "    nspcell = train_nsp[:,celln]/model_dt\n",
    "    nsp_raw = train_nsp[:,celln]\n",
    "    pred_raw = pred_train[:,celln]\n",
    "    move_data = move_train.copy()\n",
    "else: \n",
    "    predcell = pred_all[:,celln]/model_dt\n",
    "    nspcell = test_nsp[:,celln]/model_dt\n",
    "    nsp_raw = test_nsp[:,celln]\n",
    "    pred_raw = pred_all[:,celln]\n",
    "    move_data = move_test.copy()\n",
    "\n",
    "angn=4\n",
    "\n",
    "lim_max = 40\n",
    "lim_min = 0\n",
    "lims = (0, lim_max) if (lim_min)<0 else (lim_min,lim_max) \n",
    "for angn in range(5):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(8,5))\n",
    "    metric = move_test[:,modeln]\n",
    "    nranges = np.quantile(var_ranges[modeln],np.flip(quartiles))# np.linspace(np.nanmean(metric)-2*np.nanstd(metric), np.nanmean(metric)+2*np.nanstd(metric),N_bins)\n",
    "#     stat_all, edges, _ = binned_statistic(predcell,nspcell, statistic='mean',bins=pred_rangelin)\n",
    "    stat_all = np.linspace(10,30,4)\n",
    "    edge_mids = stat_all#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    traces_mean[celln,modeln]=stat_all\n",
    "    ax = axs\n",
    "    max_fr = np.max(stat_all)\n",
    "\n",
    "    for n in range(angn):\n",
    "        ind = np.where(((metric<=nranges[n+1])&(metric>nranges[n])))[0]\n",
    "        pred = predcell[ind]\n",
    "        sp = nspcell[ind]\n",
    "        ax.plot(edge_mids, stat_all+add_range[n],'.-', c=colors[n],label='{:d}$\\degree$ : {:d}$\\degree$'.format(int(nranges[n]),int(nranges[n+1])),lw=4,ms=20,alpha=1)\n",
    "    ax.set_title('Metric: {} Additive'.format(titles[modeln]), color=clrs[modeln])\n",
    "    ax.set_xlabel('Predicted (sp/sec)')\n",
    "    ax.set_ylabel('Actual (sp/sec)')\n",
    "\n",
    "    ax.plot(np.linspace(lims[0],lims[1]),np.linspace(lims[0],lims[1]),'k--',zorder=0)\n",
    "    ax.plot(edge_mids, stat_all,'.-', c='k', lw=5, ms=20, label='All_data', alpha=.8)\n",
    "    # ax.legend(bbox_to_anchor=(1.02, .8), fontsize=12)\n",
    "    ax.set(xlim=lims, ylim=lims)\n",
    "    ax.set_xticks(np.arange(0,lims[-1],10))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(FigPath/'Schematic_add_{}_N{}.png'.format(stim_type,angn), facecolor='white', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 126\n",
    "for angn in range(5):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(8,5))\n",
    "    # Eye Tuning Curve\n",
    "    top_yaxs = np.max(ax_ylims[celln])+2*np.max(tuning_stds[celln])\n",
    "    metric = move_test[:,modeln]\n",
    "    var_ranges_schematic = np.linspace(var_ranges[modeln,0],var_ranges[modeln,-1],len(var_ranges[modeln]))\n",
    "    nranges = np.quantile(var_ranges_schematic,quartiles)\n",
    "    cmap = mpl.colors.ListedColormap(np.flip(colors,axis=0), N=colors.shape[0])\n",
    "    norm = mpl.colors.BoundaryNorm(boundaries=np.floor(nranges), ncolors=cmap.N)\n",
    "    ax = axs\n",
    "    tuning_schematic = np.linspace(tuning_curves[celln,modeln][0],tuning_curves[celln,modeln][-1],len(tuning_curves[celln,modeln]))\n",
    "    for m in range(angn):\n",
    "        ax.axvspan(nranges[m], nranges[m+1],ymin=0,ymax=1,alpha=0.8, color=colors[m],zorder=0)\n",
    "\n",
    "    # img = ax.imshow(np.round(nranges,decimals=1)[None,:angn],aspect='auto', origin='lower',cmap=cmap,norm=norm,extent=(nranges[0],nranges[angn],0,top_yaxs),alpha=.8)\n",
    "    ax.errorbar(var_ranges_schematic,tuning_schematic, yerr=tuning_stds[celln,modeln],label=titles[modeln],c='k',lw=4,elinewidth=3)\n",
    "    ax.set_ylim(bottom=0,top=np.max(ax_ylims,axis=1)[celln]+2*np.max(tuning_stds,axis=(1,2))[celln])\n",
    "    ax.set_xlim(-50,50)\n",
    "    ax.set_xlabel('Pitch (deg)')\n",
    "    ax.set_ylabel('sp/sec')\n",
    "    ax.set_title('Head Tuning Curve')\n",
    "    # ax.legend(bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "\n",
    "    lines = ax.get_lines()\n",
    "    # legend1 = ax.legend([lines[0]],[titles[0]],bbox_to_anchor=(1.01, .2), fontsize=12)\n",
    "#     legend2 = axs.legend([lines[1]],[titles[1]],bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "#     ax.add_artist(legend1)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(FigPath/'Schematic_Tuning_{}_N{}.png'.format(stim_type,angn), facecolor='white', transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Curves and Modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celln = 121# np.argmax(r2_all)\n",
    "bin_length = 40\n",
    "dataset_type = 'train'\n",
    "ncells=model_nsp.shape[-1]\n",
    "colors = plt.cm.cool(np.linspace(0,1,4))\n",
    "clrs = ['blue','orange','green','red']\n",
    "quartiles = np.arange(0,1.25,.25)\n",
    "\n",
    "fig, axs = plt.subplots(2,4, figsize=((25,10))) \n",
    "\n",
    "if dataset_type == 'test':\n",
    "    predcell = pred_train[:,celln]/model_dt\n",
    "    nspcell = train_nsp[:,celln]/model_dt\n",
    "    nsp_raw = train_nsp[:,celln]\n",
    "    pred_raw = pred_train[:,celln]\n",
    "    move_data = move_train.copy()\n",
    "else: \n",
    "    predcell = pred_all[:,celln]/model_dt\n",
    "    nspcell = test_nsp[:,celln]/model_dt\n",
    "    nsp_raw = test_nsp[:,celln]\n",
    "    pred_raw = pred_all[:,celln]\n",
    "    move_data = move_test.copy()\n",
    "\n",
    "nsp_smooth=((np.convolve(nsp_raw, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "pred_smooth=((np.convolve(pred_raw, np.ones(bin_length), 'same')) / (bin_length * model_dt))[bin_length:-bin_length]\n",
    "\n",
    "\n",
    "# Set up predicted spike range between 1-99th percentile\n",
    "stat_bins = 5\n",
    "pred_range = np.quantile(predcell,[.1,.9])\n",
    "test_nsp_range = np.quantile(nspcell,[.01,1])\n",
    "spike_percentiles = np.arange(0,1.25,.25)\n",
    "spike_percentiles[-1]=.99\n",
    "spk_percentile2 = np.arange(.125,1.125,.25)\n",
    "pred_rangelin = np.quantile(predcell,spike_percentiles)\n",
    "xbin_pts = np.quantile(predcell,spk_percentile2)\n",
    "stat_bins = len(pred_rangelin) #5\n",
    "\n",
    "# Eye Tuning Curve\n",
    "top_yaxs = np.max(ax_ylims[celln])+2*np.max(tuning_stds[celln])\n",
    "for i,modeln in enumerate(range(len(titles))):\n",
    "    metric = move_data[:,modeln]\n",
    "    nranges = np.quantile(metric,quartiles)\n",
    "    stat_range, edges, _ = binned_statistic(metric,nsp_raw,statistic='mean',bins=nranges)\n",
    "    edge_mids = np.quantile(metric,spk_percentile2)#\n",
    "    for m in range(len(nranges)-1):\n",
    "        axs[0,modeln].axvspan(nranges[m], nranges[m+1],ymin=0,ymax=1,alpha=0.8, color=colors[m],zorder=0)\n",
    "    axs[0,modeln].plot(edge_mids,stat_range/model_dt,'.-', ms=20, lw=4,c='k')\n",
    "\n",
    "    axs[0,modeln].set_ylim(bottom=0,top=np.max(ax_ylims,axis=1)[celln]+2*np.nanmax(tuning_stds,axis=(1,2))[celln])\n",
    "    axs[0,modeln].set_xlim(-30,30)\n",
    "    axs[0,modeln].set_xlabel('Angle (deg))')\n",
    "    axs[0,modeln].set_ylabel('sp/sec')\n",
    "    axs[0,modeln].set_title(titles[modeln],fontsize=24)\n",
    "\n",
    "\n",
    "mse_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "mse_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "alpha_add = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "alpha_mult = np.zeros((ncells,len(titles),len(quartiles)-1))\n",
    "\n",
    "traces = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "traces_mean = np.zeros((ncells,len(titles),stat_bins-1)) # (model_type,quartile,FR)\n",
    "edges_all = np.zeros((ncells,len(titles),len(quartiles)-1,stat_bins-1)) # (model_type,quartile,FR)\n",
    "# df_traces = pd.DataFrame([],columns=['modeln','quartile','FR']) \n",
    "for modeln in range(len(titles)):\n",
    "    metric = move_data[:,modeln]\n",
    "    nranges = np.quantile(metric,quartiles)# np.linspace(np.nanmean(metric)-2*np.nanstd(metric), np.nanmean(metric)+2*np.nanstd(metric),N_bins)\n",
    "    stat_all, edges, _ = binned_statistic(predcell,nspcell,statistic='mean',bins=pred_rangelin)\n",
    "    edge_mids = xbin_pts#np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "    traces_mean[celln,modeln]=stat_all\n",
    "    max_fr = np.max(stat_all)\n",
    "#     axs[1,modeln].set_xlim(0,pred_range[1]+np.std(pred_range))\n",
    "#     axs[1,modeln].set_ylim(0,np.max(stat)+np.std(stat))\n",
    "\n",
    "    for n in range(len(nranges)-1):\n",
    "        ind = np.where(((metric<=nranges[n+1])&(metric>nranges[n])))[0]\n",
    "        pred = predcell[ind]\n",
    "        sp = nspcell[ind]\n",
    "\n",
    "        stat_range, edges, _ = binned_statistic(pred, sp, statistic='mean',bins=pred_rangelin)\n",
    "        edge_mids = xbin_pts #np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "        traces[celln,modeln,n]=stat_range\n",
    "        edges_all[celln,modeln,n]=edge_mids\n",
    "        res_add = minimize_scalar(f_add,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "        res_mult = minimize_scalar(f_mult,args=(stat_range/max_fr, stat_all/max_fr))\n",
    "        mse_add[celln, modeln, n] = res_add.fun\n",
    "        mse_mult[celln, modeln, n] = res_mult.fun\n",
    "        alpha_add[celln, modeln, n] = res_add.x\n",
    "        alpha_mult[celln, modeln, n] = res_mult.x\n",
    "\n",
    "        axs[1,modeln].plot(edge_mids, stat_range,'.-', c=colors[n],label='{:.02f} : {:.02f}'.format(nranges[n],nranges[n+1]),lw=4,ms=20,alpha=.9)\n",
    "        # axs[1,modeln].set_title('Metric: {}'.format(titles[modeln]), color=clrs[modeln])\n",
    "        axs[1,modeln].set_xlabel('Predicted (sp/sec)')\n",
    "        axs[1,modeln].set_ylabel('Actual (sp/sec)')\n",
    "    \n",
    "    lim_max = np.nanmax(np.hstack((edge_mids,traces[celln,modeln].flatten())))+.75*np.std(edges)\n",
    "    lim_min = np.nanmin(np.hstack((edge_mids,traces[celln,modeln].flatten())))-.75*np.std(edges)\n",
    "    lims = (0, lim_max) if (lim_min)<0 else (lim_min,lim_max) \n",
    "    axs[1,modeln].plot(np.linspace(0,lims[1]),np.linspace(0,lims[1]),'k--',zorder=0)\n",
    "    axs[1,modeln].plot(edge_mids, stat_all,'.-', c='k', lw=5, ms=20, label='All_data', alpha=.8)\n",
    "    # axs[1,modeln].legend(bbox_to_anchor=(1.01, 1), fontsize=12)\n",
    "    # axs[1,modeln].axis('equal')\n",
    "    axs[1,modeln].set(xlim=(0,lims[1]), ylim=(0,lims[1]))\n",
    "    axs[1,modeln].set_ylim(bottom=0)\n",
    "\n",
    "\n",
    "# plt.suptitle('Celln:{}, r2={:.03f}'.format(celln,r2_all[celln]),y=1,fontsize=30)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig.savefig(FigPath_SFN/'CellTuning{}_T{:02d}.png'.format(celln,nt_glm_lag), facecolor='white', transparent=True, bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae2df1b5b2cc9cafc9aad66187e6d6dd9c60927ae7fe28644cf330a9c23b714e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
