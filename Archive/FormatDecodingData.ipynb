{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spoken-lighting",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "import sys \n",
    "import yaml \n",
    "import glob\n",
    "import h5py \n",
    "import ray\n",
    "import logging \n",
    "import json\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "# import io_dict_to_hdf5 as ioh5\n",
    "import xarray as xr\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy import interpolate \n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import shift as imshift\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sys.path.append(str(Path('.').absolute().parent))\n",
    "from utils import check_path, add_colorbar, sizeof_fmt\n",
    "import io_dict_to_hdf5 as ioh5\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "FigPath = check_path(Path('~/Research/SensoryMotorPred_Data').expanduser(),'Figures')\n",
    "\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    logging_level=logging.ERROR,\n",
    ")\n",
    "print(f'Dashboard URL: https://{ray.get_dashboard_url()}')\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-package",
   "metadata": {},
   "source": [
    "# Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path('~/Research/SensoryMotorPred_Data/data/070921/J553RT/fm1').expanduser()\n",
    "with open(save_dir / 'file_dict.json','r') as fp:\n",
    "    file_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@ray.remote\n",
    "def shift_vid_parallel(x, world_vid, warp_mode, criteria, dt):\n",
    "    xshift_t = []\n",
    "    yshift_t = []\n",
    "    cc_t = []\n",
    "    for i in range(x,x+dt):\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        try: \n",
    "            (cc, warp_matrix) = cv2.findTransformECC(world_vid[i,:,:], world_vid[i+1,:,:], warp_matrix, warp_mode, criteria, inputMask=None, gaussFiltSize=1)\n",
    "            xshift = warp_matrix[0,2]\n",
    "            yshift = warp_matrix[1,2]\n",
    "        except:\n",
    "            cc = np.nan\n",
    "            xshift=np.nan\n",
    "            yshift = np.nan\n",
    "        xshift_t.append(xshift)\n",
    "        yshift_t.append(yshift)\n",
    "        cc_t.append(cc)\n",
    "    return xshift_t, yshift_t, cc_t\n",
    "\n",
    "@ray.remote\n",
    "def shift_world_pt2(f, dt, world_vid, thInterp, phiInterp, ycorrection, xcorrection):\n",
    "    if (f+dt) < world_vid.shape[0]:\n",
    "        world_vid2 = np.zeros((dt,world_vid.shape[1],world_vid.shape[2]))\n",
    "        for n, x in enumerate(range(f,f+dt)):\n",
    "            world_vid2[n,:,:] = imshift(world_vid[x,:,:],(-np.int8(thInterp[x]*ycorrection[0] + phiInterp[x]*ycorrection[1]),\n",
    "                                                         -np.int8(thInterp[x]*xcorrection[0] + phiInterp[x]*xcorrection[1])))\n",
    "    else: \n",
    "        world_vid2 = np.zeros((world_vid.shape[0]-f,world_vid.shape[1],world_vid.shape[2]))\n",
    "        for n,x in enumerate(range(f,world_vid.shape[0])):\n",
    "            world_vid2[n,:,:] = imshift(world_vid[x,:,:],(-np.int8(thInterp[x]*ycorrection[0] + phiInterp[x]*ycorrection[1]),\n",
    "                                                         -np.int8(thInterp[x]*xcorrection[0] + phiInterp[x]*xcorrection[1])))\n",
    "    return world_vid2\n",
    "\n",
    "\n",
    "def grab_aligned_data(goodcells, worldT, accT, img_norm, gz, groll, gpitch, th_interp, phi_interp, free_move=True, downsamp=0.25, model_dt=0.025):\n",
    "    # get number of good units\n",
    "    n_units = len(goodcells)\n",
    "    print('doing GLM receptive field estimate')\n",
    "    # simplified setup for GLM\n",
    "    # these are general parameters (spike rates, eye position)\n",
    "    n_units = len(goodcells)\n",
    "    print('get timing')\n",
    "    model_t = np.arange(0,np.max(worldT),model_dt)\n",
    "    model_nsp = np.zeros((n_units,len(model_t)))\n",
    "\n",
    "    # get spikes / rate\n",
    "    print('get spikes')\n",
    "    bins = np.append(model_t,model_t[-1]+model_dt)\n",
    "    for i,ind in enumerate(goodcells.index):\n",
    "        model_nsp[i,:],bins = np.histogram(goodcells.at[ind,'spikeT'],bins)\n",
    "\n",
    "    # get eye position\n",
    "    print('get eye')\n",
    "    model_th = th_interp(model_t+model_dt/2)\n",
    "    model_phi = phi_interp(model_t+model_dt/2)\n",
    "    # del thInterp, phiInterp\n",
    "\n",
    "    # get active times\n",
    "    if free_move:\n",
    "        interp = interp1d(accT,(gz-np.mean(gz))*7.5,bounds_error=False)\n",
    "        model_gz = interp(model_t)\n",
    "        model_active = np.convolve(np.abs(model_gz), np.ones(int(1/model_dt)), 'same') / len(np.ones(int(1/model_dt)))\n",
    "        use = np.where((model_active>40))[0] # (np.abs(model_th)<10) & (np.abs(model_phi)<10) & \n",
    "        roll_interp = interp1d(accT,groll,bounds_error=False)\n",
    "        pitch_interp = interp1d(accT,gpitch,bounds_error=False)\n",
    "        model_roll = roll_interp(model_t)\n",
    "        model_pitch = pitch_interp(model_t)\n",
    "    else:\n",
    "        use = np.where((np.abs(model_th)<10) & (np.abs(model_phi)<10))[0]\n",
    "    # get video ready for GLM\n",
    "    print('setting up video') \n",
    "    movInterp = interp1d(worldT, img_norm,'nearest', axis = 0,bounds_error = False) \n",
    "    testimg = movInterp(model_t[0])\n",
    "    testimg = cv2.resize(testimg,(int(np.shape(testimg)[1]*downsamp), int(np.shape(testimg)[0]*downsamp)))\n",
    "    testimg = testimg[5:-5,5:-5]; #remove area affected by eye movement correction\n",
    "    model_vid_sm = np.zeros((len(model_t),int(np.shape(testimg)[0]),int(np.shape(testimg)[1])),dtype=float)\n",
    "    for i in tqdm(range(len(model_t))):\n",
    "        model_vid = movInterp(model_t[i] + model_dt/2)\n",
    "        smallvid = cv2.resize(model_vid,(int(np.shape(img_norm)[2]*downsamp),int(np.shape(img_norm)[1]*downsamp)), interpolation=cv2.INTER_AREA)\n",
    "        smallvid = smallvid[5:-5,5:-5]\n",
    "        #smallvid = smallvid - np.mean(smallvid)\n",
    "        model_vid_sm[i,:] = smallvid\n",
    "    nks = np.shape(smallvid); nk = nks[0]*nks[1]\n",
    "    model_vid_sm[np.isnan(model_vid_sm)]=0\n",
    "    del movInterp\n",
    "    gc.collect()\n",
    "    return model_vid_sm, model_nsp, model_t, model_th, model_phi, model_roll, model_pitch, model_active\n",
    "\n",
    "def load_ephys_data_aligned(file_dict, save_dir, free_move=True, has_imu=True, has_mouse=False, max_frames=60*60, model_dt=.025):\n",
    "        \n",
    "    ##### Align Data #####\n",
    "    if (save_dir / 'ModelData_dt{:03d}.h5'.format(int(model_dt*1000))).exists():\n",
    "        data = ioh5.load((save_dir / 'ModelData_dt{:03d}.h5'.format(int(model_dt*1000))))\n",
    "    else:\n",
    "        ##### Loading ephys experiment data #####\n",
    "        print('Starting to Load Data')\n",
    "        world_data = xr.open_dataset(file_dict['world'])\n",
    "        world_vid_raw = np.uint8(world_data['WORLD_video'])\n",
    "        # resize worldcam\n",
    "        sz = world_vid_raw.shape # raw video size\n",
    "        # if size is larger than the target 60x80, resize by 0.5\n",
    "        if sz[1]>160:\n",
    "            downsamp = 0.5\n",
    "            world_vid = np.zeros((sz[0],np.int(sz[1]*downsamp),np.int(sz[2]*downsamp)), dtype = 'uint8')\n",
    "            for f in range(sz[0]):\n",
    "                world_vid[f,:,:] = cv2.resize(world_vid_raw[f,:,:],(np.int(sz[2]*downsamp),np.int(sz[1]*downsamp)))\n",
    "        else:\n",
    "            # if the worldcam has already been resized when the nc file was written in preprocessing, don't resize\n",
    "            world_vid = world_vid_raw.copy()\n",
    "        # world timestamps\n",
    "        worldT = world_data.timestamps.copy()\n",
    "\n",
    "        # open the topdown camera nc file\n",
    "        top_data = xr.open_dataset(file_dict['top'])\n",
    "        # get the speed of the base of the animal's tail in the topdown tracking\n",
    "        # most points don't track well enough for this to be done with other parts of animal (e.g. head points)\n",
    "        topx = top_data.TOP1_pts.sel(point_loc='tailbase_x').values; topy = top_data.TOP1_pts.sel(point_loc='tailbase_y').values\n",
    "        topdX = np.diff(topx); topdY = np.diff(topy)\n",
    "        top_speed = np.sqrt(topdX**2, topdY**2) # speed of tailbase in topdown camera\n",
    "        topT = top_data.timestamps.copy() # read in time timestamps\n",
    "        top_vid = np.uint8(top_data['TOP1_video']) # read in top video\n",
    "        # clear from memory\n",
    "        del top_data , world_vid_raw\n",
    "        gc.collect()\n",
    "\n",
    "        # load IMU data\n",
    "        if file_dict['imu'] is not None:\n",
    "            print('opening imu data')\n",
    "            imu_data = xr.open_dataset(file_dict['imu'])\n",
    "            accT = imu_data.IMU_data.sample # imu timestamps\n",
    "            acc_chans = imu_data.IMU_data # imu dample data\n",
    "            # raw gyro values\n",
    "            gx = np.array(acc_chans.sel(channel='gyro_x_raw'))\n",
    "            gy = np.array(acc_chans.sel(channel='gyro_y_raw'))\n",
    "            gz = np.array(acc_chans.sel(channel='gyro_z_raw'))\n",
    "            # gyro values in degrees\n",
    "            gx_deg = np.array(acc_chans.sel(channel='gyro_x'))\n",
    "            gy_deg = np.array(acc_chans.sel(channel='gyro_y'))\n",
    "            gz_deg = np.array(acc_chans.sel(channel='gyro_z'))\n",
    "            # pitch and roll in deg\n",
    "            groll = np.array(acc_chans.sel(channel='roll'))\n",
    "            gpitch = np.array(acc_chans.sel(channel='pitch'))\n",
    "\n",
    "        print('opening ephys data')\n",
    "        # ephys data for this individual recording\n",
    "        ephys_data = pd.read_json(file_dict['ephys'])\n",
    "        # sort units by shank and site order\n",
    "        ephys_data = ephys_data.sort_values(by='ch', axis=0, ascending=True)\n",
    "        ephys_data = ephys_data.reset_index()\n",
    "        ephys_data = ephys_data.drop('index', axis=1)\n",
    "        # spike times\n",
    "        ephys_data['spikeTraw'] = ephys_data['spikeT']\n",
    "        print('getting good cells')\n",
    "        # select good cells from phy2\n",
    "        goodcells = ephys_data.loc[ephys_data['group']=='good']\n",
    "        units = goodcells.index.values\n",
    "        # get number of good units\n",
    "        n_units = len(goodcells)\n",
    "\n",
    "        print('opening eyecam data')\n",
    "        # load eye data\n",
    "        eye_data = xr.open_dataset(file_dict['eye'])\n",
    "        eye_vid = np.uint8(eye_data['REYE_video'])\n",
    "        eyeT = eye_data.timestamps.copy()\n",
    "\n",
    "        # plot eye postion across recording\n",
    "        eye_params = eye_data['REYE_ellipse_params']\n",
    "\n",
    "        # define theta, phi and zero-center\n",
    "        th = np.array((eye_params.sel(ellipse_params = 'theta')-np.nanmean(eye_params.sel(ellipse_params = 'theta')))*180/3.14159)\n",
    "        phi = np.array((eye_params.sel(ellipse_params = 'phi')-np.nanmean(eye_params.sel(ellipse_params = 'phi')))*180/3.14159)\n",
    "\n",
    "        print('adjusting camera times to match ephys')\n",
    "        # adjust eye/world/top times relative to ephys\n",
    "        ephysT0 = ephys_data.iloc[0,12]\n",
    "        eyeT = eye_data.timestamps  - ephysT0\n",
    "        if eyeT[0]<-600:\n",
    "            eyeT = eyeT + 8*60*60 # 8hr offset for some data\n",
    "        worldT = world_data.timestamps - ephysT0\n",
    "        if worldT[0]<-600:\n",
    "            worldT = worldT + 8*60*60\n",
    "        if free_move is True and has_imu is True:\n",
    "            accT = imu_data.IMU_data.sample - ephysT0\n",
    "        # if free_move is False and has_mouse is True:\n",
    "        #     speedT = spd_tstamps - ephysT0\n",
    "        if free_move is True:\n",
    "            topT = topT - ephysT0\n",
    "\n",
    "        ##### Clear some memory #####\n",
    "        del world_data, eye_data, ephys_data \n",
    "        gc.collect()\n",
    "\n",
    "        ##### Correction to world cam #####\n",
    "        if (save_dir / 'corrected_worldcam.npy').exists():\n",
    "            world_vid = np.load(save_dir / 'corrected_worldcam.npy', mmap_mode='r')\n",
    "            # get eye displacement for each worldcam frame\n",
    "            th_interp = interp1d(eyeT, th, bounds_error=False)\n",
    "            phi_interp = interp1d(eyeT, phi, bounds_error=False)\n",
    "        else:\n",
    "            start = time.time()\n",
    "            # get eye displacement for each worldcam frame\n",
    "            th_interp = interp1d(eyeT, th, bounds_error=False)\n",
    "            phi_interp = interp1d(eyeT, phi, bounds_error=False)\n",
    "            dth = np.diff(th_interp(worldT))\n",
    "            dphi = np.diff(phi_interp(worldT))\n",
    "            # calculate x-y shift for each worldcam frame  \n",
    "            number_of_iterations = 5000\n",
    "            termination_eps = 1e-4\n",
    "            criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations, termination_eps)\n",
    "            warp_mode = cv2.MOTION_TRANSLATION\n",
    "\n",
    "            # Parallel Testing\n",
    "            world_vid_r = ray.put(world_vid)\n",
    "            warp_mode_r = ray.put(warp_mode)\n",
    "            criteria_r = ray.put(criteria)\n",
    "            dt = 60\n",
    "            result_ids = []\n",
    "            [result_ids.append(shift_vid_parallel.remote(i, world_vid_r, warp_mode_r, criteria_r, dt)) for i in range(0, max_frames, dt)]\n",
    "            results_p = ray.get(result_ids)\n",
    "            results_p = np.array(results_p).transpose(0,2,1).reshape(-1,3)\n",
    "\n",
    "            xshift = results_p[:,0]\n",
    "            yshift = results_p[:,1]\n",
    "            cc = results_p[:,2]\n",
    "\n",
    "            xmodel = LinearRegression()\n",
    "            ymodel = LinearRegression()\n",
    "\n",
    "            # eye data as predictors\n",
    "            eyeData = np.zeros((max_frames,2))\n",
    "            eyeData[:,0] = dth[0:max_frames]\n",
    "            eyeData[:,1] = dphi[0:max_frames]\n",
    "            # shift in x and y as outputs\n",
    "            xshiftdata = xshift[0:max_frames]\n",
    "            yshiftdata = yshift[0:max_frames]\n",
    "            # only use good data\n",
    "            # not nans, good correlation between frames, small eye movements (no sacccades, only compensatory movements)\n",
    "            usedata = ~np.isnan(eyeData[:,0]) & ~np.isnan(eyeData[:,1]) & (cc>0.95)  & (np.abs(eyeData[:,0])<2) & (np.abs(eyeData[:,1])<2) & (np.abs(xshiftdata)<5) & (np.abs(yshiftdata)<5)\n",
    "\n",
    "            # fit xshift\n",
    "            xmodel.fit(eyeData[usedata,:],xshiftdata[usedata])\n",
    "            xmap = xmodel.coef_\n",
    "            xrscore = xmodel.score(eyeData[usedata,:],xshiftdata[usedata])\n",
    "            # fit yshift\n",
    "            ymodel.fit(eyeData[usedata,:],yshiftdata[usedata])\n",
    "            ymap = ymodel.coef_\n",
    "            yrscore = ymodel.score(eyeData[usedata,:],yshiftdata[usedata])\n",
    "            warp_mat_duration = time.time() - start\n",
    "            print(\"warp mat duration =\", warp_mat_duration)\n",
    "            del results_p, warp_mode_r, criteria_r, result_ids\n",
    "            gc.collect()\n",
    "\n",
    "            start = time.time()\n",
    "            print('estimating eye-world calibration')\n",
    "            xcorrection_r = ray.put(xmap.copy())\n",
    "            ycorrection_r = ray.put(ymap.copy())\n",
    "            print('shifting worldcam for eyes')\n",
    "\n",
    "            thInterp_r = ray.put(th_interp(worldT))\n",
    "            phiInterp_r = ray.put(phi_interp(worldT))\n",
    "\n",
    "            dt = 1000\n",
    "            result_ids2 = []\n",
    "            [result_ids2.append(shift_world_pt2.remote(f, dt, world_vid_r, thInterp_r, phiInterp_r, ycorrection_r, xcorrection_r)) for f in range(0, world_vid.shape[0], dt)] # \n",
    "            results = ray.get(result_ids2)\n",
    "            world_vid = np.concatenate(results,axis=0).astype(np.uint8)\n",
    "            print('saving worldcam video corrected for eye movements')\n",
    "            np.save(file=(save_dir / 'corrected_worldcam.npy'), arr=world_vid)\n",
    "            shift_world_duration = time.time() - start\n",
    "            print(\"shift world duration =\", shift_world_duration)\n",
    "            print('Total Duration:', warp_mat_duration + shift_world_duration)\n",
    "\n",
    "        ##### Calculating image norm #####\n",
    "        print('Calculating Image Norm')\n",
    "        start = time.time()\n",
    "        world_vid = world_vid.astype(float)\n",
    "        std_im = np.std(world_vid, axis=0, dtype=float)\n",
    "        img_norm = ((world_vid-np.mean(world_vid,axis=0,dtype=float))/std_im).astype(float)\n",
    "        std_im[std_im<20] = 0\n",
    "        img_norm = (img_norm * (std_im>0)).astype(float)\n",
    "        del world_vid\n",
    "        gc.collect()\n",
    "        img_norm_duration = time.time() - start\n",
    "        print(\"img_norm duration =\", img_norm_duration)\n",
    "\n",
    "        start = time.time()\n",
    "        model_vid_sm, model_nsp, model_t, model_th, model_phi, model_roll, model_pitch, model_active = grab_aligned_data(\n",
    "            goodcells, worldT, accT, img_norm, gz, groll, gpitch, th_interp, phi_interp, free_move=True, downsamp=0.25, model_dt=model_dt)\n",
    "\n",
    "        data = {'model_vid_sm': model_vid_sm,\n",
    "                'model_nsp': model_nsp.T,\n",
    "                'model_t': model_t,\n",
    "                'model_th': model_th,\n",
    "                'model_phi': model_phi,\n",
    "                'model_roll': model_roll,\n",
    "                'model_pitch': model_pitch,\n",
    "                'model_active': model_active}\n",
    "        \n",
    "        ioh5.save( (save_dir / 'ModelData_dt{:03d}.h5'.format(int(model_dt*1000))), data)\n",
    "        align_data_duration = time.time() - start\n",
    "        print(\"align_data_duration =\", align_data_duration)\n",
    "    print('Done Loading Aligned Data')\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_ephys_data_aligned(file_dict, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-filling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-binding",
   "metadata": {},
   "source": [
    "# Testing Aligning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_move = True; has_imu = True; has_mouse = False\n",
    "##### Loading ephys experiment data #####\n",
    "world_data = xr.open_dataset(file_dict['world'])\n",
    "world_vid_raw = np.uint8(world_data['WORLD_video'])\n",
    "# resize worldcam\n",
    "sz = world_vid_raw.shape # raw video size\n",
    "# if size is larger than the target 60x80, resize by 0.5\n",
    "if sz[1]>160:\n",
    "    downsamp = 0.5\n",
    "    world_vid = np.zeros((sz[0],np.int(sz[1]*downsamp),np.int(sz[2]*downsamp)), dtype = 'uint8')\n",
    "    for f in range(sz[0]):\n",
    "        world_vid[f,:,:] = cv2.resize(world_vid_raw[f,:,:],(np.int(sz[2]*downsamp),np.int(sz[1]*downsamp)))\n",
    "else:\n",
    "    # if the worldcam has already been resized when the nc file was written in preprocessing, don't resize\n",
    "    world_vid = world_vid_raw.copy()\n",
    "# world timestamps\n",
    "worldT = world_data.timestamps.copy()\n",
    "\n",
    "# open the topdown camera nc file\n",
    "top_data = xr.open_dataset(file_dict['top'])\n",
    "# get the speed of the base of the animal's tail in the topdown tracking\n",
    "# most points don't track well enough for this to be done with other parts of animal (e.g. head points)\n",
    "topx = top_data.TOP1_pts.sel(point_loc='tailbase_x').values; topy = top_data.TOP1_pts.sel(point_loc='tailbase_y').values\n",
    "topdX = np.diff(topx); topdY = np.diff(topy)\n",
    "top_speed = np.sqrt(topdX**2, topdY**2) # speed of tailbase in topdown camera\n",
    "topT = top_data.timestamps.copy() # read in time timestamps\n",
    "top_vid = np.uint8(top_data['TOP1_video']) # read in top video\n",
    "# clear from memory\n",
    "del top_data, world_vid_raw\n",
    "gc.collect()\n",
    "\n",
    "# load IMU data\n",
    "if file_dict['imu'] is not None:\n",
    "    print('opening imu data')\n",
    "    imu_data = xr.open_dataset(file_dict['imu'])\n",
    "    accT = imu_data.IMU_data.sample # imu timestamps\n",
    "    acc_chans = imu_data.IMU_data # imu dample data\n",
    "    # raw gyro values\n",
    "    gx = np.array(acc_chans.sel(channel='gyro_x_raw'))\n",
    "    gy = np.array(acc_chans.sel(channel='gyro_y_raw'))\n",
    "    gz = np.array(acc_chans.sel(channel='gyro_z_raw'))\n",
    "    # gyro values in degrees\n",
    "    gx_deg = np.array(acc_chans.sel(channel='gyro_x'))\n",
    "    gy_deg = np.array(acc_chans.sel(channel='gyro_y'))\n",
    "    gz_deg = np.array(acc_chans.sel(channel='gyro_z'))\n",
    "    # pitch and roll in deg\n",
    "    groll = np.array(acc_chans.sel(channel='roll'))\n",
    "    gpitch = np.array(acc_chans.sel(channel='pitch'))\n",
    "\n",
    "print('opening ephys data')\n",
    "# ephys data for this individual recording\n",
    "ephys_data = pd.read_json(file_dict['ephys'])\n",
    "# sort units by shank and site order\n",
    "ephys_data = ephys_data.sort_values(by='ch', axis=0, ascending=True)\n",
    "ephys_data = ephys_data.reset_index()\n",
    "ephys_data = ephys_data.drop('index', axis=1)\n",
    "# spike times\n",
    "ephys_data['spikeTraw'] = ephys_data['spikeT']\n",
    "print('getting good cells')\n",
    "# select good cells from phy2\n",
    "goodcells = ephys_data.loc[ephys_data['group']=='good']\n",
    "units = goodcells.index.values\n",
    "# get number of good units\n",
    "n_units = len(goodcells)\n",
    "\n",
    "print('opening eyecam data')\n",
    "# load eye data\n",
    "eye_data = xr.open_dataset(file_dict['eye'])\n",
    "eye_vid = np.uint8(eye_data['REYE_video'])\n",
    "eyeT = eye_data.timestamps.copy()\n",
    "\n",
    "# plot eye postion across recording\n",
    "eye_params = eye_data['REYE_ellipse_params']\n",
    "\n",
    "# define theta, phi and zero-center\n",
    "th = np.array((eye_params.sel(ellipse_params = 'theta')-np.nanmean(eye_params.sel(ellipse_params = 'theta')))*180/3.14159)\n",
    "phi = np.array((eye_params.sel(ellipse_params = 'phi')-np.nanmean(eye_params.sel(ellipse_params = 'phi')))*180/3.14159)\n",
    "\n",
    "print('adjusting camera times to match ephys')\n",
    "# adjust eye/world/top times relative to ephys\n",
    "ephysT0 = ephys_data.iloc[0,12]\n",
    "eyeT = eye_data.timestamps  - ephysT0\n",
    "if eyeT[0]<-600:\n",
    "    eyeT = eyeT + 8*60*60 # 8hr offset for some data\n",
    "worldT = world_data.timestamps - ephysT0\n",
    "if worldT[0]<-600:\n",
    "    worldT = worldT + 8*60*60\n",
    "if free_move is True and has_imu is True:\n",
    "    accT = imu_data.IMU_data.sample - ephysT0\n",
    "if free_move is False and has_mouse is True:\n",
    "    speedT = spd_tstamps - ephysT0\n",
    "if free_move is True:\n",
    "    topT = topT - ephysT0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-institute",
   "metadata": {},
   "source": [
    "# Parallel Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def shift_vid_parallel(x, world_vid,wrap_mode,criteria,dt):\n",
    "    xshift_t = []\n",
    "    yshift_t = []\n",
    "    cc_t = []\n",
    "    for i in range(x,x+dt):\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        try: \n",
    "            (cc, warp_matrix) = cv2.findTransformECC(world_vid[i,:,:], world_vid[i+1,:,:], warp_matrix, warp_mode, criteria, inputMask=None, gaussFiltSize=1)\n",
    "            xshift = warp_matrix[0,2]\n",
    "            yshift = warp_matrix[1,2]\n",
    "        except:\n",
    "            cc = np.nan\n",
    "            xshift=np.nan\n",
    "            yshift = np.nan\n",
    "        xshift_t.append(xshift)\n",
    "        yshift_t.append(yshift)\n",
    "        cc_t.append(cc)\n",
    "    return xshift_t, yshift_t, cc_t\n",
    "\n",
    "@ray.remote\n",
    "def shift_world_pt2(f, dt, world_vid, thInterp, phiInterp, ycorrection, xcorrection):\n",
    "    if (f+dt) < world_vid.shape[0]:\n",
    "        world_vid2 = np.zeros((dt,world_vid.shape[1],world_vid.shape[2]))\n",
    "        for n, x in enumerate(range(f,f+dt)):\n",
    "            world_vid2[n,:,:] = imshift(world_vid[x,:,:],(-np.int8(thInterp[x]*ycorrection[0] + phiInterp[x]*ycorrection[1]),\n",
    "                                                         -np.int8(thInterp[x]*xcorrection[0] + phiInterp[x]*xcorrection[1])))\n",
    "    else: \n",
    "        world_vid2 = np.zeros((world_vid.shape[0]-f,world_vid.shape[1],world_vid.shape[2]))\n",
    "        for n,x in enumerate(range(f,world_vid.shape[0])):\n",
    "            world_vid2[n,:,:] = imshift(world_vid[x,:,:],(-np.int8(thInterp[x]*ycorrection[0] + phiInterp[x]*ycorrection[1]),\n",
    "                                                         -np.int8(thInterp[x]*xcorrection[0] + phiInterp[x]*xcorrection[1])))\n",
    "    return world_vid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "max_frames = 60*60\n",
    "# get eye displacement for each worldcam frame\n",
    "th_interp = interp1d(eyeT, th, bounds_error=False)\n",
    "phi_interp = interp1d(eyeT, phi, bounds_error=False)\n",
    "dth = np.diff(th_interp(worldT))\n",
    "dphi = np.diff(phi_interp(worldT))\n",
    "# calculate x-y shift for each worldcam frame  \n",
    "number_of_iterations = 5000\n",
    "termination_eps = 1e-4\n",
    "criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations, termination_eps)\n",
    "warp_mode = cv2.MOTION_TRANSLATION\n",
    "\n",
    "# Parallel Testing\n",
    "world_vid_r = ray.put(world_vid)\n",
    "warp_mode_r = ray.put(warp_mode)\n",
    "criteria_r = ray.put(criteria)\n",
    "dt = 60\n",
    "result_ids = []\n",
    "[result_ids.append(shift_vid_parallel.remote(i, world_vid_r, warp_mode_r, criteria_r, dt)) for i in range(0, max_frames, dt)]\n",
    "results_p = ray.get(result_ids)\n",
    "results_p = np.array(results_p).transpose(0,2,1).reshape(-1,3)\n",
    "\n",
    "xshift = results_p[:,0]\n",
    "yshift = results_p[:,1]\n",
    "cc = results_p[:,2]\n",
    "\n",
    "xmodel = LinearRegression()\n",
    "ymodel = LinearRegression()\n",
    "\n",
    "# eye data as predictors\n",
    "eyeData = np.zeros((max_frames,2))\n",
    "eyeData[:,0] = dth[0:max_frames]\n",
    "eyeData[:,1] = dphi[0:max_frames]\n",
    "# shift in x and y as outputs\n",
    "xshiftdata = xshift[0:max_frames]\n",
    "yshiftdata = yshift[0:max_frames]\n",
    "# only use good data\n",
    "# not nans, good correlation between frames, small eye movements (no sacccades, only compensatory movements)\n",
    "usedata = ~np.isnan(eyeData[:,0]) & ~np.isnan(eyeData[:,1]) & (cc>0.95)  & (np.abs(eyeData[:,0])<2) & (np.abs(eyeData[:,1])<2) & (np.abs(xshiftdata)<5) & (np.abs(yshiftdata)<5)\n",
    "\n",
    "# fit xshift\n",
    "xmodel.fit(eyeData[usedata,:],xshiftdata[usedata])\n",
    "xmap = xmodel.coef_\n",
    "xrscore = xmodel.score(eyeData[usedata,:],xshiftdata[usedata])\n",
    "# fit yshift\n",
    "ymodel.fit(eyeData[usedata,:],yshiftdata[usedata])\n",
    "ymap = ymodel.coef_\n",
    "yrscore = ymodel.score(eyeData[usedata,:],yshiftdata[usedata])\n",
    "par_time = time.time() - start\n",
    "print(\"duration =\", par_time)\n",
    "del results_p, warp_mode_r, criteria_r, result_ids\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnostic plots\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(dth[0:max_frames],xshift[0:max_frames],'.')\n",
    "plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "plt.ylim(-12,12); plt.xlabel('dtheta'); plt.ylabel('xshift')\n",
    "plt.title('xmap = '+str(xmap))\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(dth[0:max_frames],yshift[0:max_frames],'.')\n",
    "plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "plt.ylim(-12,12); plt.xlabel('dtheta'); plt.ylabel('yshift')\n",
    "plt.title('ymap = '+str(ymap))\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(dphi[0:max_frames],xshift[0:max_frames],'.')\n",
    "plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "plt.ylim(-12,12); plt.xlabel('dphi'); plt.ylabel('xshift')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(dphi[0:max_frames],yshift[0:max_frames],'.')\n",
    "plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "plt.ylim(-12,12); plt.xlabel('dphi'); plt.ylabel('yshift')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print('estimating eye-world calibration')\n",
    "# fig, xmap, ymap = eye_shift_estimation(th, phi, eyeT, world_vid,worldT,60*60)\n",
    "xcorrection_r = ray.put(xmap.copy())\n",
    "ycorrection_r = ray.put(ymap.copy())\n",
    "print('shifting worldcam for eyes')\n",
    "# worldT_r = ray.put(world_data.timestamps.copy())\n",
    "\n",
    "thInterp_r = ray.put(th_interp(worldT))\n",
    "phiInterp_r = ray.put(phi_interp(worldT))\n",
    "dt = 1000\n",
    "dt_r = ray.put(dt)\n",
    "\n",
    "# thWorld = ray.put(thInterp(worldT))\n",
    "# phiWorld = ray.put(phiInterp(worldT))\n",
    "\n",
    "result_ids2 = []\n",
    "[result_ids2.append(shift_world_pt2.remote(f, dt, world_vid_r, thInterp_r, phiInterp_r, ycorrection_r, xcorrection_r)) for f in range(0, world_vid.shape[0], dt)] # \n",
    "results = ray.get(result_ids2)\n",
    "world_vid = np.concatenate(results,axis=0).astype(np.uint8)\n",
    "print('saving worldcam video corrected for eye movements')\n",
    "# np.save(file=os.path.join(file_dict['save'], 'corrected_worldcam.npy'), arr=world_vid)\n",
    "par_time = time.time() - start\n",
    "print(\"duration =\", par_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path('~/Research/SensoryMotorPred_Data/data/070921/J553RT/fm1').expanduser()\n",
    "# np.save(file= save_dir / 'corrected_worldcam.npy', arr=world_vid)\n",
    "world_vid = np.load(save_dir / 'corrected_worldcam.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "world_vid = world_vid.astype(float)\n",
    "std_im = np.std(world_vid, axis=0, dtype=float)\n",
    "img_norm = ((world_vid-np.mean(world_vid,axis=0,dtype=float))/std_im).astype(float)\n",
    "std_im[std_im<20] = 0\n",
    "img_norm = (img_norm * (std_im>0)).astype(float)\n",
    "del world_vid\n",
    "gc.collect()\n",
    "print('Done Loading!')\n",
    "print(\"duration =\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of good units\n",
    "n_units = len(goodcells)\n",
    "print('doing GLM receptive field estimate')\n",
    "# simplified setup for GLM\n",
    "# these are general parameters (spike rates, eye position)\n",
    "n_units = len(goodcells)\n",
    "print('get timing')\n",
    "model_dt = 0.025\n",
    "model_t = np.arange(0,np.max(worldT),model_dt)\n",
    "model_nsp = np.zeros((n_units,len(model_t)))\n",
    "\n",
    "# get spikes / rate\n",
    "print('get spikes')\n",
    "bins = np.append(model_t,model_t[-1]+model_dt)\n",
    "for i,ind in enumerate(goodcells.index):\n",
    "    model_nsp[i,:],bins = np.histogram(goodcells.at[ind,'spikeT'],bins)\n",
    "\n",
    "# get eye position\n",
    "print('get eye')\n",
    "model_th = th_interp(model_t+model_dt/2)\n",
    "model_phi = phi_interp(model_t+model_dt/2)\n",
    "# del thInterp, phiInterp\n",
    "\n",
    "# get active times\n",
    "if free_move:\n",
    "    interp = interp1d(accT,(gz-np.mean(gz))*7.5,bounds_error=False)\n",
    "    model_gz = interp(model_t)\n",
    "    model_active = np.convolve(np.abs(model_gz),np.ones(int(1/model_dt)),'same')\n",
    "    use = np.where((np.abs(model_th)<10) & (np.abs(model_phi)<10)& (model_active>40))[0]\n",
    "    roll_interp = interp1d(accT,groll,bounds_error=False)\n",
    "    pitch_interp = interp1d(accT,gpitch,bounds_error=False)\n",
    "    model_roll = roll_interp(model_t)\n",
    "    model_pitch = pitch_interp(model_t)\n",
    "else:\n",
    "    use = np.where((np.abs(model_th)<10) & (np.abs(model_phi)<10))[0]\n",
    "# get video ready for GLM\n",
    "downsamp = 0.25\n",
    "print('setting up video') \n",
    "movInterp = interp1d(worldT,img_norm,'nearest',axis = 0,bounds_error = False) \n",
    "testimg = movInterp(model_t[0])\n",
    "testimg = cv2.resize(testimg,(int(np.shape(testimg)[1]*downsamp), int(np.shape(testimg)[0]*downsamp)))\n",
    "testimg = testimg[5:-5,5:-5]; #remove area affected by eye movement correction\n",
    "model_vid_sm = np.zeros((len(model_t),int(np.shape(testimg)[0]),int(np.shape(testimg)[1])),dtype=float)\n",
    "for i in tqdm(range(len(model_t))):\n",
    "    model_vid = movInterp(model_t[i] + model_dt/2)\n",
    "    smallvid = cv2.resize(model_vid,(int(np.shape(img_norm)[2]*downsamp),int(np.shape(img_norm)[1]*downsamp)),interpolation = cv2.INTER_AREA)\n",
    "    smallvid = smallvid[5:-5,5:-5]\n",
    "    #smallvid = smallvid - np.mean(smallvid)\n",
    "    model_vid_sm[i,:] = smallvid\n",
    "nks = np.shape(smallvid); nk = nks[0]*nks[1]\n",
    "model_vid_sm[np.isnan(model_vid_sm)]=0\n",
    "del movInterp\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vid_sm.shape, model_nsp.shape, model_t.shape, model_th.shape, model_phi.shape, model_roll.shape, model_pitch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'model_vid_sm': model_vid_sm,\n",
    "        'model_nsp': model_nsp,\n",
    "        'model_t': model_t,\n",
    "        'model_th': model_th,\n",
    "        'model_phi': model_phi,\n",
    "        'model_roll': model_roll,\n",
    "        'model_pitch': model_pitch,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioh5.save(save_dir / 'ModelData.h5', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-ottawa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "connected-taiwan",
   "metadata": {},
   "source": [
    "# Sequential Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def shift_vid(i, world_vid,wrap_mode,criteria):\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "    try: \n",
    "        (cc, warp_matrix) = cv2.findTransformECC(world_vid[i,:,:], world_vid[i+1,:,:], warp_matrix, warp_mode, criteria, inputMask=None, gaussFiltSize=1)\n",
    "        xshift = warp_matrix[0,2]\n",
    "        yshift = warp_matrix[1,2]\n",
    "    except:\n",
    "        cc = np.nan\n",
    "        xshift=np.nan\n",
    "        yshift = np.nan\n",
    "    return xshift, yshift, cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_glm_vid(model_vid, model_nsp, model_dt, use, nks):\n",
    "    \"\"\"\n",
    "    calculate GLM spatial receptive field\n",
    "    INPUTS\n",
    "        model_vid: video as array\n",
    "        model_nsp: binned number of spikes\n",
    "        model_dt: dt\n",
    "        use: frames when animal is active\n",
    "        nks: dimensions of video\n",
    "    OUTPUTS\n",
    "        sta_all: receptive fields for each unit\n",
    "        cc_all: cross correlation for each unit\n",
    "        fig: figure\n",
    "    \"\"\"\n",
    "    nT = np.shape(model_nsp)[1]\n",
    "    x = model_vid.copy()\n",
    "    # image dimensions\n",
    "    nk  = nks[0] * nks[1]\n",
    "    n_units = np.shape(model_nsp)[0]\n",
    "    # subtract mean and renormalize -- necessary? \n",
    "    mn_img = np.mean(x[use,:],axis=0)\n",
    "    x = x-mn_img\n",
    "    x = x/np.std(x[use,:],axis =0)\n",
    "    x = np.append(x,np.ones((nT,1)), axis = 1) # append column of ones\n",
    "    x = x[use,:]\n",
    "    # set up prior matrix (regularizer)\n",
    "    # L2 prior\n",
    "    Imat = np.eye(nk)\n",
    "    Imat = linalg.block_diag(Imat,np.zeros((1,1)))\n",
    "    # smoothness prior\n",
    "    consecutive = np.ones((nk, 1))\n",
    "    consecutive[nks[1]-1::nks[1]] = 0\n",
    "    diff = np.zeros((1,2))\n",
    "    diff[0,0] = -1\n",
    "    diff[0,1]= 1\n",
    "    Dxx = sparse.diags((consecutive @ diff).T, np.array([0, 1]), (nk-1,nk))\n",
    "    Dxy = sparse.diags((np.ones((nk,1))@ diff).T, np.array([0, nks[1]]), (nk-nks[1], nk))\n",
    "    Dx = Dxx.T @ Dxx + Dxy.T @ Dxy\n",
    "    D  = linalg.block_diag(Dx.toarray(),np.zeros((1,1)))      \n",
    "    # summed prior matrix\n",
    "    Cinv = D + Imat\n",
    "    lag_list = [ -4, -2, 0 , 2, 4]\n",
    "    lambdas = 1024 * (2**np.arange(0,16))\n",
    "    nlam = len(lambdas)\n",
    "    # set up empty arrays for receptive field and cross correlation\n",
    "    sta_all = np.zeros((n_units, len(lag_list), nks[0], nks[1]))\n",
    "    cc_all = np.zeros((n_units,len(lag_list)))\n",
    "    # iterate through units\n",
    "    for celln in tqdm(range(n_units)):\n",
    "        # iterate through timing lags\n",
    "        for lag_ind, lag in enumerate(lag_list):\n",
    "            sps = np.roll(model_nsp[celln,:],-lag)\n",
    "            sps = sps[use]\n",
    "            nT = len(sps)\n",
    "            #split training and test data\n",
    "            test_frac = 0.3\n",
    "            ntest = int(nT*test_frac)\n",
    "            x_train = x[ntest:,:] ; sps_train = sps[ntest:]\n",
    "            x_test = x[:ntest,:]; sps_test = sps[:ntest]\n",
    "            #calculate a few terms\n",
    "            sta = x_train.T@sps_train/np.sum(sps_train)\n",
    "            XXtr = x_train.T @ x_train\n",
    "            XYtr = x_train.T @sps_train\n",
    "            msetrain = np.zeros((nlam,1))\n",
    "            msetest = np.zeros((nlam,1))\n",
    "            w_ridge = np.zeros((nk+1,nlam))\n",
    "            # initial guess\n",
    "            w = sta\n",
    "            # loop over regularization strength\n",
    "            for l in range(len(lambdas)):  \n",
    "                # calculate MAP estimate               \n",
    "                w = np.linalg.solve(XXtr + lambdas[l]*Cinv, XYtr) # equivalent of \\ (left divide) in matlab\n",
    "                w_ridge[:,l] = w\n",
    "                # calculate test and training rms error\n",
    "                msetrain[l] = np.mean((sps_train - x_train@w)**2)\n",
    "                msetest[l] = np.mean((sps_test - x_test@w)**2)\n",
    "            # select best cross-validated lambda for RF\n",
    "            best_lambda = np.argmin(msetest)\n",
    "            w = w_ridge[:,best_lambda]\n",
    "            ridge_rf = w_ridge[:,best_lambda]\n",
    "            sta_all[celln,lag_ind,:,:] = np.reshape(w[:-1],nks)\n",
    "            # plot predicted vs actual firing rate\n",
    "            # predicted firing rate\n",
    "            sp_pred = x_test@ridge_rf\n",
    "            # bin the firing rate to get smooth rate vs time\n",
    "            bin_length = 80\n",
    "            sp_smooth = (np.convolve(sps_test, np.ones(bin_length), 'same')) / (bin_length * model_dt)\n",
    "            pred_smooth = (np.convolve(sp_pred, np.ones(bin_length), 'same')) / (bin_length * model_dt)\n",
    "            # a few diagnostics\n",
    "            err = np.mean((sp_smooth-pred_smooth)**2)\n",
    "            cc = np.corrcoef(sp_smooth, pred_smooth)\n",
    "            cc_all[celln,lag_ind] = cc[0,1]\n",
    "    # figure of receptive fields\n",
    "    fig = plt.figure(figsize=(10,np.int(np.ceil(n_units/3))),dpi=50)\n",
    "    for celln in tqdm(range(n_units)):\n",
    "        for lag_ind, lag in enumerate(lag_list):\n",
    "            crange = np.max(np.abs(sta_all[celln,:,:,:]))\n",
    "            plt.subplot(n_units,6,(celln*6)+lag_ind + 1)  \n",
    "            plt.imshow(sta_all[celln, lag_ind, :, :], vmin=-crange, vmax=crange, cmap='jet')\n",
    "            plt.title('cc={:.2f}'.format (cc_all[celln,lag_ind]),fontsize=5)\n",
    "    return sta_all, cc_all, fig\n",
    "\n",
    "def eye_shift_estimation(th, phi, eyeT, world_vid, worldT, max_frames=3600):\n",
    "    \"\"\"\n",
    "    do a simple shift of the worldcam using eye parameters\n",
    "    aim is to approximate the visual scene\n",
    "    INPUTS\n",
    "        th: theta as an array\n",
    "        phi: phi as an array\n",
    "        eyeT: eye timestamps\n",
    "        world_vid: worldcam video as an array\n",
    "        worldT: worldcam timestamps\n",
    "        max_frames: number of frames to use in the estimation\n",
    "    OUTPUTS\n",
    "        fig: figure\n",
    "        xmap: worldcam x-correction factor\n",
    "        ymap: worldcam y-correction factor\n",
    "    \"\"\"\n",
    "    # get eye displacement for each worldcam frame\n",
    "    th_interp = interp1d(eyeT, th, bounds_error=False)\n",
    "    phi_interp = interp1d(eyeT, phi, bounds_error=False)\n",
    "    dth = np.diff(th_interp(worldT))\n",
    "    dphi = np.diff(phi_interp(worldT))\n",
    "    # calculate x-y shift for each worldcam frame  \n",
    "    number_of_iterations = 5000\n",
    "    termination_eps = 1e-4\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations, termination_eps)\n",
    "    warp_mode = cv2.MOTION_TRANSLATION\n",
    "    cc = np.zeros(max_frames)\n",
    "    xshift = np.zeros(max_frames)\n",
    "    yshift = np.zeros(max_frames)\n",
    "    warp_all = np.zeros((6,max_frames))\n",
    "    # get shift between adjacent frames\n",
    "    \n",
    "    for i in tqdm(range(max_frames)):\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        try: \n",
    "            (cc[i], warp_matrix) = cv2.findTransformECC(world_vid[i,:,:], world_vid[i+1,:,:], warp_matrix, warp_mode, criteria, inputMask=None, gaussFiltSize=1)\n",
    "            xshift[i] = warp_matrix[0,2]\n",
    "            yshift[i] = warp_matrix[1,2]\n",
    "        except:\n",
    "            cc[i] = np.nan\n",
    "            xshift[i]=np.nan\n",
    "            yshift[i] = np.nan\n",
    "    # perform regression to predict frameshift based on eye shifts\n",
    "    # set up models\n",
    "    xmodel = LinearRegression()\n",
    "    ymodel = LinearRegression()\n",
    "    # eye data as predictors\n",
    "    eyeData = np.zeros((max_frames,2))\n",
    "    eyeData[:,0] = dth[0:max_frames]\n",
    "    eyeData[:,1] = dphi[0:max_frames]\n",
    "    # shift in x and y as outputs\n",
    "    xshiftdata = xshift[0:max_frames]\n",
    "    yshiftdata = yshift[0:max_frames]\n",
    "    # only use good data\n",
    "    # not nans, good correlation between frames, small eye movements (no sacccades, only compensatory movements)\n",
    "    usedata = ~np.isnan(eyeData[:,0]) & ~np.isnan(eyeData[:,1]) & (cc>0.95)  & (np.abs(eyeData[:,0])<2) & (np.abs(eyeData[:,1])<2) & (np.abs(xshiftdata)<5) & (np.abs(yshiftdata)<5)\n",
    "    # fit xshift\n",
    "    xmodel.fit(eyeData[usedata,:],xshiftdata[usedata])\n",
    "    xmap = xmodel.coef_\n",
    "    xrscore = xmodel.score(eyeData[usedata,:],xshiftdata[usedata])\n",
    "    # fit yshift\n",
    "    ymodel.fit(eyeData[usedata,:],yshiftdata[usedata])\n",
    "    ymap = ymodel.coef_\n",
    "    yrscore = ymodel.score(eyeData[usedata,:],yshiftdata[usedata])\n",
    "   # diagnostic plots\n",
    "    fig = plt.figure(figsize = (8,6))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(dth[0:max_frames],xshift[0:max_frames],'.')\n",
    "    plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "    plt.ylim(-12,12); plt.xlabel('dtheta'); plt.ylabel('xshift')\n",
    "    plt.title('xmap = '+str(xmap))\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(dth[0:max_frames],yshift[0:max_frames],'.')\n",
    "    plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "    plt.ylim(-12,12); plt.xlabel('dtheta'); plt.ylabel('yshift')\n",
    "    plt.title('ymap = '+str(ymap))\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(dphi[0:max_frames],xshift[0:max_frames],'.')\n",
    "    plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "    plt.ylim(-12,12); plt.xlabel('dphi'); plt.ylabel('xshift')\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(dphi[0:max_frames],yshift[0:max_frames],'.')\n",
    "    plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "    plt.ylim(-12,12); plt.xlabel('dphi'); plt.ylabel('yshift')\n",
    "    plt.tight_layout()\n",
    "    return fig, xmap, ymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "max_frames = 60*60\n",
    "# get eye displacement for each worldcam frame\n",
    "th_interp = interp1d(eyeT, th, bounds_error=False)\n",
    "phi_interp = interp1d(eyeT, phi, bounds_error=False)\n",
    "dth = np.diff(th_interp(worldT))\n",
    "dphi = np.diff(phi_interp(worldT))\n",
    "# calculate x-y shift for each worldcam frame  \n",
    "number_of_iterations = 5000\n",
    "termination_eps = 1e-4\n",
    "criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations, termination_eps)\n",
    "warp_mode = cv2.MOTION_TRANSLATION\n",
    "cc = np.zeros(max_frames)\n",
    "xshift = np.zeros(max_frames)\n",
    "yshift = np.zeros(max_frames)\n",
    "warp_all = np.zeros((6,max_frames))\n",
    "# get shift between adjacent frames\n",
    "\n",
    "for i in tqdm(range(max_frames)):\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "    try: \n",
    "        (cc[i], warp_matrix) = cv2.findTransformECC(world_vid[i,:,:], world_vid[i+1,:,:], warp_matrix, warp_mode, criteria, inputMask=None, gaussFiltSize=1)\n",
    "        xshift[i] = warp_matrix[0,2]\n",
    "        yshift[i] = warp_matrix[1,2]\n",
    "    except:\n",
    "        cc[i] = np.nan\n",
    "        xshift[i]=np.nan\n",
    "        yshift[i] = np.nan\n",
    "        \n",
    "\n",
    "# perform regression to predict frameshift based on eye shifts\n",
    "# set up models\n",
    "xmodel = LinearRegression()\n",
    "ymodel = LinearRegression()\n",
    "# eye data as predictors\n",
    "eyeData = np.zeros((max_frames,2))\n",
    "eyeData[:,0] = dth[0:max_frames]\n",
    "eyeData[:,1] = dphi[0:max_frames]\n",
    "# shift in x and y as outputs\n",
    "xshiftdata = xshift[0:max_frames]\n",
    "yshiftdata = yshift[0:max_frames]\n",
    "# only use good data\n",
    "# not nans, good correlation between frames, small eye movements (no sacccades, only compensatory movements)\n",
    "usedata = ~np.isnan(eyeData[:,0]) & ~np.isnan(eyeData[:,1]) & (cc>0.95)  & (np.abs(eyeData[:,0])<2) & (np.abs(eyeData[:,1])<2) & (np.abs(xshiftdata)<5) & (np.abs(yshiftdata)<5)\n",
    "# fit xshift\n",
    "xmodel.fit(eyeData[usedata,:],xshiftdata[usedata])\n",
    "xmap = xmodel.coef_\n",
    "xrscore = xmodel.score(eyeData[usedata,:],xshiftdata[usedata])\n",
    "# fit yshift\n",
    "ymodel.fit(eyeData[usedata,:],yshiftdata[usedata])\n",
    "ymap = ymodel.coef_\n",
    "yrscore = ymodel.score(eyeData[usedata,:],yshiftdata[usedata])\n",
    "seq_time = time.time() - start\n",
    "print(\"duration =\", seq_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "xshiftdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeData[usedata,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnostic plots\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(dth[0:max_frames],xshift[0:max_frames],'.')\n",
    "plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "plt.ylim(-12,12); plt.xlabel('dtheta'); plt.ylabel('xshift')\n",
    "plt.title('xmap = '+str(xmap))\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(dth[0:max_frames],yshift[0:max_frames],'.')\n",
    "plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "plt.ylim(-12,12); plt.xlabel('dtheta'); plt.ylabel('yshift')\n",
    "plt.title('ymap = '+str(ymap))\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(dphi[0:max_frames],xshift[0:max_frames],'.')\n",
    "plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "plt.ylim(-12,12); plt.xlabel('dphi'); plt.ylabel('xshift')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(dphi[0:max_frames],yshift[0:max_frames],'.')\n",
    "plt.plot([-5, 5], [5, -5],'r'); plt.xlim(-12,12)\n",
    "plt.ylim(-12,12); plt.xlabel('dphi'); plt.ylabel('yshift')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "print('estimating eye-world calibration')\n",
    "# fig, xmap, ymap = eye_shift_estimation(th, phi, eyeT, world_vid,worldT,60*60)\n",
    "xcorrection = xmap.copy()\n",
    "ycorrection = ymap.copy()\n",
    "print('shifting worldcam for eyes')\n",
    "thInterp =interp1d(eyeT,th, bounds_error = False)\n",
    "phiInterp =interp1d(eyeT,phi, bounds_error = False)\n",
    "thWorld = thInterp(worldT)\n",
    "phiWorld = phiInterp(worldT)\n",
    "for f in tqdm(range(3000)):#np.shape(world_vid)[0])):\n",
    "    world_vid[f,:,:] = imshift(world_vid[f,:,:],(-np.int8(thInterp(worldT[f])*ycorrection[0] + phiInterp(worldT[f])*ycorrection[1]),\n",
    "                                                 -np.int8(thInterp(worldT[f])*xcorrection[0] + phiInterp(worldT[f])*xcorrection[1])))\n",
    "    \n",
    "seq_time = time.time() - start\n",
    "print(\"duration =\", seq_time)\n",
    "print('saving worldcam video corrected for eye movements')\n",
    "# np.save(file=os.path.join(file_dict['save'], 'corrected_worldcam.npy'), arr=world_vid)\n",
    "# std_im = np.std(world_vid,axis=0)\n",
    "# img_norm = (world_vid-np.mean(world_vid,axis=0))/std_im\n",
    "# std_im[std_im<20] = 0\n",
    "# img_norm = img_norm * (std_im>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-pitch",
   "metadata": {},
   "source": [
    "# Loading Other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath = check_path(Path('~/Research/SensoryMotorPred_Data').expanduser(),'data/070921/J553RT/fm1')\n",
    "DataFile = list(DataPath.glob('*.h5'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(DataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fm1_dEye'][7].shape, df['spikeT'][7].shape, df['fm1_pitch_interp'][7].shape, df['fm1_theta'][7].shape, df['rate'][7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "ex_n = df['spikeT'].iloc[n]\n",
    "ex_n_rate = df['rate'].iloc[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 100\n",
    "dt = 1000\n",
    "norm_roll = df['fm1_roll_interp'].iloc[n][t:t+dt]/np.max(np.abs(df['fm1_roll_interp'].iloc[n][t:t+dt]))\n",
    "norm_roll = norm_roll-norm_roll[0]\n",
    "norm_rate = ex_n_rate[t:t+dt]/np.max(ex_n_rate[t:t+dt])\n",
    "plt.plot(norm_rate)\n",
    "plt.plot(norm_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(norm_roll,norm_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
