{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "limiting-proposal",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "import sys \n",
    "import yaml \n",
    "import glob\n",
    "import h5py \n",
    "import ray\n",
    "import logging \n",
    "import json\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "# import io_dict_to_hdf5 as ioh5\n",
    "import xarray as xr\n",
    "import scipy.linalg as linalg\n",
    "import scipy.sparse as sparse\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import shift as imshift\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model as lm \n",
    "from scipy.stats import binned_statistic\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import r2_score, mean_poisson_deviance\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from scipy.ndimage import uniform_filter1d \n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sys.path.append(str(Path('.').absolute().parent))\n",
    "from utils import *\n",
    "import io_dict_to_hdf5 as ioh5\n",
    "from format_data import load_ephys_data_aligned\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "FigPath = check_path(Path('~/Research/SensoryMotorPred_Data').expanduser(),'Figures/Decoding')\n",
    "\n",
    "ray.init(\n",
    "    ignore_reinit_error=True,\n",
    "    logging_level=logging.ERROR,\n",
    ")\n",
    "# print(f'Dashboard URL: http://{ray.get_dashboard_url()}')\n",
    "# print('Dashboard URL: http://localhost:{}'.format(ray.get_dashboard_url().split(':')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-cyprus",
   "metadata": {},
   "source": [
    "Decode out spatial patches from neural activity. \n",
    "\n",
    "nonlinear combining of visual and movement gives more predictive power then linear combining. \n",
    "\n",
    "frames and movement at time t predict visual info at t+1 with linear comb and nonlinear comb. combining in nonlin way would work better. \n",
    "\n",
    "how to make linear or nonlinear combinations of inputs? input is pixel intensities, and movment params output pixel intesities at t+1. \n",
    "\n",
    "mult case: random projection at same dimentionality. Pixels * movement. \n",
    "\n",
    "h0 just visual predicts only visual. movement \"adds\" something here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-watch",
   "metadata": {},
   "source": [
    "# Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test(file_dict, save_dir, model_dt=.1, frac=.1, train_size=.7, do_shuffle=False, do_norm=False, free_move=True, has_imu=True, has_mouse=False,):\n",
    "    ##### Load in preprocessed data #####\n",
    "    data = load_ephys_data_aligned(file_dict, save_dir, model_dt=model_dt, free_move=free_move, has_imu=has_imu, has_mouse=has_mouse,)\n",
    "    if free_move:\n",
    "        ##### Find 'good' timepoints when mouse is active #####\n",
    "        nan_idxs = []\n",
    "        for key in data.keys():\n",
    "            nan_idxs.append(np.where(np.isnan(data[key]))[0])\n",
    "        good_idxs = np.ones(len(data['model_active']),dtype=bool)\n",
    "        good_idxs[data['model_active']<.5] = False\n",
    "        good_idxs[np.unique(np.hstack(nan_idxs))] = False\n",
    "    else:\n",
    "        good_idxs = np.where((np.abs(data['model_th'])<10) & (np.abs(data['model_phi'])<10))[0]\n",
    "    \n",
    "    data['raw_nsp'] = data['model_nsp'].copy()\n",
    "    ##### return only active data #####\n",
    "    for key in data.keys():\n",
    "        if (key != 'model_nsp') & (key != 'model_active') & (key != 'unit_nums'):\n",
    "            data[key] = data[key][good_idxs] # interp_nans(data[key]).astype(float)\n",
    "        elif (key == 'model_nsp'):\n",
    "            data[key] = data[key][good_idxs]\n",
    "        elif (key == 'unit_nums'):\n",
    "            pass\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=train_size, random_state=42)\n",
    "    nT = data['model_nsp'].shape[0]\n",
    "    groups = np.hstack([i*np.ones(int((frac*i)*nT) - int((frac*(i-1))*nT)) for i in range(1,int(1/frac)+1)])\n",
    "\n",
    "    for train_idx, test_idx in gss.split(np.arange(len(data['model_nsp'])), groups=groups):\n",
    "        print(\"TRAIN:\", len(train_idx), \"TEST:\", len(test_idx))\n",
    "\n",
    "\n",
    "    data['model_dth'] = np.diff(data['model_th'],append=0)\n",
    "    data['model_dphi'] = np.diff(data['model_phi'],append=0)\n",
    "\n",
    "    data['model_vid_sm'] = (data['model_vid_sm'] - np.mean(data['model_vid_sm'],axis=0))/np.nanstd(data['model_vid_sm'],axis=0)\n",
    "    data['model_vid_sm'][np.isnan(data['model_vid_sm'])]=0\n",
    "    if do_norm:\n",
    "#         data['model_vid_sm'] = (data['model_vid_sm'])/np.max(data['model_vid_sm'],axis=(-1,-2))[:,np.newaxis,np.newaxis]\n",
    "        data['model_th'] = (data['model_th'] - np.mean(data['model_th'],axis=0))/np.std(data['model_th'],axis=0) \n",
    "        data['model_phi'] = (data['model_phi'] - np.mean(data['model_phi'],axis=0))/np.std(data['model_phi'],axis=0) \n",
    "        if free_move:\n",
    "            data['model_roll'] = (data['model_roll'] - np.mean(data['model_roll'],axis=0))/np.std(data['model_roll'],axis=0) \n",
    "            data['model_pitch'] = (data['model_pitch'] - np.mean(data['model_pitch'],axis=0))/np.std(data['model_pitch'],axis=0) \n",
    "\n",
    "    ##### Split Data by train/test #####\n",
    "    data_train_test = {\n",
    "        'train_vid': data['model_vid_sm'][train_idx],\n",
    "        'test_vid': data['model_vid_sm'][test_idx],\n",
    "        'train_nsp': shuffle(data['model_nsp'][train_idx],random_state=42) if do_shuffle else data['model_nsp'][train_idx],\n",
    "        'test_nsp': shuffle(data['model_nsp'][test_idx],random_state=42) if do_shuffle else data['model_nsp'][test_idx],\n",
    "        'train_th': data['model_th'][train_idx],\n",
    "        'test_th': data['model_th'][test_idx],\n",
    "        'train_phi': data['model_phi'][train_idx],\n",
    "        'test_phi': data['model_phi'][test_idx],\n",
    "        'train_roll': data['model_roll'][train_idx] if free_move else [],\n",
    "        'test_roll': data['model_roll'][test_idx] if free_move else [],\n",
    "        'train_pitch': data['model_pitch'][train_idx] if free_move else [],\n",
    "        'test_pitch': data['model_pitch'][test_idx] if free_move else [],\n",
    "        'train_t': data['model_t'][train_idx],\n",
    "        'test_t': data['model_t'][test_idx],\n",
    "        'train_dth': data['model_dth'][train_idx],\n",
    "        'test_dth': data['model_dth'][test_idx],\n",
    "        'train_dphi': data['model_dphi'][train_idx],\n",
    "        'test_dphi': data['model_dphi'][test_idx],\n",
    "        'train_gz': data['model_gz'][train_idx] if free_move else [],\n",
    "        'test_gz': data['model_gz'][test_idx] if free_move else [],\n",
    "    }\n",
    "\n",
    "    d1 = data\n",
    "    d1.update(data_train_test)\n",
    "    return d1,train_idx,test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_move = True\n",
    "if free_move:\n",
    "    stim_type = 'fm1'\n",
    "else:\n",
    "    stim_type = 'hf1_wn' # 'fm1' # \n",
    "\n",
    "data_dir  = Path('~/Goeppert/freely_moving_ephys/ephys_recordings/070921/J553RT').expanduser() / stim_type\n",
    "save_dir  = check_path(Path('~/Research/SensoryMotorPred_Data/data/070921/J553RT/').expanduser(), stim_type)\n",
    "FigPath = check_path(FigPath, stim_type)\n",
    "save_dir,data_dir,FigPath\n",
    "# with open(save_dir / 'file_dict.json','r') as fp:\n",
    "#     file_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {'cell': 0,\n",
    " 'drop_slow_frames': True,\n",
    " 'ephys': list(data_dir.glob('*ephys_merge.json'))[0].as_posix(),\n",
    " 'ephys_bin': list(data_dir.glob('*Ephys.bin'))[0].as_posix(),\n",
    " 'eye': list(data_dir.glob('*REYE.nc'))[0].as_posix(),\n",
    " 'imu': list(data_dir.glob('*imu.nc'))[0].as_posix() if stim_type=='fm1' else None,\n",
    " 'mapping_json': '/home/seuss/Research/Github/FreelyMovingEphys/probes/channel_maps.json',\n",
    " 'mp4': True,\n",
    " 'name': '070921_J553RT_control_Rig2_'+stim_type,\n",
    " 'probe_name': 'DB_P128-6',\n",
    " 'save': data_dir.as_posix(),\n",
    " 'speed': None,\n",
    " 'stim_type': 'light',\n",
    " 'top': list(data_dir.glob('*TOP1.nc'))[0].as_posix() if stim_type=='fm1' else None,\n",
    " 'world': list(data_dir.glob('*world.nc'))[0].as_posix(),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = .05\n",
    "data,train_idx,test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=False, do_norm=True,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "locals().update(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-token",
   "metadata": {},
   "source": [
    "# Testing Tuning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tuning curve for theta\n",
    "def tuning_curve(model_nsp, var, model_dt = .05, N_bins=10, Nstds=3):\n",
    "    var_range = np.linspace(np.nanmean(var)-Nstds*np.nanstd(var), np.nanmean(var)+Nstds*np.nanstd(var),N_bins)\n",
    "    tuning = np.zeros((model_nsp.shape[-1],len(var_range)-1))\n",
    "    tuning_std = np.zeros((model_nsp.shape[-1],len(var_range)-1))\n",
    "    for n in range(model_nsp.shape[-1]):\n",
    "        for j in range(len(var_range)-1):\n",
    "            usePts = (var>=var_range[j]) & (var<var_range[j+1])\n",
    "            tuning[n,j] = np.nanmean(model_nsp[usePts,n])/model_dt\n",
    "            tuning_std[n,j] = (np.nanstd(model_nsp[usePts,n])/model_dt)/ np.sqrt(np.count_nonzero(usePts))\n",
    "    return tuning, tuning_std, var_range[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning, tuning_std, var_range = tuning_curve(test_nsp, test_th, N_bins=10, model_dt=model_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 21\n",
    "fig, axs = plt.subplots(1,figsize=(7,5))\n",
    "axs.errorbar(var_range,tuning[n], yerr=tuning_std[n])\n",
    "axs.set_ylim(bottom=0)\n",
    "axs.set_xlabel('Eye Phi')\n",
    "axs.set_ylabel('Spikes/s')\n",
    "axs.set_title('Neuron: {}'.format(n))\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'ExampleTuningCurve.png',bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-means",
   "metadata": {},
   "source": [
    "# Decoding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def do_glm_fit_vis_skl(train_nsp, test_nsp, y_train, y_test, celln, model_type, lag_list, bin_length=40, model_dt=.1):\n",
    "    \n",
    "    ##### Format data #####\n",
    "    nt_glm_lag = len(lag_list)\n",
    "    \n",
    "    # Shift spikes by -lag for GLM fits\n",
    "    sps_train = train_nsp[:,celln] # np.roll(train_nsp[:,celln],-lag)\n",
    "    sps_test = test_nsp[:,celln] # np.roll(test_nsp[:,celln],-lag)\n",
    "\n",
    "    if model_type == 'elasticnetcv':\n",
    "        model = lm.ElasticNetCV(l1_ratio=[.05, .01, .5, .7]) # lm.RidgeCV(alphas=np.arange(100,10000,1000))) #  #MultiOutputRegressor(lm.Ridge(),n_jobs=-1)) \n",
    "        model.fit(sps_train,y_train)\n",
    "        sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "        sp_pred = model.predict(y_test)\n",
    "    elif model_type == 'ridgecv':\n",
    "        lambdas = 1024 * (2**np.arange(0,16))\n",
    "        model = lm.RidgeCV(alphas=lambdas)\n",
    "        model.fit(sps_train,y_train)\n",
    "        sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "        sp_pred = model.predict(y_test)\n",
    "    return cc_all, sta_all, sps_test, sp_pred, r2_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag=150 # in ms\n",
    "nt_glm_lag = 5\n",
    "# minlag = int(-lag//(1000*model_dt)); maxlag=int((lag//(1000*model_dt))+1)\n",
    "lag_list = np.array([0]) #,np.arange(minlag,maxlag,np.floor((maxlag-minlag)/nt_glm_lag).astype(int))\n",
    "nt_glm_lag = len(lag_list)\n",
    "print(lag_list,1000*lag_list*model_dt)\n",
    "do_shuffle=False\n",
    "model_type = 'ridgecv'\n",
    "\n",
    "nks = np.shape(train_vid)[1:]; nk = nks[0]*nks[1]*nt_glm_lag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-station",
   "metadata": {},
   "source": [
    "Gabor patches to construct image. C1*GP1 + c2*gp2 ..., for each gabor patch. decomose each image as a combination of gabor patches.\n",
    "\n",
    "I = sum(cj*phi_j) minimize for regression. Phi = gabor, pcs etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# winds_train = sliding_window_view(train_vid,(windn,windn),axis=(1,2))[:,::skipn,::skipn]\n",
    "# winds_train = winds_train.reshape(winds_train.shape[0],-1,winds_train.shape[-2],winds_train.shape[-1])\n",
    "# winds_test = sliding_window_view(test_vid,(windn,windn),axis=(1,2))[:,::skipn,::skipn]\n",
    "# winds_test = winds_test.reshape(winds_test.shape[0],-1,winds_test.shape[-2],winds_test.shape[-1])\n",
    "\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "model = lm.RidgeCV(alphas=lambdas)\n",
    "# model = lm.MultiTaskElasticNetCV(l1_ratio=[.05, .01, .5, .7]) # lm.RidgeCV(alphas=np.arange(100,10000,1000))) #  #MultiOutputRegressor(lm.Ridge(),n_jobs=-1)) \n",
    "model.fit(train_nsp,train_vid.reshape(train_vid.shape[0],-1))\n",
    "sta_all = np.reshape(model.coef_,(train_nsp.shape[-1],nt_glm_lag,)+nks)\n",
    "sp_pred = model.predict(test_nsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_glm_lag = 1\n",
    "nks = np.shape(train_vid)[1:]; nk = nks[0]*nks[1]*nt_glm_lag\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "ncv = 5\n",
    "model = lm.RidgeCV(alphas=lambdas)\n",
    "msetest = np.zeros((test_nsp.shape[-1],ncv))\n",
    "for ncells in tqdm(np.arange(test_nsp.shape[-1],0,-1)):\n",
    "    for cvind in np.arange(0,ncv):\n",
    "        inds = sorted(np.random.choice(np.arange(0,test_nsp.shape[-1]),ncells))\n",
    "        # model = lm.MultiTaskElasticNetCV(cv=2,l1_ratio=[.01,.05,.5],verbose=True,selection='random',n_jobs=-1) # lm.RidgeCV(alphas=np.arange(100,10000,1000))) #  #MultiOutputRegressor(lm.Ridge(),n_jobs=-1)) \n",
    "        model.fit(train_nsp[:,inds],train_vid.reshape(train_vid.shape[0],-1))\n",
    "        # sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "        pred_test = model.predict(test_nsp[:,inds]).reshape(-1,nks[0],nks[1])\n",
    "        # test_vid = sp_pred.reshape(sp_pred.shape[0],nks[0],nks[1])\n",
    "\n",
    "        msetest[ncells-1,cvind] = mean_squared_error(test_vid.reshape(test_vid.shape[0],-1),model.predict(test_nsp[:,inds]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.reshape(test_vid.shape[0],-1).shape,test_vid.reshape(test_vid.shape[0],-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(pred_test.reshape(test_vid.shape[0],-1).T,test_vid.reshape(test_vid.shape[0],-1).T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(np.roll(test_vid.reshape(test_vid.shape[0],-1),1,axis=0).T,test_vid.reshape(test_vid.shape[0],-1).T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(msetest.mean(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 2\n",
    "pred_test_norm = normimgs(pred_test)\n",
    "pred_test_up = np.zeros((pred_test.shape[0],sf*pred_test.shape[1],sf*pred_test.shape[2]))\n",
    "test_vid_norm = normimgs(test_vid)\n",
    "test_vid_up = np.zeros((test_vid.shape[0],sf*test_vid.shape[1],sf*test_vid.shape[2]))\n",
    "pred_train_norm = normimgs(pred_train)\n",
    "pred_train_up = np.zeros((pred_train.shape[0],sf*pred_train.shape[1],sf*pred_train.shape[2]))\n",
    "train_vid_norm = normimgs(train_vid)\n",
    "train_vid_up = np.zeros((train_vid.shape[0],sf*train_vid.shape[1],sf*train_vid.shape[2]))\n",
    "for n in range(pred_test.shape[0]):\n",
    "    pred_test_up[n] = cv2.resize(pred_test_norm[n],(sf*pred_test.shape[2],sf*pred_test.shape[1]))\n",
    "    test_vid_up[n] = cv2.resize(test_vid_norm[n],(sf*test_vid.shape[2],sf*test_vid.shape[1]))\n",
    "    pred_train_up[n] = cv2.resize(pred_train_norm[n],(sf*pred_train.shape[2],sf*pred_train.shape[1]))\n",
    "    train_vid_up[n] = cv2.resize(train_vid_norm[n],(sf*train_vid.shape[2],sf*train_vid.shape[1]))\n",
    "\n",
    "cond = 'test'\n",
    "if cond == 'train':\n",
    "    tot_samps = np.stack((pred_train_up, train_vid_up))\n",
    "else:\n",
    "    tot_samps = np.stack((pred_test_up, test_vid_up))\n",
    "tot_samps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "FigPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 2990#2000\n",
    "dt = 5\n",
    "fig, ax = plt.subplots(2,dt,figsize=(10,5))\n",
    "\n",
    "for n,t in enumerate(np.arange(t,t+dt)):\n",
    "    ax[0,n].imshow(pred_test_up[t,:,:], cmap='gray')\n",
    "    ax[0,n].axis('off')\n",
    "# plt.suptitle('Decoding Frames')\n",
    "# plt.tight_layout()\n",
    "# fig.savefig(FigPath/'Decoding_Frame.png',facecolor='white', transparent=True)\n",
    "\n",
    "# fig2, ax2 = plt.subplots(1,10,figsize=(30,3))\n",
    "for n,t in enumerate(np.arange(t,t+dt)):\n",
    "    ax[1,n].imshow(test_vid_up[t,:,:], cmap='gray')\n",
    "    ax[1,n].axis('off')\n",
    "# plt.suptitle('Actual Frames')\n",
    "plt.tight_layout()\n",
    "fig.savefig(FigPath/'Decoding_Frames2.pdf',facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 2800#2000\n",
    "dt = 200\n",
    "im_grid = torchvision.utils.make_grid(torch.from_numpy(pred_test[t:t+dt,np.newaxis,:,:]),nrow=10,normalize=False)[0]\n",
    "im_grid2 = torchvision.utils.make_grid(torch.from_numpy(test_vid[t:t+dt,np.newaxis,:,:]),nrow=10,normalize=False)[0]\n",
    "fig, axs = plt.subplots(1,2,figsize=(20,20))\n",
    "axs[0].imshow(im_grid, cmap='gray')#.permute(1,2,0))\n",
    "axs[0].set_title('Decoding Prediction')\n",
    "axs[1].imshow(im_grid2, cmap='gray')#.permute(1,2,0))\n",
    "axs[1].set_title('Actual Frame')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'DecodedMontage_{}.png'.format(model_type),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coeff = model.coef_.T.reshape(train_nsp.shape[-1],train_vid.shape[1],train_vid.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(1e-2,100,10,base=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "crange = np.max(np.abs(model_coeff[21]))\n",
    "plt.imshow(model_coeff[21],cmap='RdBu_r',vmin=-crange,vmax=crange)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_grid = torchvision.utils.make_grid(torch.from_numpy(model_coeff[:,np.newaxis]),nrow=10,normalize=True)[0]\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,10))\n",
    "axs.imshow(im_grid, cmap='gray')#.permute(1,2,0))\n",
    "axs.set_title('Decoding Coeff')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'DecodingWeights_{}.png'.format(model_type),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "nks = np.shape(train_vid)[1:]; nk = nks[0]*nks[1]*nt_glm_lag\n",
    "vid_pred = sp_pred.reshape(sp_pred.shape[0],nks[0],nks[1])\n",
    "t=20\n",
    "plt.imshow(vid_pred[t])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for do_shuffle in [False]:\n",
    "    # Load Data\n",
    "    data,train_idx,test_idx = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=do_shuffle, do_norm=True,free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "    locals().update(data)\n",
    "    windn = 5\n",
    "    skipn = 3\n",
    "    ##### Start GLM Parallel Processing #####\n",
    "    start = time.time()\n",
    "    nks = np.shape(train_vid)[1:]; nk = nks-[0]*nks[1]*nt_glm_lag\n",
    "    # Reshape data (video) into (T*n)xN array\n",
    "    winds_train = sliding_window_view(train_vid,(windn,windn),axis=(1,2))[:,::skipn,::skipn]\n",
    "    winds_train = winds_train.reshape(winds_train.shape[0],-1,winds_train.shape[-2],winds_train.shape[-1])\n",
    "    winds_test = sliding_window_view(test_vid,(windn,windn),axis=(1,2))[:,::skipn,::skipn]\n",
    "    winds_test = winds_test.reshape(winds_test.shape[0],-1,winds_test.shape[-2],winds_test.shape[-1])\n",
    "#     y_train = train_vid.reshape(train_vid.shape[0],-1)\n",
    "#     y_test = test_vid.reshape(test_vid.shape[0],-1) \n",
    "    \n",
    "    # Put data into shared memory for parallization \n",
    "    train_nsp_r = ray.put(train_nsp)\n",
    "    test_nsp_r = ray.put(test_nsp)\n",
    "    train_data_r = ray.put(x_train)\n",
    "    test_data_r = ray.put(x_test)\n",
    "    result_ids = []\n",
    "    # Loop over parameters appending process ids\n",
    "    for celln in range(train_nsp.shape[1]):\n",
    "        result_ids.append(do_glm_fit_vis_skl.remote(train_nsp_r, test_nsp_r, train_data_r, test_data_r, celln, model_type, lag_list, model_dt=model_dt))\n",
    "\n",
    "    print('N_proc:', len(result_ids))\n",
    "    results_p = ray.get(result_ids)\n",
    "    print('GLM Add: ', time.time()-start)\n",
    "\n",
    "    ##### Gather Data and Find Max CC Model #####\n",
    "    mcc = np.stack([results_p[i][0] for i in range(len(results_p))])\n",
    "    msta = np.stack([results_p[i][1] for i in range(len(results_p))])\n",
    "    msp = np.stack([results_p[i][2] for i in range(len(results_p))])\n",
    "    mpred = np.stack([results_p[i][3] for i in range(len(results_p))])\n",
    "    mr2 = np.stack([results_p[i][4] for i in range(len(results_p))])\n",
    "\n",
    "#     nt_glm_lag = len(lag_list)\n",
    "#     GLM_Data = {'mcc': mcc,\n",
    "#                 'msta': msta,\n",
    "#                 'msp': msp,\n",
    "#                 'mpred': mpred,\n",
    "#                 'mr2':mr2,}\n",
    "#     if do_shuffle:\n",
    "#         ioh5.save(save_dir/'GLM_{}_Data_VisOnly_notsmooth_dt{:03d}_T{:02d}_shuffled.h5'.format(model_type,int(model_dt*1000), nt_glm_lag), GLM_Data)\n",
    "#     else:\n",
    "#         ioh5.save(save_dir/'GLM_{}_Data_VisOnly_notsmooth_dt{:03d}_T{:02d}.h5'.format(model_type,int(model_dt*1000), nt_glm_lag), GLM_Data)\n",
    "        \n",
    "#     del train_nsp_r, test_nsp_r, train_data_r, test_data_r, result_ids, results_p, mcc, msta, msp, mpred, mr2,\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(5000).reshape(50,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "windn = 5\n",
    "skipn = 3\n",
    "winds = sliding_window_view(train_vid,(windn,windn),axis=(1,2))[:,::skipn,::skipn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "winds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-prospect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "armed-object",
   "metadata": {},
   "source": [
    "# Predciting Future input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize movement combinations\n",
    "titles = np.array(['Theta','Phi','Roll','Pitch']) # 'dg_p','dg_n' 'roll','pitch'\n",
    "titles_all = []\n",
    "for n in range(1,len(titles)+1):\n",
    "    perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "    for ind in range(perms.shape[0]):\n",
    "        titles_all.append('_'.join([t for t in titles[perms[ind]]]))\n",
    "\n",
    "train_dgaze_p = train_dth + np.diff(train_gz,append=0)\n",
    "train_dgaze_n = train_dth - np.diff(train_gz,append=0)\n",
    "test_dgaze_p = test_dth + np.diff(test_gz,append=0)\n",
    "test_dgaze_n = test_dth - np.diff(test_gz,append=0)\n",
    "# move_train = np.hstack((train_th[:,np.newaxis],train_phi[:,np.newaxis],tr ain_roll[:,np.newaxis],train_pitch[:,np.newaxis]))#, train_dth[:,np.newaxis],train_dphi[:,np.newaxis]))\n",
    "# move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_roll[:,np.newaxis],test_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "move_train = np.hstack((train_dth[:,np.newaxis],train_dphi[:,np.newaxis],train_dgaze_p[:,np.newaxis],train_dgaze_n[:,np.newaxis]))#, train_dth[:,np.newaxis],train_dphi[:,np.newaxis]))\n",
    "move_test = np.hstack((test_dth[:,np.newaxis],test_dphi[:,np.newaxis],test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))# test_dth[:,np.newaxis],test_dphi[:,np.newaxis]))\n",
    "\n",
    "model_move = np.hstack((model_th[:,np.newaxis],model_phi[:,np.newaxis],model_roll[:,np.newaxis],model_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "model_move = model_move - np.mean(model_move,axis=0)\n",
    "move_test = move_test - np.mean(move_test,axis=0)\n",
    "move_train = move_train - np.mean(move_train,axis=0)\n",
    "\n",
    "\n",
    "lag_list = [5]\n",
    "Tvid = train_vid.shape[0]\n",
    "rolled_vid = np.hstack([np.roll(model_vid_sm, nframes, axis=0) for nframes in lag_list]) # nt_glm_lag\n",
    "x_train = train_vid.reshape(len(train_idx),-1)\n",
    "x_test = test_vid.reshape(len(test_idx),-1)\n",
    "\n",
    "y_train = rolled_vid[train_idx].reshape(len(train_idx),-1)\n",
    "y_test = rolled_vid[test_idx].reshape(len(test_idx),-1)\n",
    "\n",
    "npx = train_vid.shape[1]*train_vid.shape[2]\n",
    "npxs = train_vid.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "model = lm.RidgeCV(alphas=lambdas)\n",
    "model.fit(x_train,y_train)\n",
    "# sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "vid_pred = model.predict(x_test)\n",
    "cc = np.corrcoef(y_test,vid_pred)[0,1]\n",
    "r2 = model.score(vid_pred,y_test)\n",
    "\n",
    "n=4;ind=0\n",
    "perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "x_train_m1 = np.concatenate((x_train,move_train[:,perms[ind]]),axis=1)\n",
    "x_test_m1 = np.concatenate((x_test,move_test[:,perms[ind]]),axis=1)\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "modelm = lm.RidgeCV(alphas=lambdas)\n",
    "modelm.fit(x_train_m1,y_train)\n",
    "# sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "vid_predm = modelm.predict(x_test_m1)\n",
    "ccm = np.corrcoef(y_test,vid_predm)[0,1]\n",
    "r2m = r2_score(vid_predm[:,:npx], y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-question",
   "metadata": {},
   "source": [
    "## Mult Model I-IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model I: Visual only\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "modelm1 = lm.RidgeCV(alphas=lambdas)\n",
    "modelm1.fit(x_train,y_train)\n",
    "# sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "vid_predm1 = modelm1.predict(x_test)\n",
    "ccm1 = np.corrcoef(y_test,vid_predm1)[0,1]\n",
    "r2m1 = model1.score(vid_predm1,y_test)\n",
    "msem1 = np.mean((y_test-vid_predm1)**2)\n",
    "\n",
    "# Model II: Visual + Movement\n",
    "n=4;ind=0\n",
    "perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "x_train_m2 = np.concatenate((x_train,move_train[:,perms[ind]]),axis=1)\n",
    "x_test_m2 = np.concatenate((x_test,move_test[:,perms[ind]]),axis=1)\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "modelm2 = lm.RidgeCV(alphas=lambdas)\n",
    "modelm2.fit(x_train_m2,y_train)\n",
    "# sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "vid_predm2 = modelm2.predict(x_test_m2)\n",
    "ccm2 = np.corrcoef(y_test,vid_predm2)[0,1]\n",
    "r2m2 = r2_score(vid_predm2[:,:npx], y_test)\n",
    "msem2 = np.mean((y_test-vid_predm2)**2)\n",
    "\n",
    "# Model III: Visual + Vis*Mov + Mov\n",
    "xtr_tot = np.hstack((x_train,np.hstack([x_train*move_train[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_train[:,perms[ind]]))\n",
    "xte_tot = np.hstack((x_test,np.hstack([x_test*move_test[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_test[:,perms[ind]]))\n",
    "W = np.random.normal(loc=0,scale=1/(x_train.shape[-1]+len(titles)*x_train.shape[-1]+len(titles)),size=(x_train.shape[-1]+len(titles)*x_train.shape[-1]+len(titles),x_train.shape[-1]))\n",
    "x_train_m3 = (xtr_tot @ W)\n",
    "x_test_m3 = (xte_tot @ W)\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "modelm3 = lm.RidgeCV(alphas=lambdas)\n",
    "modelm3.fit(x_train_m3,y_train)\n",
    "# sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "vid_predm3 = modelm3.predict(x_test_m3)\n",
    "ccm3 = np.corrcoef(y_test,vid_predm3)[0,1]\n",
    "r2m3 = r2_score(vid_predm3[:,:npx], y_test)\n",
    "msem3 = np.mean((y_test-vid_predm3)**2)\n",
    "\n",
    "# Model IV: Vis + Vis*Mov\n",
    "xtr_tot = np.hstack((x_train,np.hstack([x_train*move_train[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))])))\n",
    "xte_tot = np.hstack((x_test,np.hstack([x_test*move_test[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))])))\n",
    "W = np.random.normal(loc=0,scale=1/(x_train.shape[-1]+len(titles)*x_train.shape[-1]),size=(x_train.shape[-1]+len(titles)*x_train.shape[-1],x_train.shape[-1]))\n",
    "x_train_m4 = (xtr_tot @ W)\n",
    "x_test_m4 = (xte_tot @ W)\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "modelm4 = lm.RidgeCV(alphas=lambdas)\n",
    "modelm4.fit(x_train_m4,y_train)\n",
    "# sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "vid_predm4 = modelm4.predict(x_test_m4)\n",
    "ccm4 = np.corrcoef(y_test,vid_predm4)[0,1]\n",
    "r2m4 = r2_score(vid_predm4[:,:npx], y_test)\n",
    "msem4 = np.mean((y_test-vid_predm4)**2)\n",
    "\n",
    "# Model V: Vis*Mov + Mov\n",
    "xtr_tot = np.hstack((np.hstack([x_train*move_train[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_train[:,perms[ind]]))\n",
    "xte_tot = np.hstack((np.hstack([x_test*move_test[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_test[:,perms[ind]]))\n",
    "W = np.random.normal(loc=0,scale=1/(len(titles)*x_train.shape[-1]+len(titles)),size=(len(titles)*x_train.shape[-1]+len(titles),x_train.shape[-1]))\n",
    "x_train_m5 = (xtr_tot @ W)\n",
    "x_test_m5 = (xte_tot @ W)\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "modelm5 = lm.RidgeCV(alphas=lambdas)\n",
    "modelm5.fit(x_train_m5,y_train)\n",
    "# sta_all = np.reshape(model.coef_,(nt_glm_lag,)+nks)\n",
    "vid_predm5 = modelm5.predict(x_test_m5)\n",
    "ccm5 = np.corrcoef(y_test,vid_predm5)[0,1]\n",
    "r2m5 = r2_score(vid_predm5[:,:npx], y_test)\n",
    "msem5 = np.mean((y_test-vid_predm5)**2)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-exchange",
   "metadata": {},
   "source": [
    "Try multilayer ff network. Only changing size of input space, same output space. 600. ReLu and Tanh, RNN??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "msem1,msem2,msem3,msem4,msem5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelm1.alpha_,modelm2.alpha_,modelm3.alpha_,modelm4.alpha_,modelm5.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.coef_.shape,modelm2.coef_.shape,modelm3.coef_.shape,modelm4.coef_.shape,modelm5.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm1,ccm2,ccm3,ccm4,ccm5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "px = 100\n",
    "fig,ax = plt.subplots(figsize=(15,8))\n",
    "ax.plot(x_test[:100,px] ,label='x_test')\n",
    "ax.plot(y_test[:100,px] ,label='y_test')\n",
    "ax.plot(vid_predm1[:100,px] ,label='Model 1')\n",
    "ax.plot(vid_predm2[:100,px] ,label='Model 2')\n",
    "ax.plot(vid_predm3[:100,px] ,label='Model 3')\n",
    "ax.plot(vid_predm4[:100,px] ,label='Model 4')\n",
    "ax.plot(vid_predm5[:100,px] ,label='Model 5')\n",
    "plt.legend()\n",
    "fig.savefig(FigPath/'ExamplePixelPrediction.png',bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 4\n",
    "y_test_up = np.zeros((y_test.shape[0],sf*model_vid_sm.shape[-2],sf*model_vid_sm.shape[-1]),dtype=np.float32)\n",
    "vid_predm1_up = np.zeros((vid_predm1.shape[0],sf*model_vid_sm.shape[-2],sf*model_vid_sm.shape[-1]),np.float32)\n",
    "vid_predm2_up = np.zeros((vid_predm2.shape[0],sf*model_vid_sm.shape[-2],sf*model_vid_sm.shape[-1]),np.float32)\n",
    "vid_predm3_up = np.zeros((vid_predm3.shape[0],sf*model_vid_sm.shape[-2],sf*model_vid_sm.shape[-1]),np.float32)\n",
    "vid_predm4_up = np.zeros((vid_predm4.shape[0],sf*model_vid_sm.shape[-2],sf*model_vid_sm.shape[-1]),np.float32)\n",
    "vid_predm5_up = np.zeros((vid_predm5.shape[0],sf*model_vid_sm.shape[-2],sf*model_vid_sm.shape[-1]),np.float32)\n",
    "for n in range(y_test.shape[0]):\n",
    "    \n",
    "#     for t in range(msta.shape[1]):\n",
    "    y_test_up[n] = cv2.resize(y_test[n],(sf*model_vid_sm.shape[-1],sf*model_vid_sm.shape[-2]))\n",
    "    vid_predm1_up[n] = cv2.resize(vid_predm1[n],(sf*model_vid_sm.shape[-1],sf*model_vid_sm.shape[-2]))\n",
    "    vid_predm2_up[n] = cv2.resize(vid_predm2[n],(sf*model_vid_sm.shape[-1],sf*model_vid_sm.shape[-2]))\n",
    "    vid_predm3_up[n] = cv2.resize(vid_predm3[n],(sf*model_vid_sm.shape[-1],sf*model_vid_sm.shape[-2]))\n",
    "    vid_predm4_up[n] = cv2.resize(vid_predm4[n],(sf*model_vid_sm.shape[-1],sf*model_vid_sm.shape[-2]))\n",
    "    vid_predm5_up[n] = cv2.resize(vid_predm5[n],(sf*model_vid_sm.shape[-1],sf*model_vid_sm.shape[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 25\n",
    "fig2 = plt.figure(constrained_layout=True, figsize=(20,10))\n",
    "spec2 = gridspec.GridSpec(ncols=5, nrows=2, figure=fig2)\n",
    "f2_ax1 = fig2.add_subplot(spec2[0, :])\n",
    "f2_ax2 = fig2.add_subplot(spec2[1, 0])\n",
    "f2_ax3 = fig2.add_subplot(spec2[1, 1])\n",
    "f2_ax4 = fig2.add_subplot(spec2[1, 2])\n",
    "f2_ax5 = fig2.add_subplot(spec2[1, 3])\n",
    "f2_ax6 = fig2.add_subplot(spec2[1, 4])\n",
    "\n",
    "f2_ax1.imshow(y_test[t].reshape(npxs))\n",
    "f2_ax1.set_title('Ground Truth')\n",
    "f2_ax2.imshow(vid_predm1[t].reshape(npxs))\n",
    "f2_ax2.set_title('Model 1')\n",
    "f2_ax3.imshow(vid_predm2[t].reshape(npxs))\n",
    "f2_ax3.set_title('Model 2')\n",
    "f2_ax4.imshow(vid_predm3[t].reshape(npxs))\n",
    "f2_ax4.set_title('Model 3')\n",
    "f2_ax5.imshow(vid_predm4[t].reshape(npxs))\n",
    "f2_ax5.set_title('Model 4')\n",
    "f2_ax6.imshow(vid_predm5[t].reshape(npxs))\n",
    "f2_ax6.set_title('Model 5')\n",
    "fig2.savefig(FigPath/'ExampleFramePrediction.png',bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-database",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "SetRange = transforms.Lambda(lambda X: 2 * X - 1.)\n",
    "SetScale = transforms.Lambda(lambda X: X/X.sum(0).expand_as(X))\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "#                                 transforms.ConvertImageDtype(torch.float32),\n",
    "                                SetRange])\n",
    "transform(x_train_m2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,y_test,x_train_m1,x_test_m1,x_train_m2,x_test_m2,xtr_tot_m3,xte_tot_m3,xtr_tot_m4,xte_tot_m4,xtr_tot_m5,xte_tot_m5,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize movement combinations\n",
    "titles = np.array(['Theta','Phi','Roll','Pitch']) # 'dg_p','dg_n' 'roll','pitch'\n",
    "titles_all = []\n",
    "for n in range(1,len(titles)+1):\n",
    "    perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "    for ind in range(perms.shape[0]):\n",
    "        titles_all.append('_'.join([t for t in titles[perms[ind]]]))\n",
    "\n",
    "train_dgaze_p = train_dth + np.diff(train_gz,append=0)\n",
    "train_dgaze_n = train_dth - np.diff(train_gz,append=0)\n",
    "test_dgaze_p = test_dth + np.diff(test_gz,append=0)\n",
    "test_dgaze_n = test_dth - np.diff(test_gz,append=0)\n",
    "# move_train = np.hstack((train_th[:,np.newaxis],train_phi[:,np.newaxis],tr ain_roll[:,np.newaxis],train_pitch[:,np.newaxis]))#, train_dth[:,np.newaxis],train_dphi[:,np.newaxis]))\n",
    "# move_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_roll[:,np.newaxis],test_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "move_train = np.hstack((train_dth[:,np.newaxis],train_dphi[:,np.newaxis],train_dgaze_p[:,np.newaxis],train_dgaze_n[:,np.newaxis]))#, train_dth[:,np.newaxis],train_dphi[:,np.newaxis]))\n",
    "move_test = np.hstack((test_dth[:,np.newaxis],test_dphi[:,np.newaxis],test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))# test_dth[:,np.newaxis],test_dphi[:,np.newaxis]))\n",
    "\n",
    "model_move = np.hstack((model_th[:,np.newaxis],model_phi[:,np.newaxis],model_roll[:,np.newaxis],model_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n",
    "model_move = model_move - np.mean(model_move,axis=0)\n",
    "move_test = move_test - np.mean(move_test,axis=0)\n",
    "move_train = move_train - np.mean(move_train,axis=0)\n",
    "\n",
    "\n",
    "lag_list = [1]\n",
    "Tvid = train_vid.shape[0]\n",
    "rolled_vid = np.hstack([np.roll(model_vid_sm, nframes, axis=0) for nframes in lag_list]) # nt_glm_lag\n",
    "x_train = train_vid.reshape(len(train_idx),-1)\n",
    "x_test = test_vid.reshape(len(test_idx),-1)\n",
    "\n",
    "y_train = rolled_vid[train_idx].reshape(len(train_idx),-1)\n",
    "y_test = rolled_vid[test_idx].reshape(len(test_idx),-1)\n",
    "\n",
    "npx = train_vid.shape[1]*train_vid.shape[2]\n",
    "npxs = train_vid.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-blair",
   "metadata": {},
   "source": [
    "Linear inputs, fixed hidden, nonlinearity, lienar readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_Size = 25\n",
    "lr = .001\n",
    "nonlinearity =  nn.Tanh()# 'nn.ReLU() #\n",
    "# Model I: Visual only\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "xtr_m1 = x_train.copy()\n",
    "xte_m1 = x_test.copy()\n",
    "modelm1 = nn.Sequential(nn.Linear(xtr_m1.shape[-1],RNN_Size), \n",
    "                        nonlinearity, \n",
    "                        nn.Linear(RNN_Size,npx)).to(device)\n",
    "# nn.RNN(x_train.shape[-1],RNN_Size,nonlinearity=nonlinearity).to(device)\n",
    "# lin_m1 = nn.Linear(RNN_Size,npx).to(device)\n",
    "# optim_m1 = optim.Adam(lr=lr,params=list(modelm1.parameters()) + list(lin_m1.parameters()))\n",
    "optim_m1 = optim.AdamW(lr=lr,params=modelm1.parameters(), weight_decay=.1)\n",
    "\n",
    "# Model II: Visual + Movement\n",
    "n=4;ind=0\n",
    "perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "xtr_m2 = np.concatenate((x_train,move_train[:,perms[ind]]),axis=1)\n",
    "xte_m2 = np.concatenate((x_test,move_test[:,perms[ind]]),axis=1)\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "modelm2 =  nn.Sequential(nn.Linear(xtr_m2.shape[-1],RNN_Size), \n",
    "                         nonlinearity, \n",
    "                         nn.Linear(RNN_Size,npx)).to(device)\n",
    "# nn.RNN(x_train_m2.shape[-1],RNN_Size,nonlinearity=nonlinearity).to(device)\n",
    "# lin_m2 = nn.Linear(RNN_Size,npx).to(device)\n",
    "# optim_m2 = optim.Adam(lr=lr,params=list(modelm2.parameters()) + list(lin_m2.parameters()))\n",
    "optim_m2 = optim.AdamW(lr=lr,params=modelm2.parameters(), weight_decay=.1)\n",
    "\n",
    "# Model III: Visual + Vis*Mov + Mov\n",
    "xtr_m3 = np.hstack((x_train,np.hstack([x_train*move_train[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_train[:,perms[ind]]))\n",
    "xte_m3 = np.hstack((x_test,np.hstack([x_test*move_test[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_test[:,perms[ind]]))\n",
    "W = np.random.normal(loc=0,scale=1/(x_train.shape[-1]+len(titles)*x_train.shape[-1]+len(titles)),size=(x_train.shape[-1]+len(titles)*x_train.shape[-1]+len(titles),x_train.shape[-1]))\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "modelm3 =  nn.Sequential(nn.Linear(xtr_m3.shape[-1],RNN_Size), \n",
    "                         nonlinearity, \n",
    "                         nn.Linear(RNN_Size,npx)).to(device)\n",
    "# nn.RNN(xtr_tot_m3.shape[-1],RNN_Size,nonlinearity=nonlinearity).to(device)\n",
    "# lin_m3 = nn.Linear(RNN_Size,npx).to(device)\n",
    "# optim_m3 = optim.Adam(lr=lr,params=list(modelm3.parameters()) + list(lin_m3.parameters()))\n",
    "optim_m3 = optim.AdamW(lr=lr,params=modelm3.parameters(), weight_decay=.1)\n",
    "\n",
    "# Model IV: Vis + Vis*Mov\n",
    "xtr_m4 = np.hstack((x_train,np.hstack([x_train*move_train[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))])))\n",
    "xte_m4 = np.hstack((x_test,np.hstack([x_test*move_test[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))])))\n",
    "W = np.random.normal(loc=0,scale=1/(x_train.shape[-1]+len(titles)*x_train.shape[-1]),size=(x_train.shape[-1]+len(titles)*x_train.shape[-1],x_train.shape[-1]))\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "modelm4 =  nn.Sequential(nn.Linear(xtr_m4.shape[-1],RNN_Size), \n",
    "                         nonlinearity, \n",
    "                         nn.Linear(RNN_Size,npx)).to(device)\n",
    "# nn.RNN(xtr_tot_m4.shape[-1],RNN_Size,nonlinearity=nonlinearity).to(device)\n",
    "# lin_m4 = nn.Linear(RNN_Size,npx).to(device)\n",
    "# optim_m4 = optim.Adam(lr=lr,params=list(modelm4.parameters()) + list(lin_m4.parameters()))\n",
    "optim_m4 = optim.AdamW(lr=lr,params=modelm4.parameters(), weight_decay=.1)\n",
    "\n",
    "# Model V: Vis*Mov + Mov\n",
    "xtr_m5 = np.hstack((np.hstack([x_train*move_train[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_train[:,perms[ind]]))\n",
    "xte_m5 = np.hstack((np.hstack([x_test*move_test[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_test[:,perms[ind]]))\n",
    "W = np.random.normal(loc=0,scale=1/(len(titles)*x_train.shape[-1]+len(titles)),size=(len(titles)*x_train.shape[-1]+len(titles),x_train.shape[-1]))\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "modelm5 =  nn.Sequential(nn.Linear(xtr_m5.shape[-1],RNN_Size), \n",
    "                         nonlinearity, \n",
    "                         nn.Linear(RNN_Size,npx)).to(device)\n",
    "# nn.RNN(xtr_tot_m5.shape[-1],RNN_Size,nonlinearity=nonlinearity).to(device)\n",
    "# lin_m5 = nn.Linear(RNN_Size,npx).to(device)\n",
    "# optim_m5 = optim.Adam(lr=lr,params=list(modelm5.parameters()) + list(lin_m5.parameters()))\n",
    "optim_m5 = optim.Adam(lr=lr,params=modelm5.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ytr = torch.from_numpy(y_train.astype(np.float32)).to(device)\n",
    "yte = torch.from_numpy(y_test.astype(np.float32)).to(device)\n",
    "xtr_tot_m1 = torch.from_numpy(xtr_m1.reshape(1,xtr_m1.shape[0],xtr_m1.shape[-1]).astype(np.float32)).to(device)\n",
    "xte_tot_m1 = torch.from_numpy(xte_m1.reshape(1,xte_m1.shape[0],xte_m1.shape[-1]).astype(np.float32)).to(device)\n",
    "xtr_tot_m2 = torch.from_numpy(xtr_m2.reshape(1,xtr_m2.shape[0],xtr_m2.shape[-1]).astype(np.float32)).to(device)\n",
    "xte_tot_m2 = torch.from_numpy(xte_m2.reshape(1,xte_m2.shape[0],xte_m2.shape[-1]).astype(np.float32)).to(device)\n",
    "xtr_tot_m3 = torch.from_numpy(xtr_m3.reshape(1,xtr_m3.shape[0],xtr_m3.shape[-1]).astype(np.float32)).to(device)\n",
    "xte_tot_m3 = torch.from_numpy(xte_m3.reshape(1,xte_m3.shape[0],xte_m3.shape[-1]).astype(np.float32)).to(device)\n",
    "xtr_tot_m4 = torch.from_numpy(xtr_m4.reshape(1,xtr_m4.shape[0],xtr_m4.shape[-1]).astype(np.float32)).to(device)\n",
    "xte_tot_m4 = torch.from_numpy(xte_m4.reshape(1,xte_m4.shape[0],xte_m4.shape[-1]).astype(np.float32)).to(device)\n",
    "xtr_tot_m5 = torch.from_numpy(xtr_m5.reshape(1,xtr_m5.shape[0],xtr_m5.shape[-1]).astype(np.float32)).to(device)\n",
    "xte_tot_m5 = torch.from_numpy(xte_m5.reshape(1,xte_m5.shape[0],xte_m5.shape[-1]).astype(np.float32)).to(device)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbatches = 1000\n",
    "lossfn = nn.MSELoss()\n",
    "Loss_trace_train = np.zeros((5,Nbatches))\n",
    "Loss_trace_test = np.zeros((5,Nbatches))\n",
    "\n",
    "for n in tqdm(np.arange(Nbatches)):\n",
    "    out1= modelm1(xtr_tot_m1)\n",
    "#     out1 = lin_m1(out1)\n",
    "    out2= modelm2(xtr_tot_m2)\n",
    "#     out2 = lin_m2(out2)\n",
    "    out3= modelm3(xtr_tot_m3)\n",
    "#     out3 = lin_m3(out3)\n",
    "    out4= modelm4(xtr_tot_m4)\n",
    "#     out4 = lin_m4(out4)\n",
    "    out5= modelm5(xtr_tot_m5)\n",
    "#     out5 = lin_m5(out5)\n",
    "    optim_m1.zero_grad()\n",
    "    optim_m2.zero_grad()\n",
    "    optim_m3.zero_grad()\n",
    "    optim_m4.zero_grad()\n",
    "    optim_m5.zero_grad()\n",
    "    loss1 = lossfn(out1.squeeze(),ytr)\n",
    "    loss2 = lossfn(out2.squeeze(),ytr)\n",
    "    loss3 = lossfn(out3.squeeze(),ytr)\n",
    "    loss4 = lossfn(out4.squeeze(),ytr)\n",
    "    loss5 = lossfn(out5.squeeze(),ytr)\n",
    "    loss1.backward()\n",
    "    loss2.backward()\n",
    "    loss3.backward()\n",
    "    loss4.backward()\n",
    "    loss5.backward()\n",
    "    optim_m1.step()\n",
    "    optim_m2.step()\n",
    "    optim_m3.step()\n",
    "    optim_m4.step()\n",
    "    optim_m5.step()\n",
    "    v_loss1 = lossfn(modelm1(xte_tot_m1).squeeze(),yte)\n",
    "    v_loss2 = lossfn(modelm2(xte_tot_m2).squeeze(),yte)\n",
    "    v_loss3 = lossfn(modelm3(xte_tot_m3).squeeze(),yte)\n",
    "    v_loss4 = lossfn(modelm4(xte_tot_m4).squeeze(),yte)\n",
    "    v_loss5 = lossfn(modelm5(xte_tot_m5).squeeze(),yte)\n",
    "    Loss_trace_train[:,n] = np.array([loss1.item(),loss2.item(),loss3.item(),loss4.item(),loss5.item()])\n",
    "    Loss_trace_test[:,n] = np.array([v_loss1.item(),v_loss2.item(),v_loss3.item(),v_loss4.item(),v_loss5.item()])\n",
    "out1 = modelm1(xte_tot_m1)\n",
    "# out1 = lin_m1(out1)\n",
    "out2 = modelm2(xte_tot_m2)\n",
    "# out2 = lin_m2(out2)\n",
    "out3 = modelm3(xte_tot_m3)\n",
    "# out3 = lin_m3(out3)\n",
    "out4 = modelm4(xte_tot_m4)\n",
    "# out4 = lin_m4(out4)\n",
    "out5 = modelm5(xte_tot_m5)\n",
    "# out5 = lin_m5(out5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_trace_train[:,-1], Loss_trace_test[:,-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = ['-', '--', '-.', ':','--']\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "for n in range(Loss_trace_train.shape[0]):\n",
    "    ax.plot(Loss_trace_train[n],label='Model {}'.format(n+1),lw=3,ls=ls[n])\n",
    "#     ax.plot(Loss_trace_test[n],label='Model {}'.format(n+1),lw=3,ls=ls[n])\n",
    "    \n",
    "ax.set_xlabel('Batch Iteration')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.legend()\n",
    "# fig.savefig(FigPath/'FF_Loss_{}_Traces_{}.png'.format('Train',nonlinearity),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls = ['-', '--', '-.', ':','--']\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "for n in range(Loss_trace_train.shape[0]):\n",
    "#     ax.plot(Loss_trace_train[n],label='Model {}'.format(n+1),lw=3,ls=ls[n])\n",
    "    ax.plot(Loss_trace_test[n],label='Model {}'.format(n+1),lw=3,ls=ls[n])\n",
    "    \n",
    "ax.set_xlabel('Batch Iteration')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.legend()\n",
    "# fig.savefig(FigPath/'FF_Loss_{}_Traces_{}.png'.format('Test',nonlinearity),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1 = y_test.cpu().detach().numpy().reshape((y_test.shape[0],)+npxs)\n",
    "out1 = out1.cpu().detach().numpy().reshape((out1.shape[1],)+npxs)\n",
    "out2 = out2.cpu().detach().numpy().reshape((out2.shape[1],)+npxs)\n",
    "out3 = out3.cpu().detach().numpy().reshape((out3.shape[1],)+npxs)\n",
    "out4 = out4.cpu().detach().numpy().reshape((out4.shape[1],)+npxs)\n",
    "out5 = out5.cpu().detach().numpy().reshape((out5.shape[1],)+npxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 150\n",
    "fig2 = plt.figure(constrained_layout=True, figsize=(20,10))\n",
    "spec2 = gridspec.GridSpec(ncols=5, nrows=2, figure=fig2)\n",
    "f2_ax1 = fig2.add_subplot(spec2[0, :])\n",
    "f2_ax2 = fig2.add_subplot(spec2[1, 0])\n",
    "f2_ax3 = fig2.add_subplot(spec2[1, 1])\n",
    "f2_ax4 = fig2.add_subplot(spec2[1, 2])\n",
    "f2_ax5 = fig2.add_subplot(spec2[1, 3])\n",
    "f2_ax6 = fig2.add_subplot(spec2[1, 4])\n",
    "\n",
    "f2_ax1.imshow(y_test1[t])\n",
    "f2_ax1.set_title('Ground Truth')\n",
    "f2_ax1.axis('off')\n",
    "f2_ax2.imshow(out1[t])\n",
    "f2_ax2.set_title('Model 1')\n",
    "f2_ax2.axis('off')\n",
    "f2_ax3.imshow(out2[t])\n",
    "f2_ax3.set_title('Model 2')\n",
    "f2_ax3.axis('off')\n",
    "f2_ax4.imshow(out3[t])\n",
    "f2_ax4.set_title('Model 3')\n",
    "f2_ax4.axis('off')\n",
    "f2_ax5.imshow(out4[t])\n",
    "f2_ax5.set_title('Model 4')\n",
    "f2_ax5.axis('off')\n",
    "f2_ax6.imshow(out5[t])\n",
    "f2_ax6.set_title('Model 5')\n",
    "f2_ax6.axis('off')\n",
    "# fig2.savefig(FigPath/'FF_ExampleFramePrediction_{}.png'.format(nonlinearity),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "FigPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-spectacular",
   "metadata": {},
   "source": [
    "### Pytorch RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_Size = 25\n",
    "lr = .001\n",
    "nonlinearity = 'tanh' #nn.Tanh()# 'nn.ReLU() #\n",
    "# Model I: Visual only\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "xtr_m1 = x_train.copy()\n",
    "xte_m1 = x_test.copy()\n",
    "# modelm1 = nn.Sequential(nn.Linear(xtr_m1.shape[-1],RNN_Size), \n",
    "#                         nonlinearity, \n",
    "#                         nn.Linear(RNN_Size,npx)).to(device)\n",
    "modelm1 = nn.RNN(xtr_m1.shape[-1],RNN_Size,nonlinearity=nonlinearity).to(device)\n",
    "lin_m1 = nn.Linear(RNN_Size,npx).to(device)\n",
    "optim_m1 = optim.AdamW(lr=lr,params=list(modelm1.parameters()) + list(lin_m1.parameters()), weight_decay=.01)\n",
    "# optim_m1 = optim.Adam(lr=lr,params=modelm1.parameters())\n",
    "\n",
    "# Model II: Visual + Movement\n",
    "n=4;ind=0\n",
    "perms = np.array(list(itertools.combinations(np.arange(len(titles)), n)))\n",
    "xtr_m2 = np.concatenate((x_train,move_train[:,perms[ind]]),axis=1)\n",
    "xte_m2 = np.concatenate((x_test,move_test[:,perms[ind]]),axis=1)\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "# modelm2 =  nn.Sequential(nn.Linear(xtr_m2.shape[-1],RNN_Size), \n",
    "#                          nonlinearity, \n",
    "#                          nn.Linear(RNN_Size,npx)).to(device)\n",
    "modelm2 = nn.RNN(xtr_m2.shape[-1],RNN_Size,nonlinearity=nonlinearity).to(device)\n",
    "lin_m2 = nn.Linear(RNN_Size,npx).to(device)\n",
    "optim_m2 = optim.AdamW(lr=lr,params=list(modelm2.parameters()) + list(lin_m2.parameters()), weight_decay=.01)\n",
    "# optim_m2 = optim.Adam(lr=lr,params=modelm2.parameters())\n",
    "\n",
    "# Model III: Visual + Vis*Mov + Mov\n",
    "xtr_m3 = np.hstack((x_train,np.hstack([x_train*move_train[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_train[:,perms[ind]]))\n",
    "xte_m3 = np.hstack((x_test,np.hstack([x_test*move_test[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_test[:,perms[ind]]))\n",
    "W = np.random.normal(loc=0,scale=1/(x_train.shape[-1]+len(titles)*x_train.shape[-1]+len(titles)),size=(x_train.shape[-1]+len(titles)*x_train.shape[-1]+len(titles),x_train.shape[-1]))\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "# modelm3 =  nn.Sequential(nn.Linear(xtr_m3.shape[-1],RNN_Size), \n",
    "#                          nonlinearity, \n",
    "#                          nn.Linear(RNN_Size,npx)).to(device)\n",
    "modelm3 = nn.RNN(xtr_m3.shape[-1],RNN_Size,nonlinearity=nonlinearity).to(device)\n",
    "lin_m3 = nn.Linear(RNN_Size,npx).to(device)\n",
    "optim_m3 = optim.AdamW(lr=lr,params=list(modelm3.parameters()) + list(lin_m3.parameters()), weight_decay=.01)\n",
    "# optim_m3 = optim.Adam(lr=lr,params=modelm3.parameters())\n",
    "\n",
    "# Model IV: Vis + Vis*Mov\n",
    "xtr_m4 = np.hstack((x_train,np.hstack([x_train*move_train[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))])))\n",
    "xte_m4 = np.hstack((x_test,np.hstack([x_test*move_test[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))])))\n",
    "W = np.random.normal(loc=0,scale=1/(x_train.shape[-1]+len(titles)*x_train.shape[-1]),size=(x_train.shape[-1]+len(titles)*x_train.shape[-1],x_train.shape[-1]))\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "# modelm4 =  nn.Sequential(nn.Linear(xtr_m4.shape[-1],RNN_Size), \n",
    "#                          nonlinearity, \n",
    "#                          nn.Linear(RNN_Size,npx)).to(device)\n",
    "modelm4 = nn.RNN(xtr_m4.shape[-1],RNN_Size,nonlinearity=nonlinearity).to(device)\n",
    "lin_m4 = nn.Linear(RNN_Size,npx).to(device)\n",
    "optim_m4 = optim.AdamW(lr=lr,params=list(modelm4.parameters()) + list(lin_m4.parameters()), weight_decay=.01)\n",
    "# optim_m4 = optim.Adam(lr=lr,params=modelm4.parameters())\n",
    "\n",
    "# Model V: Vis*Mov + Mov\n",
    "xtr_m5 = np.hstack((np.hstack([x_train*move_train[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_train[:,perms[ind]]))\n",
    "xte_m5 = np.hstack((np.hstack([x_test*move_test[:,modeln][:,np.newaxis] for modeln in np.arange(len(titles))]), move_test[:,perms[ind]]))\n",
    "W = np.random.normal(loc=0,scale=1/(len(titles)*x_train.shape[-1]+len(titles)),size=(len(titles)*x_train.shape[-1]+len(titles),x_train.shape[-1]))\n",
    "lambdas = 1024 * (2**np.arange(0,16))\n",
    "# modelm5 =  nn.Sequential(nn.Linear(xtr_m5.shape[-1],RNN_Size), \n",
    "#                          nonlinearity, \n",
    "#                          nn.Linear(RNN_Size,npx)).to(device)\n",
    "modelm5 = nn.RNN(xtr_m5.shape[-1],RNN_Size,nonlinearity=nonlinearity).to(device)\n",
    "lin_m5 = nn.Linear(RNN_Size,npx).to(device)\n",
    "optim_m5 = optim.AdamW(lr=lr,params=list(modelm5.parameters()) + list(lin_m5.parameters()), weight_decay=.01)\n",
    "# optim_m5 = optim.Adam(lr=lr,params=modelm5.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbatches = 1000\n",
    "lossfn = nn.MSELoss()\n",
    "Loss_trace_train = np.zeros((5,Nbatches))\n",
    "Loss_trace_test = np.zeros((5,Nbatches))\n",
    "\n",
    "for n in tqdm(np.arange(Nbatches)):\n",
    "    out1,_ = modelm1(xtr_tot_m1)\n",
    "    out1 = lin_m1(out1)\n",
    "    out2,_ = modelm2(xtr_tot_m2)\n",
    "    out2 = lin_m2(out2)\n",
    "    out3,_ = modelm3(xtr_tot_m3)\n",
    "    out3 = lin_m3(out3)\n",
    "    out4,_ = modelm4(xtr_tot_m4)\n",
    "    out4 = lin_m4(out4)\n",
    "    out5,_ = modelm5(xtr_tot_m5)\n",
    "    out5 = lin_m5(out5)\n",
    "    optim_m1.zero_grad()\n",
    "    optim_m2.zero_grad()\n",
    "    optim_m3.zero_grad()\n",
    "    optim_m4.zero_grad()\n",
    "    optim_m5.zero_grad()\n",
    "    loss1 = lossfn(out1.squeeze(),ytr)\n",
    "    loss2 = lossfn(out2.squeeze(),ytr)\n",
    "    loss3 = lossfn(out3.squeeze(),ytr)\n",
    "    loss4 = lossfn(out4.squeeze(),ytr)\n",
    "    loss5 = lossfn(out5.squeeze(),ytr)\n",
    "    loss1.backward()\n",
    "    loss2.backward()\n",
    "    loss3.backward()\n",
    "    loss4.backward()\n",
    "    loss5.backward()\n",
    "    optim_m1.step()\n",
    "    optim_m2.step()\n",
    "    optim_m3.step()\n",
    "    optim_m4.step()\n",
    "    optim_m5.step()\n",
    "    v_loss1 = lossfn(lin_m1(modelm1(xte_tot_m1)[0]).squeeze(),yte)\n",
    "    v_loss2 = lossfn(lin_m2(modelm2(xte_tot_m2)[0]).squeeze(),yte)\n",
    "    v_loss3 = lossfn(lin_m3(modelm3(xte_tot_m3)[0]).squeeze(),yte)\n",
    "    v_loss4 = lossfn(lin_m4(modelm4(xte_tot_m4)[0]).squeeze(),yte)\n",
    "    v_loss5 = lossfn(lin_m5(modelm5(xte_tot_m5)[0]).squeeze(),yte)\n",
    "    Loss_trace_train[:,n] = np.array([loss1.item(),loss2.item(),loss3.item(),loss4.item(),loss5.item()])\n",
    "    Loss_trace_test[:,n] = np.array([v_loss1.item(),v_loss2.item(),v_loss3.item(),v_loss4.item(),v_loss5.item()])\n",
    "out1,_ = modelm1(xte_tot_m1)\n",
    "out1 = lin_m1(out1)\n",
    "out2,_ = modelm2(xte_tot_m2)\n",
    "out2 = lin_m2(out2)\n",
    "out3,_ = modelm3(xte_tot_m3)\n",
    "out3 = lin_m3(out3)\n",
    "out4,_ = modelm4(xte_tot_m4)\n",
    "out4 = lin_m4(out4)\n",
    "out5,_ = modelm5(xte_tot_m5)\n",
    "out5 = lin_m5(out5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = ['-', '--', '-.', ':','--']\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "for n in range(Loss_trace_train.shape[0]):\n",
    "    ax.plot(Loss_trace_train[n],label='Model {}'.format(n+1),lw=3,ls=ls[n])\n",
    "#     ax.plot(Loss_trace_test[n],label='Model {}'.format(n+1),lw=3,ls=ls[n])\n",
    "    \n",
    "ax.set_xlabel('Batch Iteration')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.legend()\n",
    "# fig.savefig(FigPath/'FF_Loss_{}_Traces_{}.png'.format('Train',nonlinearity),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls = ['-', '--', '-.', ':','--']\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "for n in range(Loss_trace_train.shape[0]):\n",
    "#     ax.plot(Loss_trace_train[n],label='Model {}'.format(n+1),lw=3,ls=ls[n])\n",
    "    ax.plot(Loss_trace_test[n],label='Model {}'.format(n+1),lw=3,ls=ls[n])\n",
    "    \n",
    "ax.set_xlabel('Batch Iteration')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.legend()\n",
    "# fig.savefig(FigPath/'FF_Loss_{}_Traces_{}.png'.format('Test',nonlinearity),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1 = yte.cpu().detach().numpy().reshape((y_test.shape[0],)+npxs)\n",
    "out1 = out1.cpu().detach().numpy().reshape((out1.shape[1],)+npxs)\n",
    "out2 = out2.cpu().detach().numpy().reshape((out2.shape[1],)+npxs)\n",
    "out3 = out3.cpu().detach().numpy().reshape((out3.shape[1],)+npxs)\n",
    "out4 = out4.cpu().detach().numpy().reshape((out4.shape[1],)+npxs)\n",
    "out5 = out5.cpu().detach().numpy().reshape((out5.shape[1],)+npxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 150\n",
    "fig2 = plt.figure(constrained_layout=True, figsize=(20,10))\n",
    "spec2 = gridspec.GridSpec(ncols=5, nrows=2, figure=fig2)\n",
    "f2_ax1 = fig2.add_subplot(spec2[0, :])\n",
    "f2_ax2 = fig2.add_subplot(spec2[1, 0])\n",
    "f2_ax3 = fig2.add_subplot(spec2[1, 1])\n",
    "f2_ax4 = fig2.add_subplot(spec2[1, 2])\n",
    "f2_ax5 = fig2.add_subplot(spec2[1, 3])\n",
    "f2_ax6 = fig2.add_subplot(spec2[1, 4])\n",
    "\n",
    "f2_ax1.imshow(y_test1[t])\n",
    "f2_ax1.set_title('Ground Truth')\n",
    "f2_ax1.axis('off')\n",
    "f2_ax2.imshow(out1[t])\n",
    "f2_ax2.set_title('Model 1')\n",
    "f2_ax2.axis('off')\n",
    "f2_ax3.imshow(out2[t])\n",
    "f2_ax3.set_title('Model 2')\n",
    "f2_ax3.axis('off')\n",
    "f2_ax4.imshow(out3[t])\n",
    "f2_ax4.set_title('Model 3')\n",
    "f2_ax4.axis('off')\n",
    "f2_ax5.imshow(out4[t])\n",
    "f2_ax5.set_title('Model 4')\n",
    "f2_ax5.axis('off')\n",
    "f2_ax6.imshow(out5[t])\n",
    "f2_ax6.set_title('Model 5')\n",
    "f2_ax6.axis('off')\n",
    "# fig2.savefig(FigPath/'FF_ExampleFramePrediction_{}.png'.format(nonlinearity),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-control",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-corpus",
   "metadata": {},
   "source": [
    "## Regression on Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_shuffle = False\n",
    "data = load_train_test(file_dict, save_dir, model_dt=model_dt, do_shuffle=do_shuffle, do_norm=True, free_move=free_move, has_imu=free_move, has_mouse=False)\n",
    "locals().update(data)\n",
    "Y_train = np.hstack((train_th[:,np.newaxis],train_phi[:,np.newaxis],train_roll[:,np.newaxis],train_pitch[:,np.newaxis]))#, train_dth[:,np.newaxis],train_dphi[:,np.newaxis]))\n",
    "Y_test = np.hstack((test_th[:,np.newaxis],test_phi[:,np.newaxis],test_roll[:,np.newaxis],test_pitch[:,np.newaxis])) #,test_dgaze_p[:,np.newaxis],test_dgaze_n[:,np.newaxis]))#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'ridgecv'\n",
    "if model_type == 'elasticnetcv':\n",
    "    model = make_pipeline(StandardScaler(), lm.ElasticNetCV()) # lm.RidgeCV(alphas=np.arange(100,10000,1000))) #  #MultiOutputRegressor(lm.Ridge(),n_jobs=-1)) \n",
    "elif model_type == 'ridgecv':\n",
    "    model = make_pipeline(StandardScaler(), lm.RidgeCV())\n",
    "\n",
    "model.fit(train_nsp, Y_train)\n",
    "pred_train = model.predict(train_nsp)\n",
    "pred_test = model.predict(test_nsp)\n",
    "train_score = model.score(train_nsp,Y_train)\n",
    "test_score = model.score(test_nsp, Y_test)\n",
    "print('Train Score:', train_score, 'Test Score:', test_score)\n",
    "# print(model['model_type'].coef_[22])\n",
    "cc = np.corrcoef(pred_test,Y_test)\n",
    "print('cc={:.02f}'.format(cc[0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Flip test and train #####\n",
    "# model2 = make_pipeline(StandardScaler(), lm.RidgeCV())\n",
    "# model2.fit(test_nsp, Y_test)\n",
    "# pred_train = model2.predict(test_nsp)\n",
    "# pred_test = model2.predict(train_nsp)\n",
    "# train_score = model2.score(test_nsp,Y_test)\n",
    "# test_score = model2.score(train_nsp, Y_train)\n",
    "# print('Train Score:', train_score, 'Test Score:', test_score)\n",
    "# print(model2['ridgecv'].coef_[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "model[model_type].alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeln = 3\n",
    "plt.plot(Y_test[:100,modeln])\n",
    "\n",
    "plt.plot(pred_test[:100,modeln])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "dt = 10000\n",
    "plt.plot(np.arange(t,t+dt),Y_train[t:t+dt])\n",
    "plt.plot(np.arange(t,t+dt), pred_train[t:t+dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 100\n",
    "dt = 100\n",
    "fig, axs = plt.subplots(1,figsize=(7,5))\n",
    "cc = np.corrcoef(Y_test,pred_test)[0,1]\n",
    "axs.plot(np.arange(t,t+dt)*model_dt,Y_test[t:t+dt], 'k', label='Ground Truth')\n",
    "axs.plot(np.arange(t,t+dt)*model_dt,pred_test[t:t+dt], 'r', label='Prediction')\n",
    "axs.set_title('CorrCoeff: {:.02f}'.format(cc))\n",
    "axs.set_xlabel('Time (s)')\n",
    "# axs.set_ylabel('Eye Phi Angle')\n",
    "axs.legend()\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'LinearRegressionExample_phi.png',bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(Y_train,pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(Y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test,pred_test, alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(model['elasticnetcv'].coef_)\n",
    "plt.plot(model['ridgecv'].coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-methodology",
   "metadata": {},
   "source": [
    "# Autocorrelation of the th, vid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter1d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(test_th, test_nsp[:,22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcorr_data = plt.xcorr(test_th, test_nsp[:,22], maxlags=100)\n",
    "lags, xscore = xcorr_data[0], xcorr_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags[np.argmax(xscore)], xscore[np.argmax(xscore)],lags[np.argmin(xscore)], xscore[np.argmin(xscore)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.acorr(train_th, maxlags=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-department",
   "metadata": {},
   "source": [
    "## Regression on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vid, test_vid, train_nsp, test_nsp, train_th, test_th, train_phi, test_phi, train_roll, test_roll, train_pitch, test_pitch, train_t, test_t, train_dth, test_dth, train_dphi, test_dphi = \\\n",
    "train_test_split(model_vid_sm, model_nsp, model_th, model_phi, model_roll, model_pitch, model_t, model_dth, model_dphi, train_size=.6, shuffle=False, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-secretariat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_vid.reshape(train_vid.shape[0],-1)#[:,10:11] # np.stack((train_roll, train_pitch),axis=1) # \n",
    "Y_test = test_vid.reshape(test_vid.shape[0],-1)#[:,10:11] # np.stack((test_roll, test_pitch),axis=1) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def multi_regression(train_nsp,Y_train,test_nsp,Y_test,idx,model_type):\n",
    "    if model_type == 'elasticnetcv':\n",
    "        model = lm.ElasticNetCV() # lm.RidgeCV(alphas=np.arange(100,10000,1000))) #  #MultiOutputRegressor(lm.Ridge(),n_jobs=-1)) \n",
    "    elif model_type == 'ridgecv':\n",
    "        model = lm.RidgeCV(alphas=np.arange(100,10000,1000))\n",
    "        \n",
    "    # MultiTaskElasticNetCV(n_jobs=-1)) # RidgeCV()# MultiTaskLassoCV(n_jobs=-1) # RidgeCV() # LinearRegression(n_jobs=-1) #\n",
    "    # register_ray()\n",
    "    # with joblib.parallel_backend('ray'):\n",
    "    model.fit(train_nsp, Y_train[:,idx])\n",
    "    pred_train = model.predict(train_nsp)\n",
    "    pred_test = model.predict(test_nsp)\n",
    "    model_coeff = model.coef_\n",
    "#     print('Train Score:', model.score(train_nsp,Y_train), 'Test Score:', model.score(test_nsp, Y_test))\n",
    "    train_score = np.corrcoef(pred_train,Y_train[:,idx])[0,1]\n",
    "    test_score = np.corrcoef(pred_test, Y_test[:,idx])[0,1]\n",
    "    alphas = model.alpha_\n",
    "    return pred_train, pred_test, train_score, test_score, model_coeff, alphas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'ridgecv'\n",
    "\n",
    "start = time.time()\n",
    "train_nsp_r = ray.put(train_nsp)\n",
    "Y_train_r = ray.put(Y_train)\n",
    "test_nsp_r = ray.put(test_nsp)\n",
    "Y_test_r = ray.put(Y_test)\n",
    "result_ids = []\n",
    "[result_ids.append(multi_regression.remote(train_nsp_r,Y_train_r,test_nsp_r,Y_test_r,idx,model_type)) for idx in range(0, train_vid.shape[-1]*train_vid.shape[-2])]\n",
    "results_p = ray.get(result_ids)\n",
    "print('MultiReg Time: ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = np.stack([results_p[i][0] for i in range(len(results_p))])\n",
    "pred_test = np.stack([results_p[i][1] for i in range(len(results_p))])\n",
    "train_scores = np.array([results_p[i][2] for i in range(len(results_p))])\n",
    "test_scores = np.array([results_p[i][3] for i in range(len(results_p))])\n",
    "model_coeff = np.array([results_p[i][4] for i in range(len(results_p))])\n",
    "alphas = np.array([results_p[i][5] for i in range(len(results_p))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pred_train.T.reshape(pred_train.shape[-1],train_vid.shape[1],train_vid.shape[2])\n",
    "pred_test = pred_test.T.reshape(pred_test.shape[-1],test_vid.shape[1],test_vid.shape[2])\n",
    "model_coeff = model_coeff.T.reshape(train_nsp.shape[-1],train_vid.shape[1],train_vid.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet_data = {\n",
    "#                 'train_scores': train_scores,\n",
    "#                 'test_scores': test_scores,\n",
    "#                 'pred_train': pred_train,\n",
    "#                 'pred_test': pred_test, }\n",
    "# ioh5.save(save_dir/'ElasticNet_data.h5',ElasticNet_data)\n",
    "\n",
    "# Ridge_data = ioh5.load(save_dir/'RidgeData.h5')\n",
    "# locals().update(ElasticNet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# t = 200\n",
    "# dt = 500\n",
    "# comb = np.concatenate((pred_train[t:t+dt,np.newaxis,:,:], train_vid[t:t+dt,np.newaxis,:,:]),axis=1)\n",
    "\n",
    "# fig = px.imshow(comb, animation_frame=0, facet_col=1, binary_string=False)\n",
    "# fig.update_layout(width=1000,\n",
    "#                   height=500,\n",
    "#                  )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-commodity",
   "metadata": {},
   "source": [
    "Need to look at decoding weights and see if they resempble receptive fields?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-mercury",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "auburn-johnston",
   "metadata": {},
   "source": [
    "## Plotting Decoded Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torchvision\n",
    "from scipy.ndimage import uniform_filter1d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "FigPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1130 #2000\n",
    "dt = 10\n",
    "fig, ax = plt.subplots(1,10,figsize=(30,3))\n",
    "\n",
    "for n,t in enumerate(np.arange(t,t+dt)):\n",
    "    ax[n].imshow(pred_test[t,:,:], cmap='gray')\n",
    "    ax[n].axis('off')\n",
    "plt.suptitle('Decoding Frames')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'Decoding_Frame.png',facecolor='white', transparent=True)\n",
    "\n",
    "fig2, ax2 = plt.subplots(1,10,figsize=(30,3))\n",
    "for n,t in enumerate(np.arange(t,t+dt)):\n",
    "    ax2[n].imshow(test_vid[t,:,:], cmap='gray')\n",
    "    ax2[n].axis('off')\n",
    "plt.suptitle('Actual Frames')\n",
    "plt.tight_layout()\n",
    "# fig2.savefig(FigPath/'Decoding_Actual_Frame.png',facecolor='white', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1030 #2000\n",
    "dt = 100\n",
    "im_grid = torchvision.utils.make_grid(torch.from_numpy(pred_test[t:t+dt,np.newaxis,:,:]),nrow=10,normalize=False)[0]\n",
    "im_grid2 = torchvision.utils.make_grid(torch.from_numpy(test_vid[t:t+dt,np.newaxis,:,:]),nrow=10,normalize=False)[0]\n",
    "fig, axs = plt.subplots(2,1,figsize=(20,10))\n",
    "axs[0].imshow(im_grid, cmap='gray')#.permute(1,2,0))\n",
    "axs[0].set_title('Decoding Prediction')\n",
    "axs[1].imshow(im_grid2, cmap='gray')#.permute(1,2,0))\n",
    "axs[1].set_title('Actual Frame')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'DecodedMontage_{}.png'.format(model_type),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_grid = torchvision.utils.make_grid(torch.from_numpy(model_coeff[:,np.newaxis]),nrow=10,normalize=False)[0]\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,10))\n",
    "axs.imshow(im_grid, cmap='gray')#.permute(1,2,0))\n",
    "axs.set_title('Decoding Coeff')\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'DecodingWeights_{}.png'.format(model_type),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 2\n",
    "pred_test_norm = normimgs(pred_test)\n",
    "pred_test_up = np.zeros((pred_test.shape[0],sf*pred_test.shape[1],sf*pred_test.shape[2]))\n",
    "test_vid_norm = normimgs(test_vid)\n",
    "test_vid_up = np.zeros((test_vid.shape[0],sf*test_vid.shape[1],sf*test_vid.shape[2]))\n",
    "pred_train_norm = normimgs(pred_train)\n",
    "pred_train_up = np.zeros((pred_train.shape[0],sf*pred_train.shape[1],sf*pred_train.shape[2]))\n",
    "train_vid_norm = normimgs(train_vid)\n",
    "train_vid_up = np.zeros((train_vid.shape[0],sf*train_vid.shape[1],sf*train_vid.shape[2]))\n",
    "for n in range(pred_test.shape[0]):\n",
    "    pred_test_up[n] = cv2.resize(pred_test_norm[n],(sf*pred_test.shape[2],sf*pred_test.shape[1]))\n",
    "    test_vid_up[n] = cv2.resize(test_vid_norm[n],(sf*test_vid.shape[2],sf*test_vid.shape[1]))\n",
    "    pred_train_up[n] = cv2.resize(pred_train_norm[n],(sf*pred_train.shape[2],sf*pred_train.shape[1]))\n",
    "    train_vid_up[n] = cv2.resize(train_vid_norm[n],(sf*train_vid.shape[2],sf*train_vid.shape[1]))\n",
    "\n",
    "cond = 'test'\n",
    "if cond == 'train':\n",
    "    tot_samps = np.stack((pred_train_up, train_vid_up))\n",
    "else:\n",
    "    tot_samps = np.stack((pred_test_up, test_vid_up))\n",
    "tot_samps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example Frames Video\n",
    "# t = 0\n",
    "# dt = pred_test.shape[0]\n",
    "# # comb = np.concatenate((normimgs(pred_test),normimgs(test_vid)),axis=2)\n",
    "# comb = np.concatenate((pred_test_up,test_vid_up),axis=2).astype(np.uint8)\n",
    "# # comb = (comb - np.min(comb,axis=(-1,-2))[:,np.newaxis,np.newaxis])/(np.max(comb,axis=(-1,-2))-np.min(comb,axis=(-1,-2)))[:,np.newaxis,np.newaxis]\n",
    "# # comb = (comb*255).astype(np.uint8)\n",
    "\n",
    "# FPS = 10\n",
    "# out = cv2.VideoWriter(os.path.join(FigPath,'Frames_ExVid.avi'), cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), FPS, (comb.shape[-1], comb.shape[-2]),0)\n",
    "            \n",
    "# for fm in tqdm(range(comb.shape[0])):\n",
    "#     out.write(comb[fm])\n",
    "# out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### Grab data of longest continuous sequence ######\n",
    "# def func1(a,b):\n",
    "#     # \"Enclose\" mask with sentients to catch shifts later on\n",
    "#     mask = np.r_[False,a,False]\n",
    "\n",
    "#     # Get the shifting indices\n",
    "#     idx = np.flatnonzero(mask[1:] != mask[:-1])\n",
    "\n",
    "#     s0,s1 = idx[::2], idx[1::2]\n",
    "#     idx_b = np.r_[0,(s1-s0).cumsum()]\n",
    "#     out = []\n",
    "#     for (i,j,k,l) in zip(s0,s1-1,idx_b[:-1],idx_b[1:]):\n",
    "#         out.append(((i, j), b[k:l]))\n",
    "#     return out\n",
    "\n",
    "# train_idxs,test_idxs = train_test_split(good_idxs,train_size=.6,random_state=0)\n",
    "\n",
    "# out = func1(test_idxs,np.arange(test_idxs.shape[0]))\n",
    "\n",
    "# max_seqn = 0\n",
    "# for n in range(len(out)):\n",
    "#     if len(out[n][1]) > max_seqn:\n",
    "#         max_seq = np.arange(out[n][0][0],out[n][0][1])\n",
    "#         max_seqn = len(out[n][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = 3\n",
    "tot_samps2 = uniform_filter1d(tot_samps,win_size,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 500\n",
    "dt = 100\n",
    "plt.plot(tot_samps2[0,t:t+dt,5,10])\n",
    "plt.plot(tot_samps[1,t:t+dt,5,10])\n",
    "plt.plot(tot_samps2[1,t:t+dt,5,10])\n",
    "plt.legend(['Pred','Actual','Actual_smoothed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation, PillowWriter, FFMpegWriter\n",
    "from matplotlib import colors\n",
    "def init():\n",
    "    for n in range(2):\n",
    "        axs[n].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def update(t):\n",
    "    for n in range(2):\n",
    "        ims[n].set_data(tot_samps2[n,t])\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-particle",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = 0# max_seq[0]\n",
    "lat_dims = 2\n",
    "x,y = [],[]\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,4))   #8,16,figsize=(50,30)  \n",
    "axs = axs.flatten()\n",
    "ims = []\n",
    "titles = ['Pred','Actual']\n",
    "for n in range(2):\n",
    "    ims.append(axs[n].imshow(tot_samps2[n,t],cmap='gray',norm=colors.Normalize()))\n",
    "    axs[n].axis('off')\n",
    "    axs[n].set_title('{}'.format(titles[n]))\n",
    "plt.tight_layout()\n",
    "# fig.savefig(os.path.join(FigurePath,'testimg.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-insulin",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# writervideo = PillowWriter(fps=60)  \n",
    "ani = FuncAnimation(fig, update, tqdm(range(tot_samps2.shape[1])), init_func=init)  #range(tot_samps.shape[1])\n",
    "plt.show()\n",
    "vpath = check_path(FigPath,'version_{:d}'.format(0))\n",
    "vname =  'DecodedVideo_{}_upsampled{:d}_smoothed{:d}_{}.mp4'.format(model_type,sf, win_size,cond)\n",
    "writervideo = FFMpegWriter(fps=10) \n",
    "ani.save(os.path.join(vpath,vname), writer=writervideo)\n",
    "print('DONE!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = train_scores.reshape((train_vid.shape[-2],train_vid.shape[-1]))\n",
    "test_scores = test_scores.reshape((test_vid.shape[-2],test_vid.shape[-1]))\n",
    "fig, axs = plt.subplots(2,1,figsize=(10,10))\n",
    "im1 = axs[0].imshow(train_scores, vmin=0, vmax=.55)\n",
    "axs[0].set_title('Train Correlation Map')\n",
    "add_colorbar(im1)\n",
    "im2 = axs[1].imshow(test_scores, vmin=0, vmax=.55)\n",
    "axs[1].set_title('Test Correlation Map')\n",
    "add_colorbar(im2)\n",
    "plt.tight_layout()\n",
    "# fig.savefig(FigPath/'DecodingScores_{}.png'.format(model_type),bbox_inches='tight',transparent=False, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1040\n",
    "dt = 20\n",
    "comb = np.concatenate((np.concatenate((pred_test[t:t+dt,:,:], test_vid[t:t+dt,:,:]),axis=1)),axis=1)\n",
    "fig, ax = plt.subplots(1,figsize=(25,20))\n",
    "ax.imshow(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-roommate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "european-wheel",
   "metadata": {},
   "source": [
    "Decoding wieghts of visual vs, decoding weights of movement and dot product overlap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-darkness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dominican-maldives",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_roll = train_roll/np.max(train_roll)\n",
    "# train_roll -=train_roll[0]\n",
    "# train_pitch = train_pitch/np.max(train_pitch)\n",
    "# train_pitch -=train_pitch[0]\n",
    "# test_roll = test_roll/np.max(test_roll)\n",
    "# test_roll -=test_roll[0]\n",
    "# test_pitch = test_pitch/np.max(test_pitch)\n",
    "# test_pitch -=test_pitch[0]\n",
    "\n",
    "# Y_train = torch.from_numpy(np.stack((train_roll, train_pitch),axis=1)).float()\n",
    "# Y_test  = torch.from_numpy(np.stack((test_roll, test_pitch),axis=1)).float()\n",
    "\n",
    "Y_train = torch.from_numpy(train_roll[:,np.newaxis]).float() #train_vid.reshape(train_vid.shape[0],-1)).float()#[:,10:11] # np.stack((train_roll, train_pitch),axis=1) # \n",
    "Y_test = torch.from_numpy(test_roll[:,np.newaxis]).float() #test_vid.reshape(test_vid.shape[0],-1)).float()#[:,10:11] # np.stack((test_roll, test_pitch),axis=1) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodingDataset(Dataset):\n",
    "    def __init__(self, data, output, N_fm, transform=None):\n",
    "        \n",
    "        self.data = data\n",
    "        self.output = output\n",
    "        self.transform = transform\n",
    "        self.N_fm = N_fm\n",
    "\n",
    "    def __len__(self):\n",
    "        return(self.data.shape[0])\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if idx < self.N_fm:\n",
    "            idx = self.N_fm\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        sample = torch.from_numpy(self.data[idx-self.N_fm:idx]).float()\n",
    "        gt = torch.from_numpy(self.output[idx-self.N_fm:idx,:]).float()\n",
    "        return sample.view(-1), gt.view(-1)\n",
    "    \n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "    \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_fm=1\n",
    "batch_size = 1024\n",
    "in_neurons = train_nsp.shape[1]*N_fm\n",
    "out_neurons = 2048\n",
    "out_dims = Y_train.shape[-1]*N_fm\n",
    "NEpochs = 500\n",
    "# train_dataset = DecodingDataset(train_nsp, np.stack((train_roll, train_pitch),axis=1), N_fm=N_fm)\n",
    "# test_dataset = DecodingDataset(test_nsp, np.stack((test_roll, test_pitch),axis=1), N_fm=N_fm)\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_nsp).float(),Y_train)\n",
    "test_dataset  = TensorDataset(torch.from_numpy(test_nsp).float(),Y_test)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(in_neurons,out_neurons),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(out_neurons,out_neurons),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(out_neurons,out_dims)).to(device)\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=.0001)\n",
    "criteria = nn.MSELoss()\n",
    "early_stopping = EarlyStopping(path=save_dir/'checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_loss = []\n",
    "test_tot_loss = []\n",
    "for epoch in tqdm(range(NEpochs)):\n",
    "    epoch_loss = []\n",
    "    for batch, y in train_dataloader:\n",
    "        pred = model(batch.to(device))\n",
    "        loss = criteria(pred.to(device),y.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    tot_loss.append(np.mean(epoch_loss))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_epoch_loss = []\n",
    "        for batch, y in test_dataloader:\n",
    "            pred = model(batch.to(device))\n",
    "            loss = criteria(pred.to(device),y.to(device))\n",
    "            test_epoch_loss.append(loss.item())\n",
    "        test_tot_loss.append(np.mean(test_epoch_loss))\n",
    "    early_stopping(np.mean(test_epoch_loss), model)\n",
    "    if early_stopping.early_stop == True:\n",
    "        print('Stopped Early!')\n",
    "        break\n",
    "    print('Epoch:', epoch, 'Epoch_Loss_Avg: ', np.mean(epoch_loss), 'Test_Epoch_Loss_Avg: ', np.mean(test_epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = np.arange(0,1000)\n",
    "fig, ax = plt.subplots(2,1,figsize=(20,10))\n",
    "ax[0].plot(Y_train[wind,0],'b-', label='roll')\n",
    "ax[0].plot(pred[wind,0].cpu().detach(),'r-', label='pred_roll')\n",
    "ax[1].plot(Y_train[wind,1],'b-', label='pitch')\n",
    "ax[1].plot(pred[wind,1].cpu().detach(),'r-', label='pred_pitch')\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predt = []\n",
    "    for batch, y in test_dataloader:\n",
    "        pred = model(batch.to(device))\n",
    "        predt.append(pred.cpu().numpy())\n",
    "    predt = np.concatenate(predt,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = np.arange(0,1000)\n",
    "fig, ax = plt.subplots(2,1,figsize=(20,10))\n",
    "ax[0].plot(Y_test[wind,0],'b-', label='roll')\n",
    "ax[0].plot(predt[wind,0],'r-', label='pred_roll')\n",
    "ax[1].plot(Y_test[wind,1],'b-', label='pitch')\n",
    "ax[1].plot(predt[wind,1],'r-', label='pred_pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-january",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-monroe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae2df1b5b2cc9cafc9aad66187e6d6dd9c60927ae7fe28644cf330a9c23b714e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
